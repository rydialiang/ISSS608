{
  "hash": "13845a91d282778e1d7ea4972d416ef5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In-class Ex 06\"\nauthor: \"Liang Xiuhao Rydia\"\ndate: \"May 18, 2024\"\ndate-modified: \"last-modified\"\nexecute:\n  eval: true\n  echo: true\n  warning: false\n  freeze: true\n---\n\n\nExample from [corporaexplorer](https://kgjerde.github.io/corporaexplorer/articles/bible.html)\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(tidyverse, stringi,\n               rvest, corporaexplorer,\n               readtext,\n               quanteda, tidytext)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbible <- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")\n```\n:::\n\n\nTo tidy the text, we need to know where does it start and end.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# collapse all into one string\nbible <- paste(bible, collapse = \"\\n\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Identifying the beginning and end of the Bible / stripping PJ metadata\n # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).\nstart_v <- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v <- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible <- stri_sub(bible, start_v, end_v)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# In the file, every book in the bible is preceded by five newlines,\n  # which we use to split our string into a vector where each element is a book.\nbooks <- stri_split_regex(bible, \"\\n{5}\") %>%\n    unlist %>%\n    .[-40]  # Removing the heading \"The New Testament of the King James Bible\",\n              # which also was preceded by five newlines.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Because of the structure of the text in the file:\n  # Replacing double or more newlines with two newlines, and a single newline with space.\nbooks <- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %>%\n    str_replace_all(\"\\n\", \" \") %>%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks <- books[3:68]  # The two first elements are not books\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Identifying new chapters within each book and split the text into chapters.\n# (The first characters in chapter 2 will e.g. be 2:1)\nchapters <- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %>%\n    stri_split_regex(\"NEW_CHAPTER\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Removing the chapter headings from the text (we want them as metadata).\nchapters <- lapply(chapters, function(x) x[-1])\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# We are not quite happy with the long book titles in the King James Bible,\n  # so we retrieve shorter versions from esv.org which will take up less\n  # space in the corpus map plot.\nbook_titles <- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %>%\n  html_nodes(\"td:nth-child(1)\") %>%\n  html_text() %>%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# We add a column indicating whether a book belongs to the Old or New Testament,\n#   knowing that they contain respectively 39 and 27 books.\ntestament <- c(rep(\"Old\", 39), rep(\"New\", 27))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data frame with one book as one row.\nbible_df <- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# We want each chapter to be one row, but keep the metadata (book and which testament).\nbible_df <- tidyr::unnest(bible_df, Text)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nKJB <- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n```\n:::\n\n\n-   text field = text we want to analyse\n\nMake sure you check the class of the object. The below should show \"corporaexplorerobject\".\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(KJB)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"corporaexplorerobject\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexplore(KJB)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(jsonlite, tidygraph,ggraph,\n               visNetwork, graphlayouts,\n               ggforce, skimr, tidytext,\n               tidyverse)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_data <- fromJSON(\"data/MC3.json\")\n```\n:::\n\n\nThis data is a list, not a dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(mc3_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"list\"\n```\n\n\n:::\n:::\n\n\nUse distinct to remove duplicate\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_edges <-\n  as_tibble(mc3_data$links) %>%\n  distinct() %>%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %>%\n  group_by(source, target, type) %>%\n  summarise(weights = n()) %>%\n  filter(source!=target) %>%\n  ungroup\n```\n:::\n\n\n### clean edge file\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_nodes <- as_tibble(mc3_data$nodes) %>% \n  mutate(country = as.character(country),\n         id = as.character(id),\n         product_services = as.numeric(as.character(revenue_omu)),\n         type = as.character(type)) %>% \n  select(id, country, type, revenue_omu,\n         product_services)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nskim(mc3_edges)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |          |\n|:------------------------|:---------|\n|Name                     |mc3_edges |\n|Number of rows           |24036     |\n|Number of columns        |4         |\n|_______________________  |          |\n|Column type frequency:   |          |\n|character                |3         |\n|numeric                  |1         |\n|________________________ |          |\n|Group variables          |None      |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|source        |         0|             1|   6| 700|     0|    12856|          0|\n|target        |         0|             1|   6|  28|     0|    21265|          0|\n|type          |         0|             1|  16|  16|     0|        2|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate| mean| sd| p0| p25| p50| p75| p100|hist  |\n|:-------------|---------:|-------------:|----:|--:|--:|---:|---:|---:|----:|:-----|\n|weights       |         0|             1|    1|  0|  1|   1|   1|   1|    1|▁▁▇▁▁ |\n\n\n:::\n:::\n\n\n### Add the columns back in after cleaning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nid1 <- mc3_edges %>% \n  select(source) %>% \n  rename(id = source)\n\nid2 <- mc3_edges %>% \n  select(target) %>% \n  rename(id = target)\n\nmc3_nodes1 <- rbind(id1,id2) %>% \n  distinct() %>% \n  left_join(mc3_nodes,\n            unmatched = \"drop\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_graph <- tbl_graph(nodes = mc3_nodes1,\n                       edges = mc3_edges,\n                       directed = FALSE) %>% \n  mutate(betweenness_centrality = centrality_betweenness(),\n                                                         closeness_centrality = centrality_closeness())\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmc3_graph %>% \n  filter(betweenness_centrality >= 300000) %>% \nggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha=0.5)) +\n  geom_node_point(aes(\n    size = betweenness_centrality,\n    colors = \"lightblue\",\n    alpha = 0.5)) +\n  scale_size_continuous(range=c(1,10)) +\n  theme_graph()\n```\n\n::: {.cell-output-display}\n![](In-class_Ex06_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "In-class_Ex06_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}