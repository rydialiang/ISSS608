[
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, you will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\n\n\n\nBy the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps.\n\n\n\n\nBefore we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\n\n\n\n\n\nNote\n\n\n\nThings to learn from the argument above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\n\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bounding box provides information of the extend of the geospatial data.\n\n\n\n\nTo create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\n\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\n\n\n\n\n\n\n\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#overview",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#overview",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, you will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#learning-outcome",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#learning-outcome",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "By the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#getting-started",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#getting-started",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "Before we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#geospatial-data-wrangling",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#geospatial-data-wrangling",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "The data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\n\n\n\n\n\nNote\n\n\n\nThings to learn from the argument above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\n\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bounding box provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#drawing-proportional-symbol-map",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#drawing-proportional-symbol-map",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "To create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\n\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\n\n\n\n\n\n\n\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#reference",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#reference",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html",
    "href": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html",
    "title": "Hands On Exercise 8c",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap\n\n\n\n\n\n\n\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")\n\n\nlist(NGA_wp)\n\n[[1]]\nSimple feature collection with 774 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 26662.71 ymin: 30523.38 xmax: 1344157 ymax: 1096029\nProjected CRS: Minna / Nigeria Mid Belt\nFirst 10 features:\n          ADM2_EN ADM2_PCODE                   ADM1_EN ADM1_PCODE\n1       Aba North   NG001001                      Abia      NG001\n2       Aba South   NG001002                      Abia      NG001\n3          Abadam   NG008001                     Borno      NG008\n4           Abaji   NG015001 Federal Capital Territory      NG015\n5            Abak   NG003001                 Akwa Ibom      NG003\n6       Abakaliki   NG011001                    Ebonyi      NG011\n7  Abeokuta North   NG028001                      Ogun      NG028\n8  Abeokuta South   NG028002                      Ogun      NG028\n9             Abi   NG009001               Cross River      NG009\n10    Aboh-Mbaise   NG017001                       Imo      NG017\n                         geometry total_wp wp_functional wp_nonfunctional\n1  MULTIPOLYGON (((548795.5 11...       17             7                9\n2  MULTIPOLYGON (((547286.1 11...       71            29               35\n3  MULTIPOLYGON (((1248985 104...        0             0                0\n4  MULTIPOLYGON (((510864.9 57...       57            23               34\n5  MULTIPOLYGON (((594269 1209...       48            23               25\n6  MULTIPOLYGON (((660767 2522...      233            82               42\n7  MULTIPOLYGON (((78621.56 37...       34            16               15\n8  MULTIPOLYGON (((106627.7 35...      119            72               33\n9  MULTIPOLYGON (((632244.2 21...      152            79               62\n10 MULTIPOLYGON (((540081.3 15...       66            18               26\n   wp_unknown\n1           1\n2           7\n3           0\n4           0\n5           0\n6         109\n7           3\n8          14\n9          11\n10         22\n\n\nPlot a choropleth map showing the distribution of non-function water point by LGA:\n\ntm_shape(NGA_wp) +\n  tm_fill(\"wp_nonfunctional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Reds\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of non-functional water point by LGA\",\n            legend.outside = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\n\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\n\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geometry field.\n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = \"Percentile Map\", \n            title.position = c(\"right\",\"bottom\")) +\n  tm_facets(by=\"ADM1_EN\", \n            free.coords=TRUE, \n            drop.shapes=FALSE)\n}\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nLet’s test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map.\n\narguments:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR\n\nreturns:\n\na tmap-element (plots a map)\n\n\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#overview",
    "href": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#overview",
    "title": "Hands On Exercise 8c",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#getting-started",
    "href": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#getting-started",
    "title": "Hands On Exercise 8c",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")\n\n\nlist(NGA_wp)\n\n[[1]]\nSimple feature collection with 774 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 26662.71 ymin: 30523.38 xmax: 1344157 ymax: 1096029\nProjected CRS: Minna / Nigeria Mid Belt\nFirst 10 features:\n          ADM2_EN ADM2_PCODE                   ADM1_EN ADM1_PCODE\n1       Aba North   NG001001                      Abia      NG001\n2       Aba South   NG001002                      Abia      NG001\n3          Abadam   NG008001                     Borno      NG008\n4           Abaji   NG015001 Federal Capital Territory      NG015\n5            Abak   NG003001                 Akwa Ibom      NG003\n6       Abakaliki   NG011001                    Ebonyi      NG011\n7  Abeokuta North   NG028001                      Ogun      NG028\n8  Abeokuta South   NG028002                      Ogun      NG028\n9             Abi   NG009001               Cross River      NG009\n10    Aboh-Mbaise   NG017001                       Imo      NG017\n                         geometry total_wp wp_functional wp_nonfunctional\n1  MULTIPOLYGON (((548795.5 11...       17             7                9\n2  MULTIPOLYGON (((547286.1 11...       71            29               35\n3  MULTIPOLYGON (((1248985 104...        0             0                0\n4  MULTIPOLYGON (((510864.9 57...       57            23               34\n5  MULTIPOLYGON (((594269 1209...       48            23               25\n6  MULTIPOLYGON (((660767 2522...      233            82               42\n7  MULTIPOLYGON (((78621.56 37...       34            16               15\n8  MULTIPOLYGON (((106627.7 35...      119            72               33\n9  MULTIPOLYGON (((632244.2 21...      152            79               62\n10 MULTIPOLYGON (((540081.3 15...       66            18               26\n   wp_unknown\n1           1\n2           7\n3           0\n4           0\n5           0\n6         109\n7           3\n8          14\n9          11\n10         22\n\n\nPlot a choropleth map showing the distribution of non-function water point by LGA:\n\ntm_shape(NGA_wp) +\n  tm_fill(\"wp_nonfunctional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Reds\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of non-functional water point by LGA\",\n            legend.outside = FALSE)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#choropleth-map-for-rates",
    "href": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#choropleth-map-for-rates",
    "title": "Hands On Exercise 8c",
    "section": "",
    "text": "In much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#extreme-value-maps",
    "href": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#extreme-value-maps",
    "title": "Hands On Exercise 8c",
    "section": "",
    "text": "Extreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\n\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\n\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geometry field.\n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = \"Percentile Map\", \n            title.position = c(\"right\",\"bottom\")) +\n  tm_facets(by=\"ADM1_EN\", \n            free.coords=TRUE, \n            drop.shapes=FALSE)\n}\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nLet’s test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map.\n\narguments:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR\n\nreturns:\n\na tmap-element (plots a map)\n\n\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take Home Exercise 3",
    "section": "",
    "text": "Mini-challenge 2 focuses on analyzing ship movements and shipping records to understand illegal fishing practices. FishEye analysts need help creating visualizations to show patterns of ship movements and identify suspicious behaviors. They also want to understand how the commercial fishing community changed after a company was caught fishing illegally.\nThe details of the mini challenge can be found here.\n\n\n\nFishEye analysts need your help to perform geographic and temporal analysis of the CatchNet data so they can prevent illegal fishing from happening again. Your task is to develop new visual analytics tools and workflows that can be used to discover and understand signatures of different types of behavior. Can you use your tool to visualize a signature of SouthSeafood Express Corp’s illegal behavior? FishEye needs your help to develop a workflow to find other instances of illegal behavior.\n\nFishEye analysts have long wanted to better understand the flow of commercially caught fish through Oceanus’s many ports. But as they were loading data into CatchNet, they discovered they had purchased the wrong port records. They wanted to get the ship off-load records, but they instead got the port-exit records (essentially trucks/trains leaving the port area). Port exit records do not include which vessel that delivered the products. Given this limitation, develop a visualization system to associate vessels with their probable cargos. Which vessels deliver which products and when? What are the seasonal trends and anomalies in the port exit records?\nDevelop visualizations that illustrate the inappropriate behavior of SouthSeafood Express Corp vessels. How do their movement and catch contents compare to other fishing vessels? When and where did SouthSeafood Express Corp vessels perform their illegal fishing? How many different types of suspicious behaviors are observed? Use visual evidence to justify your conclusions.\nTo support further Fisheye investigations, develop visual analytics workflows that allow you to discover other vessels engaging in behaviors similar to SouthSeafood Express Corp’s illegal activities? Provide visual evidence of the similarities.\nHow did fishing activity change after SouthSeafood Express Corp was caught? What new behaviors in the Oceanus commercial fishing community are most suspicious and why?\n\n\n\n\n\n\n\n\n\nShow the code\npacman::p_load(tidyverse, jsonlite, DT, lubridate,\n               igraph, tidygraph, ggraph, \n               visNetwork, sf,\n               patchwork, CGPfunctions,\n               ggHoriPlot)\n\n\n\n\n\nLoading the .json data using jsonlite package.\n\n\nShow the code\nmc2_data &lt;- fromJSON(\"data/MC2/mc2.json\")\n\n\nmc2 is a directed multigraph, consists of nodes dataframe and links dataframe."
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#mini-challenge-2-creating-signatures-for-geo-temporal-patterns",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#mini-challenge-2-creating-signatures-for-geo-temporal-patterns",
    "title": "Take Home Exercise 3",
    "section": "",
    "text": "Mini-challenge 2 focuses on analyzing ship movements and shipping records to understand illegal fishing practices. FishEye analysts need help creating visualizations to show patterns of ship movements and identify suspicious behaviors. They also want to understand how the commercial fishing community changed after a company was caught fishing illegally.\nThe details of the mini challenge can be found here."
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#tasks-and-questions",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#tasks-and-questions",
    "title": "Take Home Exercise 3",
    "section": "",
    "text": "FishEye analysts need your help to perform geographic and temporal analysis of the CatchNet data so they can prevent illegal fishing from happening again. Your task is to develop new visual analytics tools and workflows that can be used to discover and understand signatures of different types of behavior. Can you use your tool to visualize a signature of SouthSeafood Express Corp’s illegal behavior? FishEye needs your help to develop a workflow to find other instances of illegal behavior.\n\nFishEye analysts have long wanted to better understand the flow of commercially caught fish through Oceanus’s many ports. But as they were loading data into CatchNet, they discovered they had purchased the wrong port records. They wanted to get the ship off-load records, but they instead got the port-exit records (essentially trucks/trains leaving the port area). Port exit records do not include which vessel that delivered the products. Given this limitation, develop a visualization system to associate vessels with their probable cargos. Which vessels deliver which products and when? What are the seasonal trends and anomalies in the port exit records?\nDevelop visualizations that illustrate the inappropriate behavior of SouthSeafood Express Corp vessels. How do their movement and catch contents compare to other fishing vessels? When and where did SouthSeafood Express Corp vessels perform their illegal fishing? How many different types of suspicious behaviors are observed? Use visual evidence to justify your conclusions.\nTo support further Fisheye investigations, develop visual analytics workflows that allow you to discover other vessels engaging in behaviors similar to SouthSeafood Express Corp’s illegal activities? Provide visual evidence of the similarities.\nHow did fishing activity change after SouthSeafood Express Corp was caught? What new behaviors in the Oceanus commercial fishing community are most suspicious and why?"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#loading-r-packages",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#loading-r-packages",
    "title": "Take Home Exercise 3",
    "section": "",
    "text": "Show the code\npacman::p_load(tidyverse, jsonlite, DT, lubridate,\n               igraph, tidygraph, ggraph, \n               visNetwork, sf,\n               patchwork, CGPfunctions,\n               ggHoriPlot)"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#loading-the-data",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#loading-the-data",
    "title": "Take Home Exercise 3",
    "section": "",
    "text": "Loading the .json data using jsonlite package.\n\n\nShow the code\nmc2_data &lt;- fromJSON(\"data/MC2/mc2.json\")\n\n\nmc2 is a directed multigraph, consists of nodes dataframe and links dataframe."
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-edges",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-edges",
    "title": "Take Home Exercise 3",
    "section": "1.3 Wrangling and tidying edges",
    "text": "1.3 Wrangling and tidying edges\n\n1.3.1 Extracting edges\nFirst, we extract only distinct edges from the tibble links data.frame of mc2_data and save it as a tibble data.frame called mc2_edges.\n\n\nShow the code\nmc2_edges &lt;- mc2_data$links %&gt;% \n  distinct()\n\n\nNext, glimpse() of dplyr will be used to reveal the structure of mc2_edges tibble data.table.\n\n\nShow the code\nglimpse(mc2_edges)\n\n\nRows: 271,643\nColumns: 17\n$ type                &lt;chr&gt; \"Event.TransportEvent.TransponderPing\", \"Event.Tra…\n$ time                &lt;chr&gt; \"2035-09-16T04:06:48.185987\", \"2035-09-20T05:21:33…\n$ dwell               &lt;dbl&gt; 115074.79, 412706.32, 286092.88, 327623.95, 243225…\n$ `_last_edited_by`   &lt;chr&gt; \"Olokun Daramola\", \"Melinda Manning\", \"Olokun Dara…\n$ `_date_added`       &lt;chr&gt; \"2035-09-16T00:59:46.300100\", \"2035-09-22T02:37:37…\n$ `_last_edited_date` &lt;chr&gt; \"2035-09-16T00:59:46.300100\", \"2035-09-22T02:37:37…\n$ `_raw_source`       &lt;chr&gt; \"Oceanus Vessel Locator System\", \"Oceanus Vessel L…\n$ `_algorithm`        &lt;chr&gt; \"OVLS-Catch&Hook\", \"OVLS-Catch&Hook\", \"OVLS-Catch&…\n$ source              &lt;chr&gt; \"City of Haacklee\", \"City of Haacklee\", \"City of H…\n$ target              &lt;chr&gt; \"perchplundererbc0\", \"perchplundererbc0\", \"perchpl…\n$ key                 &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7,…\n$ date                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ data_author         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ aphorism            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ holiday_greeting    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wisdom              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `saying of the sea` &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nFrom the table above, we can identify some issues with the data:\n\nThe columns with date data type are all in character format.\nSome columns have names that starts with “_”. These need to be rename to avoid coding issues.\n\n\n\n1.3.2 Correcting the date data type with lubridate()\n\n\nShow the code\nmc2_edges$time &lt;- as_datetime(mc2_edges$time)\nmc2_edges$`_last_edited_date` &lt;- as_datetime(mc2_edges$`_last_edited_date`)\nmc2_edges$`_date_added` &lt;- as_datetime(mc2_edges$`_date_added`)\nmc2_edges$date &lt;- as_datetime(mc2_edges$date)\n\n\nNext, glimpse() will be used to confirm if the process have been performed correctly.\n\n\nShow the code\nglimpse(mc2_edges)\n\n\nRows: 271,643\nColumns: 17\n$ type                &lt;chr&gt; \"Event.TransportEvent.TransponderPing\", \"Event.Tra…\n$ time                &lt;dttm&gt; 2035-09-16 04:06:48, 2035-09-20 05:21:33, 2035-09…\n$ dwell               &lt;dbl&gt; 115074.79, 412706.32, 286092.88, 327623.95, 243225…\n$ `_last_edited_by`   &lt;chr&gt; \"Olokun Daramola\", \"Melinda Manning\", \"Olokun Dara…\n$ `_date_added`       &lt;dttm&gt; 2035-09-16 00:59:46, 2035-09-22 02:37:37, 2035-09…\n$ `_last_edited_date` &lt;dttm&gt; 2035-09-16 00:59:46, 2035-09-22 02:37:37, 2035-10…\n$ `_raw_source`       &lt;chr&gt; \"Oceanus Vessel Locator System\", \"Oceanus Vessel L…\n$ `_algorithm`        &lt;chr&gt; \"OVLS-Catch&Hook\", \"OVLS-Catch&Hook\", \"OVLS-Catch&…\n$ source              &lt;chr&gt; \"City of Haacklee\", \"City of Haacklee\", \"City of H…\n$ target              &lt;chr&gt; \"perchplundererbc0\", \"perchplundererbc0\", \"perchpl…\n$ key                 &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7,…\n$ date                &lt;dttm&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ data_author         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ aphorism            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ holiday_greeting    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wisdom              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `saying of the sea` &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n1.3.3 Changing field name\nIn the code chunk below, rename() of dplyr package is used to change the following fields.\n\n\nShow the code\nmc2_edges &lt;- mc2_edges %&gt;%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"date_added\" = \"_date_added\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"raw_source\" = \"_raw_source\",\n         \"algorithm\" = \"_algorithm\") \n\n\n\n\n1.3.4 Splitting words in type column\nThe code chunk below combined the following steps:\n\nSplitting the words by “.” - after observing that the format for type is as such: “Event.TransportEvent.TransponderPing”\nThe max(lengths(word_list)) will be used to find the maximum number of elements in any split.\nApply function(x) to pad shorter splits with NA values to make them all the same length.\nCreate word_df and changing column names to event1 etc.\nConvert word_df from matrix into tibble data.frame, and checks its class.\nAppend word_df to mc2_edges tibble data.frame.\nSaving mc2_edges into R rds format as a physical file, so that there is no need to repeat the following code chunk to access a tidy mc2_edges tibble data frame.\n\n\n\nShow the code\nword_list &lt;- strsplit(mc2_edges$type, \"\\\\.\")\n\nmax_elements &lt;- max(lengths(word_list))\n\nword_list_padded &lt;- lapply(word_list, \nfunction(x) c(x, rep(NA, max_elements - length(x))))\n\nword_df &lt;- do.call(rbind, word_list_padded)\ncolnames(word_df) &lt;- paste0(\"event\", 1:max_elements)\n\nword_df &lt;- as_tibble(word_df) %&gt;%\n  select(event2, event3)\nclass(word_df)\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nShow the code\nmc2_edges &lt;- mc2_edges %&gt;%\n  cbind(word_df)\n\n# prior to running this code, create an rds folder in data folder to ensure files are saved in the correct directory\nwrite_rds(mc2_edges, \"data/rds/mc2_edges.rds\")"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-nodes",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-nodes",
    "title": "Take Home Exercise 3",
    "section": "1.4 Wrangling and tidying nodes",
    "text": "1.4 Wrangling and tidying nodes\n\n1.4.1 Extracting nodes\nThe code chunk below will be used to extract the nodes data.frame of mc2_data and parses it as a tibble data.frame called mc2_nodes.\n\n\nShow the code\nmc2_nodes &lt;- as_tibble(mc2_data$nodes) %&gt;%\n  distinct()\n\n\nNext, take a glimpse() to understand the data structure.\n\n\nShow the code\nglimpse(mc2_nodes)\n\n\nRows: 5,637\nColumns: 20\n$ type                 &lt;chr&gt; \"Entity.Commodity.Fish\", \"Entity.Commodity.Fish\",…\n$ `_last_edited_by`    &lt;chr&gt; \"Clepper Jessen\", \"Clepper Jessen\", \"Haenyeo Hyun…\n$ `_date_added`        &lt;chr&gt; \"2033-09-04T00:00:00\", \"2034-01-21T00:00:00\", \"20…\n$ `_last_edited_date`  &lt;chr&gt; \"2035-01-25T00:00:00\", \"2035-01-04T00:00:00\", \"20…\n$ `_raw_source`        &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"Oceanus:…\n$ `_algorithm`         &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ name                 &lt;chr&gt; \"Cod/Gadus n.specificatae\", \"Birdseye/Pisces frig…\n$ id                   &lt;chr&gt; \"gadusnspecificatae4ba\", \"piscesfrigus900\", \"pisc…\n$ Name                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Haacklee…\n$ Description          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Activities           &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, …\n$ kind                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"city\", \"…\n$ qty_tons             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ date                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ flag_country         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ company              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ tonnage              &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ length_overall       &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ style                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ fish_species_present &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, …\n\n\nFrom the table above, beside the date data type, inappropriate field name, and treatment for type column issues we discussed earlier, two additional data issues can be observed. They are:\n\nThe values in Activities and fish_species_present fields are in list data type, which will affect the ability to process and to analyse the data.\nSome values in the Activities field are not ready to be analyse without further tidying (i.e. removing c(““)).\n\nWe will first repeat the steps similar steps to wrangling the mc2_edges, before proceeding to tackle the issues for Activities and fish_species_present field.\n\n\n1.4.2 Correcting the date data type with lubridate()\nCorrect the date data type and take a glimpse() to confirm changes.\n\n\nShow the code\nmc2_nodes$`_last_edited_date` &lt;- as_datetime(mc2_nodes$`_last_edited_date`)\nmc2_nodes$`_date_added` &lt;- as_datetime(mc2_nodes$`_date_added`)\nmc2_nodes$date &lt;- as_datetime(mc2_nodes$date)\nglimpse(mc2_nodes)\n\n\nRows: 5,637\nColumns: 20\n$ type                 &lt;chr&gt; \"Entity.Commodity.Fish\", \"Entity.Commodity.Fish\",…\n$ `_last_edited_by`    &lt;chr&gt; \"Clepper Jessen\", \"Clepper Jessen\", \"Haenyeo Hyun…\n$ `_date_added`        &lt;dttm&gt; 2033-09-04, 2034-01-21, 2033-06-22, 2033-11-24, …\n$ `_last_edited_date`  &lt;dttm&gt; 2035-01-25, 2035-01-04, 2035-01-14, 2035-01-14, …\n$ `_raw_source`        &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"Oceanus:…\n$ `_algorithm`         &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ name                 &lt;chr&gt; \"Cod/Gadus n.specificatae\", \"Birdseye/Pisces frig…\n$ id                   &lt;chr&gt; \"gadusnspecificatae4ba\", \"piscesfrigus900\", \"pisc…\n$ Name                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Haacklee…\n$ Description          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Activities           &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, …\n$ kind                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"city\", \"…\n$ qty_tons             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ date                 &lt;dttm&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ flag_country         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ company              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ tonnage              &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ length_overall       &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ style                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ fish_species_present &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, …\n\n\n\n\n1.4.3 Changing field name\nIn the code chunk below, rename() of dplyr package is used to change the following fields.\n\n\nShow the code\nmc2_nodes &lt;- mc2_nodes %&gt;%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"date_added\" = \"_date_added\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"raw_source\" = \"_raw_source\",\n         \"algorithm\" = \"_algorithm\") \n\n\n\n\n1.4.4 Splitting words in type column\nDetails on the code chunk can be found in section 1.3.4. At this point, we will not be saving the mc2_nodes as R rds format yet, as there are more works to be done to clean up the dataframe.\n\n\nShow the code\nword_list &lt;- strsplit(mc2_nodes$type, \"\\\\.\")\n\nmax_elements &lt;- max(lengths(word_list))\n\nword_list_padded &lt;- lapply(word_list, \nfunction(x) c(x, rep(NA, max_elements - length(x))))\n\nword_df &lt;- do.call(rbind, word_list_padded)\ncolnames(word_df) &lt;- paste0(\"entity\", 1:max_elements)\n\nword_df &lt;- as_tibble(word_df) %&gt;%\n  select(entity2, entity3)\nclass(word_df)\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nShow the code\nmc2_nodes &lt;- mc2_nodes %&gt;%\n  cbind(word_df)\n\n\n\n\n1.4.5 Tidying text field\nUsing mutate() of dplyr and gsub() of Base R to tidy up the values in the cell. Essentially, the unwanted characters like c, (, ), and \\ are removed by substituting with empty value \"\" for both Activities and fish_species_present columns. What is left in the columns will be characters separated by ,.\n\n\nShow the code\nmc2_nodes &lt;- mc2_nodes %&gt;%\n  mutate(Activities = gsub(\"c[(]\", \"\", Activities)) %&gt;% \n  mutate(Activities = gsub(\"\\\"\", \"\", Activities)) %&gt;%\n  mutate(Activities = gsub(\"[)]\", \"\", Activities)) \n\n\n\n\nShow the code\nmc2_nodes &lt;- mc2_nodes %&gt;%\n  mutate(fish_species_present = gsub(\"c[(]\", \"\", fish_species_present)) %&gt;% \n  mutate(fish_species_present = gsub(\"\\\"\", \"\", fish_species_present)) %&gt;%\n  mutate(fish_species_present = gsub(\"[)]\", \"\", fish_species_present)) \n\n\nLastly, we will save the tidied mc2_nodes\n\n\nShow the code\n# prior to running this code, create an rds folder in data folder to ensure files are saved in the correct directory\nwrite_rds(mc2_nodes, \"data/rds/mc2_nodes.rds\")"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#extracting-the-required-columns-for-each-graph",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#extracting-the-required-columns-for-each-graph",
    "title": "Take Home Exercise 3",
    "section": "1.5 Extracting the required columns for each graph",
    "text": "1.5 Extracting the required columns for each graph\nIn this section, we will extract the required column for the following graphs:\n\nVessel Movements\nHarbor Reports\nHarbor Import Records\n\n\n1.5.1 Vessel Movements\nVessel Movements: Oceanus is outfitted with a transponder/ping system named the Oceanus Vessel Locator System (OVLS).  Vessels are outfitted with a transponder and periodic ‘pings’ from base-stations results in a report of vessel locations at any time.  The raw ping granularity is at the minute-level but post-processing has converted it into visit/dwell times. OVLS is generally reliable, though vessel records may be missing for a variety of reasons.\nNode/Edge types and properties present\n\nEntity.Vessel: Description of the vessel\nEntity.Location: Description of a geographic location\nEvent.TransponderPing: Links a vessel to a location\n\nFirst, we will extract the relevant nodes, namely the vessels and locations from mc2_nodes.\n\n\nShow the code\nvessel_mvmt_nodes &lt;- mc2_nodes %&gt;% \n  filter(entity2 %in% c(\"Vessel\",\"Location\")) \n\n\nNext, we will extract the vessel movement edges from mc2_edges, by filtering the “TransponderPing” from event3 column.\n\n\nShow the code\nvessel_mvmt_edges &lt;- mc2_edges %&gt;% \n  filter(event3 %in% c(\"TransponderPing\"))\n\n\n\n\nShow the code\nvessel_movement_data &lt;- vessel_mvmt_edges %&gt;% \n  filter(event3 %in% c(\"TransponderPing\")) %&gt;%\n  select(time, dwell, source, target) %&gt;% \n  mutate(source = gsub(\"^City of\", \"\", source)) %&gt;%\n  mutate(source = gsub(\"^\\\\s+\", \"\", source)) %&gt;%\n  left_join(oceanus_locations_df,\n            by = c(\"source\" = \"Name\"))\n\n\n\n\n1.5.2 Harbor Reports\nHarbor Reports: Harbor masters regularly report the vessels found in their purview anytime during the day.  This data is derived from a different system than OVLS (see “Vessel Movements”), though the data overlaps.  Harbor Reports are provided on a different schedule from different harbors. Since no harbor reports every day, this data has lower temporal granularity than vessel movement data. Additionally, the Harbor Master is also responsible for proximate navigational beacon(s), so this data has lower spatial granularity as well.  However, the list of vessels observed is considered canonical.\nNode/edge types present:\n\nEntity.Vessel\nEntity.location\nEvent.HarborReport\n\nSince the node type are the same as the vessel movements, we will make a copy of the node from vessel movement nodes.\n\n\nShow the code\nharbor_report_nodes &lt;- vessel_mvmt_nodes\n\n\nNext, we will extract the harbor report edges from mc2_edges, by filtering the “HarborReport” from event3 column.\n\n\nShow the code\nharbor_report_edges &lt;- mc2_edges %&gt;% \n  filter(event2 %in% c(\"HarborReport\"))\n\n\n\n\n1.5.3 Harbor Import Records\nHarbor Import Records: Vessels deliver cargo to the ports, and that cargo is brought into Oceanus.  These records reflect the goods that *leave* the harbor to go to businesses in Oceanus or to be exported.  It was filtered pre-ingest to focus on the delivery of raw fish.  Because it is raw, fish leave the port quickly (generally one day after delivery).  Due to clerical error, the records purchased by FishEye do not include the vessel that delivered the cargo.\nNode/Edge types present:\n\nEntity.location\nEntity.Commodity.Fish\nEntity.Document.DeliveryReport\nEvent.Transaction\n\nFirst, we will extract the relevant nodes, namely the location, commodity.fish and document.delivery report from mc2_nodes.\n\n\nShow the code\nharbor_import_records_nodes &lt;- mc2_nodes %&gt;% \n  filter(entity2 %in% c(\"Location\",\"Commodity\",\"Document\"))\n\n\nNext, we will extract harbor import records edges, by filtering the event2 with value of “Transaction”.\n\n\nShow the code\nharbor_import_records_edges &lt;- mc2_edges %&gt;% \n  filter(event2 == \"Transaction\")\n\n\nBefore we move on to exploring the data, we will save the 3 sources edges and nodes tibble data frame as R rds format in the data/rds folder:\n\n\nShow the code\nwrite_rds(vessel_mvmt_nodes, \"data/rds/vessel_mvmt_nodes.rds\")\nwrite_rds(vessel_mvmt_edges, \"data/rds/vessel_mvmt_edges.rds\")\nwrite_rds(vessel_movement_data, \"data/rds/vessel_movement_data.rds\")\nwrite_rds(harbor_report_nodes, \"data/rds/harbor_report_nodes.rds\")\nwrite_rds(harbor_report_edges, \"data/rds/harbor_report_edges.rds\")\nwrite_rds(harbor_import_records_nodes, \"data/rds/harbor_import_records_nodes.rds\")\nwrite_rds(harbor_import_records_edges, \"data/rds/harbor_import_records_edges.rds\")\n\n\n\n\nShow the code\nunique(mc2_edges$type)\n\n\n[1] \"Event.TransportEvent.TransponderPing\"\n[2] \"Event.Transaction\"                   \n[3] \"Event.HarborReport\""
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#task-1-flow-of-commercially-caught-fish",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#task-1-flow-of-commercially-caught-fish",
    "title": "Take Home Exercise 3",
    "section": "2.0 Task 1: Flow of Commercially Caught Fish",
    "text": "2.0 Task 1: Flow of Commercially Caught Fish\nIn this section, we focus on a few key areas to understand how the commercially caught fish flows from the vessels through the various ports:\n\nAssociating the vessels with their probable cargoes\nWhich vessels deliver which products and when?\nExamine the seasonal trends and anomalies in the port exit records"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#associating-the-vessels-with-their-probable-cargoes",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#associating-the-vessels-with-their-probable-cargoes",
    "title": "Take Home Exercise 3",
    "section": "2.1 Associating the vessels with their probable cargoes",
    "text": "2.1 Associating the vessels with their probable cargoes\nTo find out which commodity goes to which ports, we first create a cargo list that links the cargo to the cities and commodities. At the same time, we also clean up the name of the fish, leaving only its common name in the “name” column, by removing all the characters after the “/”.\n\n\nShow the code\ncargo_port_list &lt;- harbor_import_records_edges %&gt;% \n  select(source,target) %&gt;% \n  filter(target %in% c(\"City of Haacklee\",\n                       \"City of Lomark\",\n                       \"City of Himark\",\n                       \"City of Paackland\",\n                       \"City of South Paackland\",\n                       \"City of Port Grove\"))\n\ncargo_commodity_list &lt;- harbor_import_records_edges %&gt;% \n  select(source,target) %&gt;% \n  filter(!target %in% c(\"City of Haacklee\",\n                       \"City of Lomark\",\n                       \"City of Himark\",\n                       \"City of Paackland\",\n                       \"City of South Paackland\",\n                       \"City of Port Grove\")) %&gt;% \n  rename(commodity = target)\n\ncargo_list &lt;- cargo_port_list %&gt;% \n  left_join(cargo_commodity_list) %&gt;%\n  left_join(harbor_import_records_edges) %&gt;% \n  select(source, target, commodity, date) %&gt;% \n  rename(cargo = source, city = target) \n\ncargo_list&lt;- harbor_import_records_nodes %&gt;% \n  filter(entity3 ==\"Fish\") %&gt;% \n  rename(commodity = id) %&gt;% \n  select(name, commodity) %&gt;% \n  left_join(cargo_list) %&gt;% \n  mutate(name = str_replace(name, \"/.*\", \"\"))\n\ncargo_list&lt;- harbor_import_records_nodes %&gt;% \n  select(id,qty_tons) %&gt;% \n  rename(cargo = id) %&gt;% \n  left_join(cargo_list,\n            unmatched = \"drop\") %&gt;%\n  filter(if_all(c(qty_tons), ~ !is.na(.)))\n\n\nMatching the vessel with the cargo list\nWe will use the vessel_mvmt_nodes that contains information on the movement of fishing vessels and cargoes, and define the vessels location, start time and end time of the vessels in the particular location using transponder ping.\n\n\nShow the code\nfishing_vessel_list &lt;- vessel_mvmt_nodes %&gt;% \n  filter(entity3 %in% c(\"FishingVessel\")) %&gt;% \n  select(id)\n\n\n\n\nShow the code\nvessel_list &lt;- vessel_mvmt_nodes %&gt;% \n  filter(entity3 %in% c(\"FishingVessel\", \"CargoVessel\")) %&gt;% \n  select(id) \n\nvessel_list &lt;- as.list(vessel_list)\n\nvessel_location &lt;- mc2_edges %&gt;% \n  filter(event3 == \"TransponderPing\") %&gt;%\n  filter(target %in% unlist(vessel_list)) %&gt;% \n  select(source, target, time, dwell) %&gt;% \n  arrange(target,time) %&gt;% \n  mutate(next_time = ifelse(lead(target) == target, lead(time), NA)) %&gt;% \n  mutate(next_time = as_datetime(next_time))   %&gt;% \n  mutate(end_time = time + dwell)\n\nvessel_location_city &lt;- vessel_location %&gt;% \n  filter(source %in% c(\"City of Haacklee\",\n                       \"City of Lomark\",\n                       \"City of Himark\",\n                       \"City of Paackland\",\n                       \"City of South Paackland\",\n                       \"City of Port Grove\"))\n\n\nVessel Location based on harbor report\nThe next step we do is to extract the date, location and vessel from the harbor report. Since this is describe as canonical, it should be considered for matching first before using the vessel location data from transponder ping. Columns are renamed to match the information in the cargo_list.\n\n\nShow the code\nvessel_mvmt_hr &lt;- harbor_report_edges %&gt;% \n  select(source, target, date) %&gt;% \n  rename(vessel = source, city = target, vessel_delivery_date = date)\n\n\nMerging cargo_list and vessel_mvmt_hr\nAdding one column on vessel delivery date, which is 1 day before the date stated in the harbor import record.\n\n\nShow the code\ncargo_list &lt;- cargo_list %&gt;% \n  mutate(vessel_delivery_date = date + days(-1))\n\n\nSaving cargo_list:\n\n\nShow the code\nwrite_rds(cargo_list, \"data/rds/cargo_list.rds\")\n\n\n\n\nShow the code\nvessel_location_match_hr &lt;- cargo_list%&gt;% \n  left_join(vessel_mvmt_hr ) %&gt;%\n  filter(if_all(c(qty_tons,vessel), ~ !is.na(.))) %&gt;% \n  distinct()\n\n\n\n\nShow the code\nwrite_rds(vessel_location_match_hr, \"data/rds/vessel_location_match_hr.rds\")\n\n\n\n\nShow the code\nhr_match &lt;- mc2_nodes %&gt;% \n  select(id,Name,flag_country, company, tonnage,entity3) %&gt;% \n  rename(vessel = id) %&gt;% \n  left_join(vessel_location_match_hr) %&gt;%   \n  filter(if_all(c(qty_tons, tonnage), ~ !is.na(.))) %&gt;% \n  distinct() %&gt;% \n  filter()\n\n\nMerging cargo_list and vessel_location_city\n\n\nShow the code\nvessel_location_city &lt;- vessel_location_city %&gt;% \n  mutate(date = substr(`time`,1,10)) %&gt;% \n  mutate(vessel_delivery_date = ymd(date))  %&gt;% \n  filter(dwell &gt; 0)\n\n\n\n\nShow the code\nvessel_location_match &lt;- vessel_location_city %&gt;% \n  select(source,target,vessel_delivery_date) %&gt;% \n  rename(city = source, vessel_hr = target) %&gt;% \n  left_join(cargo_list,\n            unmatched = \"drop\") %&gt;%\n  filter(if_all(c(qty_tons), ~ !is.na(.))) %&gt;% \n  distinct()\n\n\nVessel Match Graph\n\n\nShow the code\nid1 &lt;- vessel_location_match_hr  %&gt;% \n  select(vessel) %&gt;% \n  rename(id = vessel) \n\nid2 &lt;- vessel_location_match_hr  %&gt;% \n  select(cargo) %&gt;% \n  rename(id = cargo)\n\ncargo_vessel_nodes &lt;- rbind(id1,id2) %&gt;% \n  distinct() \n\ncargo_vessel_edges &lt;- vessel_location_match_hr %&gt;% \n  select(vessel,cargo, name, city) %&gt;% \n  distinct() %&gt;%\n  group_by(vessel, cargo) %&gt;%\n  rename(source = vessel, target = cargo)%&gt;%\n  filter(source!=target) %&gt;% \n  ungroup()\n\ncargo_vessel_graph &lt;- tbl_graph(nodes = cargo_vessel_nodes,\n                       edges = cargo_vessel_edges,\n                       directed = FALSE)\n\n\n\n\nShow the code\ncargo_vessel_graph %&gt;%\n  ggraph(layout = 'fr') +\n  geom_edge_link() +\n  geom_node_point() + \n  theme_graph()\n\n\nFinding anomalies in vessel movement by comparing end time (calculated by dwell) with next time (the next time the vessel is detected at the next location).\n\n\nShow the code\nab_vessel_mvmt &lt;- vessel_location %&gt;%\n  mutate(time = ymd_hms(time)) %&gt;% \n  mutate(next_time = ymd_hms(next_time)) %&gt;% \n  mutate(end_time = ymd_hms(end_time)) %&gt;% \n  filter(end_time != next_time) \n\nab_vessel_mvmt_agg &lt;- ab_vessel_mvmt %&gt;% \n  distinct() %&gt;% \n  group_by(source) %&gt;% \n  summarise(weights = n()) %&gt;%\n  arrange(desc(weights))\nab_vessel_mvmt_agg\n\n\n# A tibble: 22 × 2\n   source                  weights\n   &lt;chr&gt;                     &lt;int&gt;\n 1 City of Paackland          2893\n 2 City of South Paackland    2553\n 3 City of Lomark             2482\n 4 City of Himark             1721\n 5 City of Haacklee           1509\n 6 Cod Table                  1018\n 7 Nav C                       710\n 8 Exit East                   646\n 9 Wrasse Beds                 592\n10 Tuna Shelf                  517\n# ℹ 12 more rows\n\n\nOverview of Harbor Report\n\n\nShow the code\ndistinct_harbor_report &lt;- harbor_report_edges %&gt;% \n  select(source,target,date) %&gt;% \n  filter(source %in% unlist(fishing_vessel_list)) %&gt;%\n  distinct() %&gt;% \n  arrange(source, date) %&gt;%\n  mutate(target = fct_infreq(target))\n\n\n\n\nShow the code\nggplot(distinct_harbor_report) +\n  geom_bar(aes(x = target))\n\n\n\n\n\n\n\n\n\nOverview of Vessels Location by Transponder Ping\n\n\nShow the code\ntransponder_location &lt;- mc2_edges %&gt;% \n  filter(event3 == \"TransponderPing\") %&gt;%\n  filter(target %in% unlist(fishing_vessel_list)) %&gt;%\n  filter(source %in% c(\"City of Haacklee\",\n                       \"City of Lomark\",\n                       \"City of Himark\",\n                       \"City of Paackland\",\n                       \"City of South Paackland\",\n                       \"City of Port Grove\")) %&gt;% \n  select(source, target, time) %&gt;%\n  mutate(source = fct_infreq(source))\n\nggplot(transponder_location) +\n  geom_bar(aes(x = source))\n\n\n\n\n\n\n\n\n\nA quick comparison between the two bar chart, we can conclude that port activities for fishing vessels are highest at City of Paackland and least at City of Himark. Also, there is no fishing vessels that visits City of Port Grove."
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#examine-the-seasonal-trends-and-anomalies-in-the-port-exit-records",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#examine-the-seasonal-trends-and-anomalies-in-the-port-exit-records",
    "title": "Take Home Exercise 3",
    "section": "2.3 Examine the seasonal trends and anomalies in the port exit records",
    "text": "2.3 Examine the seasonal trends and anomalies in the port exit records\nWe examine the cargo_list and realised that there are some records that shows negative tonnage for their cargoes. This is abnormal as all cargoes should have positive qty_tons value.\n\n\nShow the code\nnegative_ton_cargo_by_city &lt;- cargo_list %&gt;% \n  filter(qty_tons &lt;= 0) %&gt;% \n  arrange(qty_tons) %&gt;% \n  group_by(city) %&gt;% \n  summarise(total_qty_ton_neg = sum(qty_tons)) %&gt;% \n  arrange(total_qty_ton_neg)\n\npositive_ton_cargo_by_city &lt;- cargo_list %&gt;% \n  filter(qty_tons &gt; 0) %&gt;% \n  arrange(qty_tons) %&gt;% \n  group_by(city) %&gt;% \n  summarise(total_qty_ton_pos = sum(qty_tons)) %&gt;% \n  arrange(desc(total_qty_ton_pos))\n\nnegative_ton_cargo_by_city \n\n\n# A tibble: 5 × 2\n  city                    total_qty_ton_neg\n  &lt;chr&gt;                               &lt;dbl&gt;\n1 City of Paackland                  -224. \n2 City of Himark                     -173. \n3 City of South Paackland            -139. \n4 City of Lomark                     -115. \n5 City of Haacklee                    -77.8\n\n\nShow the code\npositive_ton_cargo_by_city\n\n\n# A tibble: 5 × 2\n  city                    total_qty_ton_pos\n  &lt;chr&gt;                               &lt;dbl&gt;\n1 City of Paackland                  34653.\n2 City of Himark                     32839.\n3 City of Lomark                     23721.\n4 City of South Paackland            20790.\n5 City of Haacklee                   14988.\n\n\n\n\nShow the code\npositive_ton_cargo_by_city$city &lt;- factor(positive_ton_cargo_by_city$city, \n                                           levels = rev(positive_ton_cargo_by_city$city[order(positive_ton_cargo_by_city$total_qty_ton_pos)]))\n\nggplot(positive_ton_cargo_by_city, aes(x = city)) +\n  geom_bar(aes(y = total_qty_ton_pos), \n           stat = \"identity\", \n           position = \"dodge\", fill = \"blue\", alpha = 0.6) +  # Positive quantities\n  labs(title = \"Quantities by City\",\n       x = \"\",\n       y = \"Total Quantity (tons)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThere seems to be suspicious activities going on at each cities when we look at the negative values in qty_ton.\n\n\nShow the code\nnegative_ton_cargo_by_city\n\n\n# A tibble: 5 × 2\n  city                    total_qty_ton_neg\n  &lt;chr&gt;                               &lt;dbl&gt;\n1 City of Paackland                  -224. \n2 City of Himark                     -173. \n3 City of South Paackland            -139. \n4 City of Lomark                     -115. \n5 City of Haacklee                    -77.8\n\n\nNext, we will remove the negative quantity and then find the aggregated value by the type of fish, the city, and the date of transaction.\n\n\nShow the code\nfish_by_port_agg &lt;- cargo_list %&gt;%\n  distinct() %&gt;%\n  filter(qty_tons &gt; 0) %&gt;% \n  group_by(name, city, date) %&gt;%\n  summarise(total_qty_ton = sum(qty_tons)) %&gt;%\n  ungroup() %&gt;% \n  mutate(month = month(date, \n                       label = TRUE, \n                       abbr = TRUE))\n\n\nSecondly, when we observe the heatmap, we also realised that the data only covers the month from Feb to Nov in year 2035.\n\n\nShow the code\n# Create an overall Oceanus heat map for all types of fish\nfish_agg &lt;- fish_by_port_agg  %&gt;%\n  distinct() %&gt;%\n  group_by(name,month) %&gt;%\n  summarise(total_qty_ton = sum(total_qty_ton)) \n\nggplot(fish_agg, aes(x = month, y = name, fill = total_qty_ton)) +\n    geom_tile(color = \"white\") +\n    scale_fill_gradient(low = \"white\", high = \"blue\") +\n    labs(title = paste(\"Calendar Heatmap for fish in Oceanus\"),\n         x = \"Month of the Year\",\n         y = \"Fish Type\",\n         fill = \"Total Quantity (tons)\") +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Function to create a calendar heat map\ncreate_heatmap &lt;- function(data, city, f) {\n  ggplot(data, aes(x = month, y = name, fill = total_qty_ton)) +\n    geom_tile(color = \"white\") +\n    scale_fill_gradient(low = \"white\", high = \"blue\") +\n    labs(title = paste(\"Calendar Heatmap for fish in\", city),\n         x = \"Month of the Year\",\n         y = \"Fish Type\",\n         fill = \"Total Quantity (tons)\") +\n    theme_minimal()\n}\n\n\n\n\nShow the code\n# Create an empty list to store heatmaps\nheatmaps &lt;- list()\n\n# Iterate over each city\ncities &lt;- unique(cargo_list$city)\nfor (c in cities) {\n  # Filter the data for the current city\n  heatmap_data &lt;- fish_by_port_agg %&gt;% \n    filter(city == c)\n  \n  # Create the heatmap for the current city\n  heatmap &lt;- create_heatmap(heatmap_data, c, name)\n  \n  # Store the heatmap in the list\n  heatmaps[[c]] &lt;- heatmap\n}\n\n# Print or visualize the heatmaps\nfor (c in cities) {\n  print(heatmaps[[c]])\n}"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#understanding-the-types-of-fish-that-should-not-be-in-the-market",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#understanding-the-types-of-fish-that-should-not-be-in-the-market",
    "title": "Take Home Exercise 3",
    "section": "2.3.1 Understanding the types of fish that should not be in the market",
    "text": "2.3.1 Understanding the types of fish that should not be in the market\n\n\nShow the code\nregion_fish_species &lt;- mc2_nodes %&gt;% \n  filter(entity3 == \"Region\") %&gt;% \n  select(Name, fish_species_present, Activities, kind)\n\n\n\n\nShow the code\nword_list &lt;- strsplit(region_fish_species$fish_species_present, \"\\\\,\")\n\nmax_elements &lt;- max(lengths(word_list))\n\nword_list_padded &lt;- lapply(word_list, \nfunction(x) c(x, rep(NA, max_elements - length(x))))\n\nword_df &lt;- do.call(rbind, word_list_padded)\ncolnames(word_df) &lt;- paste0(\"species\", 1:max_elements) \n\nword_df &lt;- as_tibble(word_df) %&gt;% \n  mutate(species1 = str_replace(species1, \"/.*\", \"\")) %&gt;% \n  mutate(species2 = str_replace(species2, \"/.*\", \"\")) %&gt;% \n  mutate(species3 = str_replace(species3, \"/.*\", \"\")) %&gt;% \n  mutate(species4 = str_replace(species4, \"/.*\", \"\")) %&gt;% \n  mutate(species5 = str_replace(species5 , \"/.*\", \"\")) %&gt;%\n  mutate_at(vars(species1:species5), trimws)\nclass(word_df)\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nShow the code\nregion_fish_species &lt;- region_fish_species %&gt;%\n  cbind(word_df) \n  \nregion_fish_species\n\n\n                 Name\n1           Cod Table\n2      Ghoti Preserve\n3         Wrasse Beds\n4           Nemo Reef\n5 Don Limpet Preserve\n6          Tuna Shelf\n                                                                                                  fish_species_present\n1                                             Cod/Gadus n.specificatae, Birdseye/Pisces frigus, Beauvoir/Habeas pisces\n2                       Wrasse/Labridae n.refert, Beauvoir/Habeas pisces, Helenaa/Pisces satis, Offidiaa/Piscis osseus\n3                                             Wrasse/Labridae n.refert, Birdseye/Pisces frigus, Beauvoir/Habeas pisces\n4 Wrasse/Labridae n.refert, Tuna/Thunnini n.vera, Birdseye/Pisces frigus, Beauvoir/Habeas pisces, Helenaa/Pisces satis\n5  Tuna/Thunnini n.vera, Birdseye/Pisces frigus, Beauvoir/Habeas pisces, Helenaa/Pisces satis, Sockfish/Pisces foetida\n6                         Tuna/Thunnini n.vera, Birdseye/Pisces frigus, Beauvoir/Habeas pisces, Harland/Piscis sapidum\n                         Activities                kind species1 species2\n1                Commercial fishing      Fishing Ground      Cod Birdseye\n2     Research, Tourism, Recreation Ecological Preserve   Wrasse Beauvoir\n3                Commercial fishing      Fishing Ground   Wrasse Birdseye\n4               Recreation, Tourism Ecological Preserve   Wrasse     Tuna\n5               Recreation, Tourism Ecological Preserve     Tuna Birdseye\n6 Commercial fishing, Sport fishing      Fishing Ground     Tuna Birdseye\n  species3 species4 species5\n1 Beauvoir     &lt;NA&gt;     &lt;NA&gt;\n2  Helenaa Offidiaa     &lt;NA&gt;\n3 Beauvoir     &lt;NA&gt;     &lt;NA&gt;\n4 Birdseye Beauvoir  Helenaa\n5 Beauvoir  Helenaa Sockfish\n6 Beauvoir  Harland     &lt;NA&gt;\n\n\n\nVisualising the Species presence in each Region\n\n\nShow the code\n# Order them based on 3 Preserves and 3 Fishing Ground\ndesired_order &lt;- c(\"Ghoti Preserve\", \"Nemo Reef\", \"Don Limpet Preserve\",\"Cod Table\", \"Wrasse Beds\",\"Tuna Shelf\")  \n\nregion_fish_species_long$Name &lt;- factor(region_fish_species_long$Name, levels = desired_order)\n\nggplot(region_fish_species_long, aes(x = Name, \n                                     y = Presence,\n                                     colour = Presence)) +\n  geom_point() +\n  labs(title = \"Species Presence by Name\",\n       x = \"Name\",\n       y = \"Species\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\nFrom the above visualisation, we can derive that Sockfish, Offidiaa, and Helenaa species can only be found in the preserves but not in the fishing grounds. Therefore, any cargoes that contains these fish species would have fished illegal. Below shows the visualisation of the species and qty_ton that flows through each city by months.\n\n\nShow the code\n# Create an empty list to store heatmaps\nheatmaps &lt;- list()\n\n# Iterate over each city\ncities &lt;- unique(cargo_list$city)\nfor (c in cities) {\n  # Filter the data for the current city\n  heatmap_data &lt;- fish_by_port_agg %&gt;% \n    filter(city == c) %&gt;% \n    filter(name %in% c(\"Sockfish\", \"Offidiaa\", \"Helenaa\"))\n  \n  # Create the heatmap for the current city\n  heatmap &lt;- create_heatmap(heatmap_data, c, name)\n  \n  # Store the heatmap in the list\n  heatmaps[[c]] &lt;- heatmap\n}\n\n# Print or visualize the heatmaps\nfor (c in cities) {\n  print(heatmaps[[c]])\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Create an overall Oceanus heat map for all types of fish\nfish_agg &lt;- fish_by_port_agg  %&gt;% \n  filter(name %in% c(\"Sockfish\", \"Offidiaa\", \"Helenaa\")) %&gt;% \n  distinct() %&gt;%\n  group_by(name,month) %&gt;%\n  summarise(total_qty_ton = sum(total_qty_ton))\n\nggplot(fish_agg, aes(x = month, y = name, fill = total_qty_ton)) +\n    geom_tile(color = \"white\") +\n    scale_fill_gradient(low = \"white\", high = \"blue\") +\n    labs(title = paste(\"Calendar Heatmap for fish in Oceanus\"),\n         x = \"Month of the Year\",\n         y = \"Fish Type\",\n         fill = \"Total Quantity (tons)\") +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\nFrom this heatmap above, we understand that there is an abnormal increase in Sockfish catch from May onwards, and abnormal increase in Offidiaa catch from September onwards , which are species unique to the Don Limpet Preserve and Ghoti Preserve respectively.\nProbable reason for this is that since SouthSeafood Express Corp was caught in mid-May for illegal fishing in Ghoti Preserve, other illegal fishing vessels made a switch to Don Limpet Reserves to fish."
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#task-2",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#task-2",
    "title": "Take Home Exercise 3",
    "section": "3.0 Task 2",
    "text": "3.0 Task 2\nDevelop visualizations that illustrate the inappropriate behavior of SouthSeafood Express Corp vessels. How do their movement and catch contents compare to other fishing vessels? When and where did SouthSeafood Express Corp vessels perform their illegal fishing? How many different types of suspicious behaviors are observed? Use visual evidence to justify your conclusions."
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#illegal-fishing-by-southseafood-express-corp",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#illegal-fishing-by-southseafood-express-corp",
    "title": "Take Home Exercise 3",
    "section": "3.1 Illegal fishing by SouthSeafood Express Corp",
    "text": "3.1 Illegal fishing by SouthSeafood Express Corp\nSouthSeafood Express Corp operates two fishing vessels by the id of “snappersnatcher7be” and “roachrobberdb6”.\n\n\nShow the code\ntransponder_ping_edge &lt;- mc2_edges %&gt;% \n  filter(event3 == \"TransponderPing\")\n\n\n\n\nShow the code\ntransponder_ping_edge_agg &lt;-\n  transponder_ping_edge %&gt;%\n  distinct() %&gt;%\n  group_by(source, target, type) %&gt;%\n  summarise(weights = n()) %&gt;%\n  filter(source!=target) %&gt;% \n  ungroup\n\n\n\n\nShow the code\ntransponder_ping_edge_agg %&gt;% \n  filter(target %in% c(\"snappersnatcher7be\",\"roachrobberdb6\")) %&gt;%\n  group_by(target) %&gt;% \n  ggplot(aes(x=target, y=source,\n             size = weights)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nsouthseafood_edge &lt;- mc2_edges %&gt;% \n  filter(event3 == \"TransponderPing\") %&gt;% \n  filter(target %in% c(\"snappersnatcher7be\",\"roachrobberdb6\")) %&gt;% \n  arrange(target,time)\n\n\n\n\nShow the code\nssf_edges_agg &lt;-\n  southseafood_edge %&gt;%\n  distinct() %&gt;%\n  group_by(source, target, type) %&gt;%\n  summarise(weights = n()) %&gt;%\n  filter(source!=target) %&gt;% \n  ungroup\n\n\n\n\nShow the code\nid1 &lt;- ssf_edges_agg %&gt;% \n  select(source) %&gt;% \n  rename(id = source) \n\nid2 &lt;- ssf_edges_agg %&gt;% \n  select(target) %&gt;% \n  rename(id = target)\n\nmc2_nodes1 &lt;- rbind(id1,id2) %&gt;% \n  distinct() \n\n\n\n\nShow the code\nssf_graph &lt;- tbl_graph(nodes = mc2_nodes1,\n                       edges = ssf_edges_agg,\n                       directed = TRUE)\n\n\n\n\nShow the code\n# Add a color column to nodes\nssf_graph &lt;- ssf_graph %&gt;%\n  activate(nodes) %&gt;%\n  mutate(color = case_when(\n    id %in% c(\"snappersnatcher7be\", \"roachrobberdb6\") ~ \"Vessel\",\n    TRUE ~ \"Location\"\n  ))\n\n# Create the plot\nssf_graph %&gt;% \n  activate(edges) %&gt;%\n  arrange(desc(weights)) %&gt;% \n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(color = \"\", \n                     linewidth = weights)) +\n  geom_node_point(aes(color = color, size = 10)) + \n  theme_graph() +\n  theme(\n    plot.background = element_rect(fill = \"white\", color = NA),\n    text = element_text(color = \"black\"))+\n  geom_node_text(aes(label = id), \n                 repel = TRUE, \n                 vjust = 1, \n                 hjust = 1,\n                 size = 3)\n\n\n\n\n\n\n\n\n\n\n3.1.1 When and where did SouthSeafood Express Corp vessels perform their illegal fishing?\nSince only Snapper Snatcher appears to be operating in Ghoti Preserve, we will examine this fishing vessel more closely.\n\n\nShow the code\nsnapper_activities &lt;- mc2_edges %&gt;% \n  filter(event3 == \"TransponderPing\") %&gt;% \n  filter(target %in% c(\"snappersnatcher7be\")) %&gt;% \n  filter(source == \"Ghoti Preserve\") %&gt;% \n  arrange(target,time) %&gt;% \n  mutate(end_time = time + dwell) %&gt;% \n  select(time, dwell, end_time)\nsnapper_activities\n\n\n                 time      dwell            end_time\n1 2035-02-02 05:39:59 282000.853 2035-02-05 12:00:00\n2 2035-02-09 05:49:11 281448.765 2035-02-12 12:00:00\n3 2035-02-16 07:02:09 277070.841 2035-02-19 12:00:00\n4 2035-03-15 05:46:02   6410.348 2035-03-15 07:32:52\n\n\nThere three instances (2,9 and 16 Feb) where Snapper Snatcher stayed at the Ghoti Preserve for over 3 days. These are the instances where SouthSeafood Express Corp’s Snapper Snatcher conducted IUU Fishing in Ghoti Preserve.\n\n\n3.1.2 Visualising Vessel Trajectory\nIn the code chunk below, st_as_sf() of sf package is used to convert vessel_movement_data data.frame into sf point data.frame by using values in XCOORD and YCOORD columns. The output is an sf data.frame called vessel_movement_sf.\n\n\nShow the code\nvessel_movement_sf &lt;- vessel_movement_data %&gt;%\n  st_as_sf(coords = c(\"XCOORD\", \"YCOORD\"), \n           crs = 4326)\n\n\nNext arrange() is used to sort the records according to the vessels’ name (i.e. target) and navigation time (i.e. time)\n\n\nShow the code\nvessel_movement_sf &lt;- vessel_movement_sf %&gt;%\n  arrange(target, time)\n\n\nLastly, st_cast() of sf package is used to convert vessel_movement_sf from point features into linestring features called vessel_trajectory.\n\n\nShow the code\nvessel_trajectory &lt;- vessel_movement_sf %&gt;%\n  group_by(target) %&gt;%\n  summarize(do_union = FALSE) %&gt;%\n  st_cast(\"LINESTRING\")\n\n\nSelecting SouthSeafood Express vessels\n\n\nShow the code\nvessel_trajectory_selected &lt;- vessel_trajectory %&gt;%\n  filter(target %in% c(\"snappersnatcher7be\", \"roachrobberdb6\"))\n\n\nNext, appropriate functions of ggplot2 is used to plot the selected vessel trajectories by using the code chunk below.\n\n\nShow the code\nggplot() +\n  geom_sf(data = oceanus_geography) +\n  geom_sf(data = vessel_trajectory_selected, \n          aes(color = factor(target)), \n          size = 1) +\n  theme_minimal() +\n  labs(title = \"Trajectories of SouthSeafood Express Vessels\", \n  x = \"Longitude\", y = \"Latitude\", color = \"ID\")"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#task-4",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#task-4",
    "title": "Take Home Exercise 3",
    "section": "4.0 Task 4",
    "text": "4.0 Task 4\nThe Questions:\n\nHow did fishing activity change after SouthSeafood Express Corp was caught?\nWhat new behaviors in the Oceanus commercial fishing community are most suspicious and why?\n\nIn order to understand the change in fishing activities, we first have to determine the date where SouthSeafood Express Corp was caught. We will use this timeline as the\nThe final activities of SouthSeafood’s vessels are on 2035-05-16 (snappersnatcher7be) and 2035-05-16 (roachrobberdb6) according to the transponder pings. Hence, we can conclude that the SouthSeafood is caught for illegal fishing, and had ceased operating its fishing vessels since 2035-05-16."
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#changes-in-commercial-fishing",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#changes-in-commercial-fishing",
    "title": "Take Home Exercise 3",
    "section": "4.1 Changes in Commercial Fishing",
    "text": "4.1 Changes in Commercial Fishing\nFirstly, we take a look at the species caught across the months (Feb to Nov 2035).\n\n\nShow the code\n# Create an overall Oceanus heat map for all types of fish\nfish_agg &lt;- fish_by_port_agg  %&gt;%\n  distinct() %&gt;%\n  group_by(name,month) %&gt;%\n  summarise(total_qty_ton = sum(total_qty_ton)) \n\noceanus_heatmap &lt;- ggplot(fish_agg, aes(x = month, y = name, fill = total_qty_ton)) +\n    geom_tile(color = \"white\") +\n    scale_fill_gradient(low = \"white\", high = \"blue\") +\n    labs(title = paste(\"Calendar Heatmap for fish in Oceanus\"),\n         x = \"Month of the Year\",\n         y = \"Fish Type\",\n         fill = \"Total Quantity (tons)\") +\n    theme_minimal() +\n  geom_vline(xintercept = \"May\",color = 'red', linetype = 'dashed') +\n  annotate(\"text\", x = \"May\" , y = \"Offidiaa\", label = \"SouthSeafood caught\", angle = 90, vjust = -0.5, hjust = 0.5, color = \"red\")\n\n\n\n\nShow the code\n# Order them based on 3 Preserves and 3 Fishing Ground\ndesired_order &lt;- c(\"Ghoti Preserve\", \"Nemo Reef\", \"Don Limpet Preserve\",\"Cod Table\", \"Wrasse Beds\",\"Tuna Shelf\")  \n\nregion_fish_species_long$Name &lt;- factor(region_fish_species_long$Name, levels = desired_order)\n\nspecies_plot &lt;-ggplot(region_fish_species_long, aes(x = Name, \n                                     y = Presence,\n                                     colour = Presence)) +\n  geom_point() +\n  labs(title = \"Species Presence by Name\",\n       x = \"Name\",\n       y = \"Species\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\")\n\n\n\n\nShow the code\noceanus_heatmap / species_plot\n\n\n\n\n\n\n\n\n\nFor recapitulation, we know that Sockfish, Offidiaa, and Helenaa are fish species that are unique to the three Preserves. From the two plots above, we can derive initial conclusion that there is an usual increase in Sockfish catch after SouthSeafood was caught in mid-May. We also see a minor increase in Helenaa between Jun to Aug, and later in Oct to Nov. The spike in Offidiaa catch begins in Sep and grows gradually to Nov.\nCombining the information above, we can make the following two hypothesis about the changes in fishing activities in Oceanus after SouthSeafood was caught:\n\nThe fishing vessels switched to Don Limpet Preserve for IUU fishing. Tell tale sign is the increase in Sockfish catch, which is species unique to Don Limpet Preserve. This also explains the slight increase in Helena catch from Jun.\nThe fishing vessels moved into Ghoti Preserves from Sep onwards for IUU fishing. Tell tale sign is the increase in Offidia catch from Sep, which is species unique to Ghoti Preserve.\n\nFor confirmation, we take a look at the changes to OVLS Transponder Ping, comparing the total pings to various Fishing Grounds and Preserves month by month.\n\n\nShow the code\ntransponder_ping_edge_long &lt;- transponder_ping_edge %&gt;% \n  filter(target %in% unlist(fishing_vessel_list)) %&gt;% \n  filter(source %in% c(\"Ghoti Preserve\", \n                       \"Nemo Reef\", \n                       \"Don Limpet Preserve\",\n                       \"Cod Table\", \n                       \"Wrasse Beds\",\n                       \"Tuna Shelf\")) %&gt;% \n  mutate(month = month(time)) %&gt;% \n  select(source, target, month) %&gt;% \n  group_by(source, month) %&gt;% \n  summarize(n = n()) \n\n\n\n\nShow the code\ntransponder_ping_edge_long %&gt;% \n  mutate(month = as.factor(month)) %&gt;% \n  newggslopegraph(month,n, source,\n                Title = \"Changes in Visit Frequency\",\n                SubTitle = \"across Feb to Nov 2035\",\n                Caption = \"Prepared by: Liang Xiuhao\")\n\n\n\n\n\n\n\n\n\nIn the line graph below, we observe that the overall fishing vessels activities in the fishing ground and preserves dropped.\n\n\nShow the code\naverage &lt;- transponder_ping_edge %&gt;% \n  filter(target %in% unlist(fishing_vessel_list)) %&gt;% \n  filter(source %in% c(\"Ghoti Preserve\", \n                       \"Nemo Reef\", \n                       \"Don Limpet Preserve\",\n                       \"Cod Table\", \n                       \"Wrasse Beds\",\n                       \"Tuna Shelf\")) %&gt;%\n  mutate(month = month(time)) %&gt;% \n  summarise(average = (n()/10))\n\ntransponder_ping_edge %&gt;% \n  filter(source %in% c(\"Ghoti Preserve\", \n                       \"Nemo Reef\", \n                       \"Don Limpet Preserve\",\n                       \"Cod Table\", \n                       \"Wrasse Beds\",\n                       \"Tuna Shelf\")) %&gt;%\n  filter(target %in% unlist(fishing_vessel_list)) %&gt;% \n  mutate(month = month(time)) %&gt;% \n  group_by(month) %&gt;% \n  summarise(n = as.numeric(n())) %&gt;%\n  ggplot(aes(x = month, y = n)) + \n  geom_line(color = \"blue\") +  \n  geom_point(size = 4, color = \"blue\") +\n  geom_text(aes(label = n), \n            vjust = -1,\n            size = 3) +\n  labs(title = \"Visit Frequency to All Fishing Grounds and Preserves by Month\",\n       x = \"Month\",\n       y = \"Frequency\") +\n  geom_hline(average, \n             yintercept = as.numeric(average), \n             color=\"black\",\n             linetype = 6) +\n  geom_point(x = 5, y = 13366,\n             size = 4, color = \"red\") +\n  geom_text(aes(x = 5, y = 13366, label = \"SouthSeafood caught\"),\n            color = \"red\",\n            hjust = -0.2,\n            size = 3) +\n  geom_text(aes(x = 4.5, y = 12000, label = \"Monthly Average = 11854\"),\n            color = \"black\",\n            size = 3) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nDerive monthly transponder ping:\n\n\nShow the code\nmonthly_transponder_ping &lt;- transponder_ping_edge %&gt;% \n  filter(target %in% unlist(fishing_vessel_list)) %&gt;% \n  filter(source %in% c(\"Ghoti Preserve\", \n                       \"Nemo Reef\", \n                       \"Don Limpet Preserve\",\n                       \"Cod Table\", \n                       \"Wrasse Beds\",\n                       \"Tuna Shelf\")) %&gt;% \n  mutate(month = month(time)) %&gt;% \n  select(source, target, month) %&gt;% \n  group_by(source, month) %&gt;% \n  summarize(n = n()) \n\n\n\n\nShow the code\nmonthly_transponder_ping$month &lt;- factor(monthly_transponder_ping$month)\nmonthly_transponder_ping$source &lt;- factor(monthly_transponder_ping$source,\n                                             levels = c(\"Ghoti Preserve\", \n                                                        \"Nemo Reef\",\n                                                        \"Don Limpet Preserve\",\n                                                        \"Cod Table\",\n                                                        \"Wrasse Beds\",\n                                                        \"Tuna Shelf\"))\n\nhline.data &lt;- monthly_transponder_ping %&gt;% \n  group_by(source) %&gt;%\n  summarise(avgvalue = mean(n))\n\nggplot(monthly_transponder_ping , aes(x = month, \n                                      y = n, \n                                      group = source, \n                                      color = source)) +\n  geom_line(size = 1) +\n  geom_point(size = 2) +\n  facet_wrap(~ source, scales = \"free_y\") +  # Facet by 'source'\n  theme_minimal() +\n  labs(title = \"Changes in Visit Frequency by Month by Fishing Vessels\",\n       x = \"Month\",\n       y = \"No. of Visits\",\n       color = \"Source\") +\n  geom_hline(data = hline.data,\n             aes(yintercept = avgvalue),\n             linetype = 6,\n             color = \"black\",\n             size = 0.5) +\n  geom_text(data = hline.data, \n            aes(x = \"4\", y = avgvalue, label = \"Average\"), \n            hjust = 1, vjust = 1, \n            color = \"black\",\n            size = 3) +\n  geom_vline(aes(xintercept = 4),\n             linetype = 6,\n             color = \"red\",\n             size = 0.5) +\n  geom_text(data = hline.data, \n            aes(x = \"4\", y = avgvalue, label = \"SouthSeafood caught\"), \n            hjust = 1.5, vjust = 1.5,\n            angle = 90,\n            color = \"red\",\n            size = 2)\n\n\n\n\n\n\n\n\n\nFrom the plot above, we can see that after SouthSeafood was caught in mid-May, there is a drop in activities for all the fishing grounds and preserves immediately after mid-May, except for the increase in Don Limpet Preserve, from 1 in Mar and Jun to 2 observations in Aug.\nLet’s observe for month to month if the dwell time increase for Don Limpet Preserve.\n\n\nShow the code\ndon_monthly_transponder_ping &lt;- transponder_ping_edge %&gt;% \n  filter(target %in% unlist(fishing_vessel_list)) %&gt;% \n  select(source, dwell, time) %&gt;% \n  mutate(month = month(time)) %&gt;% \n  filter(source == \"Don Limpet Preserve\") %&gt;%\n  group_by(month) %&gt;% \n  summarise(dwell_total = sum(dwell)) %&gt;%\n  ggplot(aes(x = month, y = dwell_total)) + \n  geom_line(color = \"blue\") +\n  labs(title = \"Dwell Time in Don Limpet by Month\",\n       x = \"Month\",\n       y = \"Total Count\") +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE,\n              linetype = 6,\n              color = \"black\") +\n  geom_text(data = NULL, aes(label = \"Trend Line\"), \n            x = 6, y = 7500, \n            angle = 15,\n            hjust = -0.3, vjust = -1.5, \n            color = \"black\", size = 4)\n\n\n\n\nShow the code\nnemo_monthly_transponder_ping &lt;- transponder_ping_edge %&gt;% \n  filter(target %in% unlist(fishing_vessel_list)) %&gt;% \n  select(source, dwell, time) %&gt;% \n  mutate(month = month(time)) %&gt;% \n  filter(source == \"Nemo Reef\") %&gt;%\n  group_by(month) %&gt;% \n  summarise(dwell_total = sum(dwell)) %&gt;%\n  ggplot(aes(x = month, y = dwell_total)) + \n  geom_line(color = \"blue\") +\n  labs(title = \"Dwell Time in Nemo Reef by Month\",\n       x = \"Month\",\n       y = \"Total Count\") +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE,\n              linetype = 6,\n              color = \"black\") +\n  geom_text(data = NULL, aes(label = \"Trend Line\"), \n            x = 5, y = 12500000, \n            angle = -15,\n            hjust = 0.3, \n            color = \"black\", size = 4)\n\n\n\n\nShow the code\nghoti_monthly_transponder_ping &lt;- transponder_ping_edge %&gt;% \n  filter(target %in% unlist(fishing_vessel_list)) %&gt;% \n  select(source, dwell, time) %&gt;% \n  mutate(month = month(time)) %&gt;% \n  filter(source == \"Ghoti Preserve\") %&gt;%\n  group_by(month) %&gt;% \n  summarise(dwell_total = sum(dwell)) %&gt;%\n  ggplot(aes(x = month, y = dwell_total)) + \n  geom_line(color = \"blue\") +\n  labs(title = \"Dwell Time in Ghoti by Month\",\n       x = \"Month\",\n       y = \"Total Count\") +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE,\n              linetype = 6,\n              color = \"black\") +\n  geom_text(data = NULL, aes(label = \"Trend Line\"), \n            x = 8, y = 5000000, \n            angle = -5, \n            color = \"black\", size = 4)\n\n\n\n\nShow the code\nnemo_monthly_transponder_ping/ghoti_monthly_transponder_ping\n\n\n\n\n\n\n\n\n\nFrom the above plots, we observe that for Nemo Reef and Ghoti Preserve, the trend is downwards for the amount of time spent by the fishing vessels.\n\n\nShow the code\ndon_monthly_transponder_ping\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nfishing_vessels_in_don &lt;- transponder_ping_edge %&gt;% \n  filter(source == \"Don Limpet Preserve\") %&gt;% \n  filter(target %in% unlist(fishing_vessel_list)) %&gt;% \n  select(target, dwell, date_added, time) %&gt;% \n  mutate(end_time = dwell + time) %&gt;% \n  arrange(time)\nfishing_vessels_in_don\n\n\n                   target    dwell          date_added                time\n1    yellowperchpiratec59 7413.772 2035-03-04 16:50:54 2035-03-03 16:50:54\n2 arcticgraylingangler094 5037.287 2035-06-20 06:00:00 2035-06-18 06:00:00\n3    whitefishwrangler7df 6149.014 2035-06-20 06:00:00 2035-08-18 06:00:00\n4       bluegillbandita5f 4571.235 2035-08-29 06:00:00 2035-08-27 06:00:00\n             end_time\n1 2035-03-03 18:54:28\n2 2035-06-18 07:23:57\n3 2035-08-18 07:42:29\n4 2035-08-27 07:16:11\n\n\nThere are only 4 records of visits through the OVLS to Don Limpet, once in Mar and Jun, for about 1.5 to 2hrs each, and another 2 in Aug, for about 1.25 to 1.75 hrs each. These record is high incongruent to the growing number of Sockfish that are found in the delivery report from May onwards.\n\n4.2 What new behaviors in the Oceanus commercial fishing community are most suspicious and why?"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#wrangling-of-geographical-data",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#wrangling-of-geographical-data",
    "title": "Take Home Exercise 3",
    "section": "1.2.2 Wrangling of Geographical Data",
    "text": "1.2.2 Wrangling of Geographical Data\nIn the code chunk below, st_coordinate() of sf package is used to extract coordinates from oceanus_locations sf data.frame.\n\n\nShow the code\ncoords &lt;- st_coordinates(oceanus_locations)\n\n\nNext, code chunk below is used to drop the geometry column of oceanus_locations of sf data.frame by using st_drop_geometry() of sf package and save the output into a new data.frame called oceanus_locations_df.\n\n\nShow the code\noceanus_locations_df &lt;- oceanus_locations %&gt;%\n  st_drop_geometry()\n\n\nThen, the code chunk below is to append the x- and y-coodinate values from coords list into the XCOORD and YCOORD columns of oceanus_locations_df respectively.\n\n\nShow the code\noceanus_locations_df$XCOORD &lt;- coords[, \"X\"]\noceanus_locations_df$YCOORD &lt;- coords[, \"Y\"]\n\n\nLastly, the code chunk below is used to tidy OceanusLocations_df by selecting the necessary columns only and at the same time, rename X.Kind to Loc_Type.\n\n\nShow the code\noceanus_locations_df &lt;- oceanus_locations_df %&gt;%\n  select(Name, X.Kind, XCOORD, YCOORD) %&gt;%\n  rename(Loc_Type = X.Kind)"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#exploratory-data-analysis",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#exploratory-data-analysis",
    "title": "Take Home Exercise 3",
    "section": "1.6 Exploratory Data Analysis",
    "text": "1.6 Exploratory Data Analysis\n\n1.6.1 Understanding the nodes and edges data\nIn this section, we will gain more insights from the existing data. The table below summarises the type of data we can glean from the nodes and edges:\n\n\n\n\n\n\n\n\nmc2_nodes Type\nEntity\nDetails\n\n\n\n\nCommodity\nFish\n10 x Fish Species\n\n\n\nLocation\n\nCity\nPoint\nRegion\n\n6 x City\n\n12 x Point\n\n6 x Region\n\n3 x Ecological Preserves\n3 x Fishing Ground\n\n\n\n\nDocument\nDelivery Report\n5,307 unique cargoes, with qty_ton and date (of delivery)\n\n\nVessels\n\nFishing Vessels\nCargo Vessels\nFerry Cargo\nFerry Passenger\nResearch\nTour\nOthers\n\n296 x Vessels\n\n178 x Fishing Vessels\n100 x Cargo Vessels\n2 x Cargo Ferry\n3 x Passenger Ferry\n2 x Research Vessels\n6 x Tour Vessels\n5 x Other Vessels\n\n\n\n\n\n\n\n\n\n\n\nmc2_edges type\nCount (n)\n\n\n\n\nTransponder Ping\n258,542 x Pings\n\n\nTransaction\n10,614 x Transactions (matching 5,307 unique cargoes to fish species and city)\n\n\nHarbor Report\n 2,487 x Sightings\n\n\n\n\n\n1.6.2 Understanding the Fish Species in each Region\n\n\nShow the code\nregion_fish_species &lt;- mc2_nodes %&gt;% \n  filter(entity3 == \"Region\") %&gt;% \n  select(Name, fish_species_present, Activities, kind)\n\n\n\n\nShow the code\nword_list &lt;- strsplit(region_fish_species$fish_species_present, \"\\\\,\")\n\nmax_elements &lt;- max(lengths(word_list))\n\nword_list_padded &lt;- lapply(word_list, \nfunction(x) c(x, rep(NA, max_elements - length(x))))\n\nword_df &lt;- do.call(rbind, word_list_padded)\ncolnames(word_df) &lt;- paste0(\"species\", 1:max_elements) \n\nword_df &lt;- as_tibble(word_df) %&gt;% \n  mutate(species1 = str_replace(species1, \"/.*\", \"\")) %&gt;% \n  mutate(species2 = str_replace(species2, \"/.*\", \"\")) %&gt;% \n  mutate(species3 = str_replace(species3, \"/.*\", \"\")) %&gt;% \n  mutate(species4 = str_replace(species4, \"/.*\", \"\")) %&gt;% \n  mutate(species5 = str_replace(species5 , \"/.*\", \"\")) %&gt;%\n  mutate_at(vars(species1:species5), trimws)\n\nregion_fish_species &lt;- region_fish_species %&gt;%\n  cbind(word_df)\n\n# Convert data to long format\nregion_fish_species_long &lt;- pivot_longer(region_fish_species, cols = starts_with(\"species\"), names_to = \"Species\", values_to = \"Presence\")\n\n# Filter out empty values and trim away leading and trailing whitespace\nregion_fish_species_long &lt;- region_fish_species_long[region_fish_species_long$Presence != \"\", ] %&gt;% \n  na.omit() %&gt;%\n  mutate_at(vars(Presence), trimws)\n\n\n\n\nShow the code\n# Order them based on 3 Preserves and 3 Fishing Ground\ndesired_order &lt;- c(\"Ghoti Preserve\", \"Nemo Reef\", \"Don Limpet Preserve\",\"Cod Table\", \"Wrasse Beds\",\"Tuna Shelf\")  \n\nregion_fish_species_long$Name &lt;- factor(region_fish_species_long$Name, levels = desired_order)\n\nggplot(region_fish_species_long, aes(x = Name, \n                                     y = Presence,\n                                     colour = Presence)) +\n  geom_point() +\n  labs(title = \"Species Presence in each Region\",\n       x = \"Region\",\n       y = \"Species\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from this visualisation\n\n\n\nWe can derive that Sockfish, Offidiaa, and Helenaa species can only be found in the preserves but not in the fishing grounds. Therefore, any cargoes that contains these fish species would have fished illegally. Below shows the visualisation of the species and qty_ton that flows through each city by months."
  }
]