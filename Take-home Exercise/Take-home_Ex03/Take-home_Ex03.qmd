---
title: "Take Home Exercise 3"
author: "Rydia"
date: "May 13, 2024"
date-modified: "last-modified"
execute:
  eval: true
  echo: true
  warning: false
  freeze: true
---

# VAST 2024 Mini Challenge 2: Task 1

## Mini-Challenge 2: Creating Signatures for Geo-Temporal Patterns

Mini-challenge 2 focuses on analyzing ship movements and shipping records to understand illegal fishing practices. FishEye analysts need help creating visualizations to show patterns of ship movements and identify suspicious behaviors. They also want to understand how the commercial fishing community changed after a company was caught fishing illegally.

The details of the mini challenge can be found [here](https://vast-challenge.github.io/2024/MC2.html).

## Tasks and Questions

FishEye analysts need your help to perform geographic and temporal analysis of the CatchNet data so they can prevent illegal fishing from happening again. Your task is to develop new visual analytics tools and workflows that can be used to discover and understand signatures of different types of behavior. Can you use your tool to visualize a signature of SouthSeafood Express Corp’s illegal behavior? FishEye needs your help to develop a workflow to find other instances of illegal behavior.

1.  FishEye analysts have long wanted to better understand the flow of commercially caught fish through Oceanus’s many ports. But as they were loading data into CatchNet, they discovered they had purchased the wrong port records. They wanted to get the ship off-load records, but they instead got the port-exit records (essentially trucks/trains leaving the port area). Port exit records do not include which vessel that delivered the products. Given this limitation, develop a visualization system to associate vessels with their probable cargos. Which vessels deliver which products and when? What are the seasonal trends and anomalies in the port exit records?

## 1.0 Data Preparation

## 1.1 Loading R Packages

```{r}
pacman::p_load(tidyverse, jsonlite, DT, lubridate,
               igraph, tidygraph, ggraph, 
               visNetwork)
```

## 1.2 Loading the Data

Loading the .json data using `jsonlite` package.

```{r}
mc2 <- fromJSON("data/MC2/mc2.json")
```

mc2 is a directed multigraph, consists of nodes dataframe and links dataframe.

```{r}
mc2
```

## 1.3 Extracting the nodes and links dataframes

## 1.3 Extracting the tibbles for nodes and links

```{r}
mc2_nodes_raw <- as_tibble(mc2$nodes)
```

```{r}
mc2_links_raw <- as_tibble(mc2$links)
```

## 1.4 Checking for missing values in data

```{r}
colSums(is.na(mc2_nodes_raw))
```

```{r}
colSums(is.na(mc2_links_raw))
```

## 1.5 Parsing the time with lubridate

As the `_date_added` and `_last_edited_date` contains a mixture of format, we first extract the date in "yyyy-mm-dd" format using `substr`.

```{r}
mc2_nodes_raw <- mc2_nodes_raw |> 
  mutate(`_date_added` = substr(`_date_added`,1,10)) |> 
  mutate(`_date_added` = ymd(`_date_added`)) |> 
  mutate(`_last_edited_date` = substr(`_last_edited_date`,1,10)) |> 
  mutate(`_last_edited_date` = ymd(`_last_edited_date`)) |> 
  mutate(date = ymd(date))
mc2_nodes_raw
```

```{r}
lengths <- nchar(mc2_links_raw$`_date_added`)
has_length_19 <- ifelse(lengths == 19, TRUE, FALSE)

if(any(has_length_19)){
  mc2_links_raw <- mc2_links_raw |> 
    mutate(`_date_added` = ymd(`_date_added`)) |> 
    mutate(`_last_edited_date` = ymd(`_last_edited_date`))
} else{
  mc2_links_raw <- mc2_links_raw |>
    mutate(`_date_added` = ymd_hms(`_date_added`)) |> 
    mutate(`_last_edited_date` = ymd_hms(`_last_edited_date`)) 
}
  

mc2_links_raw <- mc2_links_raw |> 
    mutate(time = ymd_hms(time))
mc2_links_raw
```

::: callout-note
Although there is a warning given: 13101 failed to parse for both `_date_added` and `_last_edited_date`, it was caused by the missing values as verified in
:::

```{r}
unique_nodes_type <- mc2_nodes_raw %>% distinct(type)
unique_nodes_type
```

```{r}

unique_links_type <- mc2_links_raw %>% distinct(type)
unique_links_type
```

## 1.5 Extracting the required columns for each graph

In this section, we will extract the required column for the following graphs:

1.  Vessel Movements

2.  Harbor Reports

3.  Harbor Import Records

### 1.5.1 Vessel Movements

For vessel movements, we require the node/links types as such:

-   Entity.Vessel:
    -   Entity.Vessel.FishingVessel,
    -   Entity.Vessel.Other ,
    -   Entity.Vessel.Ferry.Passenger,
    -   Entity.Vessel.CargoVessel,
    -   Entity.Vessel.Ferry.Cargo,
    -   Entity.Vessel.Research,
    -   Entity.Vessel.Tour
-   Entity.Location:
    -   Entity.Location.Region,
    -   Entity.Location.City,
    -   Entity.Location.Point
-   Event.TransponderPing:
    -   Event.TransportEvent.TransponderPing

For the Node Type, we will preserve the following fields:

-   Entity.Vessel: Description of the vessel

    -   Name

    -   company: Company that owns the vessel

    -   flag_country: Country the vessel is licensed in

    -   length_overall: meters length of the vessel

    -   tonnage: Gross tonnage of the vessel

```{r}
vessel_description <- c("Name","company", "flag_country","length_overall","tonnage")
```

-   Entity.Location: Description of a geographic location

    -   Name

    -   Activities: List of common activities in the region

    -   Description: Textual description

    -   fish_species_present: List of fish common found in that area

    -   kind: High-level grouping (city/preserve/etc.)

```{r}
location_description <- c("Name","Activities","Description","fish_species_present","kind")
```

For the Edge Types, we will preserve the following fields:

-   Event.TransponderPing: Links a vessel to a location via OVLS

    -   time: Start time of the visit

    -   dwell: How long was the vessel in this location

```{r}
ping_info <- c("time","dwell")
```

```{r}
vessel_mvmt_nodes <- mc2_nodes_raw |> 
  filter(str_detect(type,c("Vessel|Location"))) |> 
  select("Name","company","flag_country","length_overall",
           "tonnage","Activities","Description",
           "fish_species_present","kind")
```

```{r}
vessel_mvmt_links <- mc2_links_raw |> 
  filter(type == "Event.TransportEvent.TransponderPing") |> 
  select("source","target","_date_added","time","dwell")
```

```{r}
vessel_mvmt_links
```

### 2.0

```{r}
mc2_nodes_raw <- mc2_nodes_raw %>%
  mutate(id = as.character(id),
         type = as.character(type),
         name = as.character(name)
         )
mc2_nodes_raw
```

```{r}
mc2_links_raw <- mc2_links_raw %>%
  distinct() %>%
  mutate(source = as.character(source),
         target = as.character(target), 
         type = as.character(type)) %>%
  group_by(source, target, type) %>%
  summarise(weights = n()) %>%
  filter(source != target) %>%
  ungroup()
mc2_links_raw
```

```{r}
mc2_links_raw_source_freq <- mc2_links_raw %>%
  group_by(source) %>%
  summarise(freq_cnt = n()) %>%
  arrange(desc(freq_cnt)) %>%
  ungroup()

mc2_links_raw_source_freq
```

```{r}
mc2_links_raw_target_freq <- mc2_links_raw %>%
  group_by(target) %>%
  summarise(freq_cnt = n()) %>%
  arrange(desc(freq_cnt)) %>%
  ungroup()

mc2_links_raw_target_freq
```
