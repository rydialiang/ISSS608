---
title: "Take Home Exercise 3"
author: "Rydia"
date: "May 13, 2024"
date-modified: "last-modified"
execute:
  eval: true
  echo: true
  warning: false
  freeze: true
---

# VAST 2024 Mini Challenge 2

## Mini-Challenge 2: Creating Signatures for Geo-Temporal Patterns

Mini-challenge 2 focuses on analyzing ship movements and shipping records to understand illegal fishing practices. FishEye analysts need help creating visualizations to show patterns of ship movements and identify suspicious behaviors. They also want to understand how the commercial fishing community changed after a company was caught fishing illegally.

The details of the mini challenge can be found [here](https://vast-challenge.github.io/2024/MC2.html).

## Tasks and Questions

FishEye analysts need your help to perform geographic and temporal analysis of the CatchNet data so they can prevent illegal fishing from happening again. Your task is to develop new visual analytics tools and workflows that can be used to discover and understand signatures of different types of behavior. Can you use your tool to visualize a signature of SouthSeafood Express Corp’s illegal behavior? FishEye needs your help to develop a workflow to find other instances of illegal behavior.

1.  FishEye analysts have long wanted to better understand the flow of commercially caught fish through Oceanus’s many ports. But as they were loading data into CatchNet, they discovered they had purchased the wrong port records. They wanted to get the ship off-load records, but they instead got the port-exit records (essentially trucks/trains leaving the port area). Port exit records do not include which vessel that delivered the products. Given this limitation, develop a visualization system to associate vessels with their probable cargos. Which vessels deliver which products and when? What are the seasonal trends and anomalies in the port exit records?

2.  Develop visualizations that illustrate the inappropriate behavior of SouthSeafood Express Corp vessels. How do their movement and catch contents compare to other fishing vessels? When and where did SouthSeafood Express Corp vessels perform their illegal fishing? How many different types of suspicious behaviors are observed? Use visual evidence to justify your conclusions.

3.  To support further Fisheye investigations, develop visual analytics workflows that allow you to discover other vessels engaging in behaviors similar to SouthSeafood Express Corp’s illegal activities? Provide visual evidence of the similarities.

4.  How did fishing activity change after SouthSeafood Express Corp was caught? What new behaviors in the Oceanus commercial fishing community are most suspicious and why?

## 1.0 Data Preparation

## 1.1 Loading R Packages

```{r}
pacman::p_load(tidyverse, jsonlite, DT, lubridate,
               igraph, tidygraph, ggraph, 
               visNetwork, sf,
               patchwork, CGPfunctions,
               ggHoriPlot)
```

## 1.2 Loading the Data

Loading the .json data using `jsonlite` package.

```{r}
mc2_data <- fromJSON("data/MC2/mc2.json")
```

mc2 is a directed multigraph, consists of nodes dataframe and links dataframe.

```{r}
oceanus_map <- read_sf("data/MC2/Oceanus Information/Oceanus Geography.geojson")
```

Loading the oceanus map:

```{r}
ggplot(oceanus_map) +
  geom_sf(color = "black",
          ) +
  theme_void() +
  geom_sf_text(aes(label = Name), size = 2,
               vjust = 1.5)
```

## 1.3 **Wrangling and tidying edges**

### 1.3.1 Extracting edges

First, we extract only distinct edges from the tibble *links* data.frame of *mc2_data* and save it as a tibble data.frame called *mc2_edges*.

```{r}
mc2_edges <- mc2_data$links %>% 
  distinct()
```

Next, `glimpse()` of dplyr will be used to reveal the structure of *mc2_edges* tibble data.table.

```{r}
glimpse(mc2_edges)
```

From the table above, we can identify some issues with the data:

1.  The columns with date data type are all in character format.

2.  Some columns have names that starts with "\_". These need to be rename to avoid coding issues.

### 1.3.2 Correcting the date data type with `lubridate()`

```{r}
mc2_edges$time <- as_datetime(mc2_edges$time)
mc2_edges$`_last_edited_date` <- as_datetime(mc2_edges$`_last_edited_date`)
mc2_edges$`_date_added` <- as_datetime(mc2_edges$`_date_added`)
mc2_edges$date <- as_datetime(mc2_edges$date)
```

Next, glimpse() will be used to confirm if the process have been performed correctly.

```{r}
glimpse(mc2_edges)
```

### 1.3.3 Changing field name

In the code chunk below, rename() of dplyr package is used to change the following fields.

```{r}
mc2_edges <- mc2_edges %>%
  rename("last_edited_by" = "_last_edited_by",
         "date_added" = "_date_added",
         "last_edited_date" = "_last_edited_date",
         "raw_source" = "_raw_source",
         "algorithm" = "_algorithm") 
```

### 1.3.4 Splitting words in `type` column

The code chunk below combined the following steps:

1.  Splitting the words by "." - after observing that the format for type is as such: "Event.TransportEvent.TransponderPing"

2.  The `max(lengths(word_list))` will be used to find the maximum number of elements in any split.

3.  Apply function(x) to pad shorter splits with NA values to make them all the same length.

4.  Create word_df and changing column names to event1 etc.

5.  Convert word_df from matrix into tibble data.frame, and checks its class.

6.  Append word_df to mc2_edges tibble data.frame.

7.  Saving mc2_edges into R **rds** format as a physical file, so that there is no need to repeat the following code chunk to access a tidy mc2_edges tibble data frame.

```{r}
word_list <- strsplit(mc2_edges$type, "\\.")

max_elements <- max(lengths(word_list))

word_list_padded <- lapply(word_list, 
function(x) c(x, rep(NA, max_elements - length(x))))

word_df <- do.call(rbind, word_list_padded)
colnames(word_df) <- paste0("event", 1:max_elements)

word_df <- as_tibble(word_df) %>%
  select(event2, event3)
class(word_df)

mc2_edges <- mc2_edges %>%
  cbind(word_df)

# prior to running this code, create an rds folder in data folder to ensure files are saved in the correct directory
write_rds(mc2_edges, "data/rds/mc2_edges.rds")

```

## 1.4 **Wrangling and tidying nodes**

### 1.4.1 Extracting nodes

The code chunk below will be used to extract the nodes data.frame of mc2_data and parses it as a tibble data.frame called mc2_nodes.

```{r}
mc2_nodes <- as_tibble(mc2_data$nodes) %>%
  distinct()
```

Next, take a `glimpse()` to understand the data structure.

```{r}
glimpse(mc2_nodes)
```

From the table above, beside the date data type, inappropriate field name, and treatment for `type` column issues we discussed earlier, two additional data issues can be observed. They are:

-   The values in Activities and fish_species_present fields are in **list** data type, which will affect the ability to process and to analyse the data.

-   Some values in the Activities field are not ready to be analyse without further tidying (i.e. removing c(““)).

We will first repeat the steps similar steps to wrangling the mc2_edges, before proceeding to tackle the issues for Activities and fish_species_present field.

### 1.4.2 Correcting the date data type with `lubridate()`

Correct the date data type and take a `glimpse()` to confirm changes.

```{r}
mc2_nodes$`_last_edited_date` <- as_datetime(mc2_nodes$`_last_edited_date`)
mc2_nodes$`_date_added` <- as_datetime(mc2_nodes$`_date_added`)
mc2_nodes$date <- as_datetime(mc2_nodes$date)
glimpse(mc2_nodes)
```

### 1.4.3 Changing field name

In the code chunk below, rename() of dplyr package is used to change the following fields.

```{r}
mc2_nodes <- mc2_nodes %>%
  rename("last_edited_by" = "_last_edited_by",
         "date_added" = "_date_added",
         "last_edited_date" = "_last_edited_date",
         "raw_source" = "_raw_source",
         "algorithm" = "_algorithm") 
```

### 1.4.4 Splitting words in `type` column

Details on the code chunk can be found in section 1.3.4. At this point, we will not be saving the mc2_nodes as R **rds** format yet, as there are more works to be done to clean up the dataframe.

```{r}
word_list <- strsplit(mc2_nodes$type, "\\.")

max_elements <- max(lengths(word_list))

word_list_padded <- lapply(word_list, 
function(x) c(x, rep(NA, max_elements - length(x))))

word_df <- do.call(rbind, word_list_padded)
colnames(word_df) <- paste0("entity", 1:max_elements)

word_df <- as_tibble(word_df) %>%
  select(entity2, entity3)
class(word_df)

mc2_nodes <- mc2_nodes %>%
  cbind(word_df)
```

### 1.4.5 Tidying text field

Using `mutate()` of dplyr and `gsub()` of Base R to tidy up the values in the cell. Essentially, the unwanted characters like `c`, `(`, `)`, and `\` are removed by substituting with empty value `""` for both Activities and fish_species_present columns. What is left in the columns will be characters separated by `,`.

```{r}
mc2_nodes <- mc2_nodes %>%
  mutate(Activities = gsub("c[(]", "", Activities)) %>% 
  mutate(Activities = gsub("\"", "", Activities)) %>%
  mutate(Activities = gsub("[)]", "", Activities)) 
```

```{r}
mc2_nodes <- mc2_nodes %>%
  mutate(fish_species_present = gsub("c[(]", "", fish_species_present)) %>% 
  mutate(fish_species_present = gsub("\"", "", fish_species_present)) %>%
  mutate(fish_species_present = gsub("[)]", "", fish_species_present)) 
```

Lastly, we will save the tidied mc2_nodes

```{r}
# prior to running this code, create an rds folder in data folder to ensure files are saved in the correct directory
write_rds(mc2_nodes, "data/rds/mc2_nodes.rds")
```

## 1.5 Extracting the required columns for each graph

In this section, we will extract the required column for the following graphs:

1.  Vessel Movements

2.  Harbor Reports

3.  Harbor Import Records

### 1.5.1 Vessel Movements

**Vessel Movements:** Oceanus is outfitted with a transponder/ping system named the Oceanus Vessel Locator System (OVLS).  Vessels are outfitted with a transponder and periodic 'pings' from base-stations results in a report of vessel locations at any time.  The raw ping granularity is at the minute-level but post-processing has converted it into visit/dwell times. OVLS is generally reliable, though vessel records may be missing for a variety of reasons.

Node/Edge types and properties present

1.  Entity.Vessel: Description of the vessel
2.  Entity.Location: Description of a geographic location
3.  Event.TransponderPing: Links a vessel to a location

First, we will extract the relevant nodes, namely the vessels and locations from `mc2_nodes`. As we are only concerned about the fishing vessels, we will only extract values matching "Vessel" in entity2 column and values matching "FishingVessel" in entity3 column. For locations, we will match values of "Location" in entity2 column, and match values of "City", "Point" and "Region" in entity3 column.

```{r}
vessel_mvmt_nodes <- mc2_nodes %>% 
  filter(entity2 %in% c("Vessel","Location")) %>% 
  filter(entity3 %in% c("FishingVessel","City","Point","Region"))
```

Next, we will extract the vessel movement edges from mc2_edges, by filtering the "TransponderPing" from event3 column.

```{r}
vessel_mvmt_edges <- mc2_edges %>% 
  filter(event3 %in% c("TransponderPing"))
```

### 1.5.2 Harbor Reports

**Harbor Reports:** Harbor masters regularly report the vessels found in their purview anytime during the day.  This data is derived from a different system than OVLS (see "Vessel Movements"), though the data overlaps.  Harbor Reports are provided on a different schedule from different harbors. Since no harbor reports every day, this data has lower temporal granularity than vessel movement data. Additionally, the Harbor Master is also responsible for proximate navigational beacon(s), so this data has lower spatial granularity as well.  However, the list of vessels observed is considered canonical.

Node/edge types present:

1.  Entity.Vessel

2.  Entity.location

3.  Event.HarborReport

Since the node type are the same as the vessel movements, we will make a copy of the node from vessel movement nodes.

```{r}
harbor_report_nodes <- vessel_mvmt_nodes
```

Next, we will extract the harbor report edges from mc2_edges, by filtering the "HarborReport" from event3 column.

```{r}
harbor_report_edges <- mc2_edges %>% 
  filter(event2 %in% c("HarborReport"))
```

### 1.5.3 Harbor Import Records

**Harbor Import Records**: Vessels deliver cargo to the ports, and that cargo is brought into Oceanus.  These records reflect the goods that \*leave\* the harbor to go to businesses in Oceanus or to be exported.  It was filtered pre-ingest to focus on the delivery of raw fish.  Because it is raw, fish leave the port quickly (generally one day after delivery).  Due to clerical error, the records purchased by FishEye do not include the vessel that delivered the cargo.

Node/Edge types present:

1.  Entity.location

2.  Entity.Commodity.Fish

3.  Entity.Document.DeliveryReport

4.  Event.Transaction

First, we will extract the relevant nodes, namely the location, commodity.fish and document.delivery report from `mc2_nodes`.

```{r}
harbor_import_records_nodes <- mc2_nodes %>% 
  filter(entity2 %in% c("Location","Commodity","Document"))
```

Next, we will extract harbor import records edges, by filtering the event2 with value of "Transaction".

```{r}
harbor_import_records_edges <- mc2_edges %>% 
  filter(event2 == "Transaction")
```

Before we move on to exploring the data, we will save the 3 sources edges and nodes tibble data frame as R **rds** format in the data/rds folder:

```{r}
write_rds(vessel_mvmt_nodes, "data/rds/vessel_mvmt_nodes.rds")
write_rds(vessel_mvmt_edges, "data/rds/vessel_mvmt_edges.rds")
write_rds(harbor_report_nodes, "data/rds/harbor_report_nodes.rds")
write_rds(harbor_report_edges, "data/rds/harbor_report_edges.rds")
write_rds(harbor_import_records_nodes, "data/rds/harbor_import_records_nodes.rds")
write_rds(harbor_import_records_edges, "data/rds/harbor_import_records_edges.rds")
```

## 2.0 Task 1: Flow of Commercially Caught Fish

In this section, we focus on a few key areas to understand how the commercially caught fish flows from the vessels through the various ports:

1.  Associating the vessels with their probable cargoes
2.  Which vessels deliver which products and when?
3.  Examine the seasonal trends and anomalies in the port exit records

## 2.1 Associating the vessels with their probable cargoes

To find out which commodity goes to which ports, we first create a cargo list that links the cargo to the cities and commodities. At the same time, we also clean up the name of the fish, leaving only its common name in the "name" column, by removing all the characters after the "/".

```{r}
cargo_port_list <- harbor_import_records_edges %>% 
  select(source,target) %>% 
  filter(target %in% c("City of Haacklee",
                       "City of Lomark",
                       "City of Himark",
                       "City of Paackland",
                       "City of South Paackland",
                       "City of Port Grove"))

cargo_commodity_list <- harbor_import_records_edges %>% 
  select(source,target) %>% 
  filter(!target %in% c("City of Haacklee",
                       "City of Lomark",
                       "City of Himark",
                       "City of Paackland",
                       "City of South Paackland",
                       "City of Port Grove")) %>% 
  rename(commodity = target)

cargo_list <- cargo_port_list %>% 
  left_join(cargo_commodity_list) %>%
  left_join(harbor_import_records_edges) %>% 
  select(source, target, commodity, date) %>% 
  rename(cargo = source, city = target) 

cargo_list<- harbor_import_records_nodes %>% 
  rename(commodity = id) %>% 
  select(name, commodity) %>% 
  left_join(cargo_list) %>% 
  mutate(name = str_replace(name, "/.*", ""))

cargo_list<- harbor_import_records_nodes %>% 
  select(id,qty_tons) %>% 
  rename(cargo = id) %>% 
  left_join(cargo_list,
            unmatched = "drop") %>%
  filter(if_all(c(qty_tons), ~ !is.na(.)))
```

**Matching the vessel with the cargo list** 

We first single out all the fishing vessels from mc2_edges and define the fishing vessel location, start time and end time of the vessels in the particular location. 

```{r}
fishing_vessel_list <- mc2_nodes %>% 
  filter(entity3 == "FishingVessel") %>% 
  select(id) 

fishing_vessel_list <- as.list(fishing_vessel_list)

vessel_location <- mc2_edges %>% 
  filter(event3 == "TransponderPing") %>%
  filter(target %in% unlist(fishing_vessel_list)) %>% 
  select(source, target, time, dwell) %>% 
  arrange(target,time) %>% 
  mutate(next_time = ifelse(lead(target) == target, lead(time), NA)) %>% 
  mutate(next_time = as_datetime(next_time))   %>% 
  mutate(end_time = time + dwell)

vessel_location_city <- vessel_location %>% 
  filter(source %in% c("City of Haacklee",
                       "City of Lomark",
                       "City of Himark",
                       "City of Paackland",
                       "City of South Paackland",
                       "City of Port Grove"))
```

**Merging cargo_list and vessel_location_city**

```{r}
cargo_list <- cargo_list %>% 
  mutate(vessel_delivery_date = date + days(-1))
```

```{r}
vessel_location_city <- vessel_location_city %>% 
  mutate(date = substr(`time`,1,10)) %>% 
  mutate(vessel_delivery_date = ymd(date)) 
```

```{r}
vessel_location_match <- vessel_location_city %>% 
  select(source,target,vessel_delivery_date) %>% 
  rename(city = source, vessel_hr = target) %>% 
  left_join(cargo_list,
            unmatched = "drop") %>%
  filter(if_all(c(qty_tons), ~ !is.na(.))) %>% 
  distinct()
```

There are a total of 5,307 unique cargoes, but we have  65,340 matches between the cargoes and vessels.

```{r}
vessel_location_match %>% 
  select(cargo) %>% 
  distinct()
```

```{r}
id1 <- vessel_location_match  %>% 
  select(vessel_hr) %>% 
  rename(id = vessel_hr) 

id2 <- vessel_location_match  %>% 
  select(cargo) %>% 
  rename(id = cargo)

cargo_vessel_nodes <- rbind(id1,id2) %>% 
  distinct() 

cargo_vessel_edges <- vessel_location_match %>% 
  select(vessel_hr,cargo) %>% 
  distinct() %>%
  group_by(vessel_hr, cargo) %>%
  rename(source = vessel_hr, target = cargo)%>%
  filter(source!=target) %>% 
  ungroup

cargo_vessel_graph <- tbl_graph(nodes = cargo_vessel_nodes,
                       edges = cargo_vessel_edges,
                       directed = FALSE)
```

```{r}
#| eval: FALSE
cargo_vessel_graph %>%
  ggraph(layout = 'nicely') +
  geom_edge_link() +
  geom_node_point() + 
  theme_graph()
```

Finding anomalies in vessel movement by comparing end time (calculated by dwell) with next time (the next time the vessel is detected at the next location). 

```{r}
ab_vessel_mvmt <- vessel_location %>%
  mutate(time = ymd_hms(time)) %>% 
  mutate(next_time = ymd_hms(next_time)) %>% 
  mutate(end_time = ymd_hms(end_time)) %>% 
  filter(end_time != next_time) 

ab_vessel_mvmt_agg <- ab_vessel_mvmt %>% 
  distinct() %>% 
  group_by(source) %>% 
  summarise(weights = n()) %>%
  arrange(desc(weights))
ab_vessel_mvmt_agg
```



**Overview of Harbor Report**

```{r}
distinct_harbor_report <- harbor_report_edges %>% 
  select(source,target,date) %>% 
  filter(source %in% unlist(fishing_vessel_list)) %>%
  distinct() %>% 
  arrange(source, date) %>%
  mutate(target = fct_infreq(target))
```

```{r}
ggplot(distinct_harbor_report) +
  geom_bar(aes(x = target))
```

**Overview of Vessels Location by Transponder Ping**

```{r}
transponder_location <- mc2_edges %>% 
  filter(event3 == "TransponderPing") %>%
  filter(target %in% unlist(fishing_vessel_list)) %>%
  filter(source %in% c("City of Haacklee",
                       "City of Lomark",
                       "City of Himark",
                       "City of Paackland",
                       "City of South Paackland",
                       "City of Port Grove")) %>% 
  select(source, target, time) %>%
  mutate(source = fct_infreq(source))

ggplot(transponder_location) +
  geom_bar(aes(x = source))
```
A quick comparison between the two bar chart, we can conclude that port activities for fishing vessels are highest at City of Paackland and least at City of Himark. Also, there is no fishing vessels that visits City of Port Grove. 

## 2.3 Examine the seasonal trends and anomalies in the port exit records

We examine the cargo_list and realised that there are some records that shows negative tonnage for their cargoes. This is abnormal as all cargoes should have positive qty_tons value. 

```{r}
negative_ton_cargo_by_city <- cargo_list %>% 
  filter(qty_tons <= 0) %>% 
  arrange(qty_tons) %>% 
  group_by(city) %>% 
  summarise(total_qty_ton_neg = sum(qty_tons)) %>% 
  arrange(total_qty_ton_neg)

positive_ton_cargo_by_city <- cargo_list %>% 
  filter(qty_tons > 0) %>% 
  arrange(qty_tons) %>% 
  group_by(city) %>% 
  summarise(total_qty_ton_pos = sum(qty_tons)) %>% 
  arrange(desc(total_qty_ton_pos))

negative_ton_cargo_by_city 
positive_ton_cargo_by_city
```

```{r}
positive_ton_cargo_by_city$city <- factor(positive_ton_cargo_by_city$city, 
                                           levels = rev(positive_ton_cargo_by_city$city[order(positive_ton_cargo_by_city$total_qty_ton_pos)]))

ggplot(positive_ton_cargo_by_city, aes(x = city)) +
  geom_bar(aes(y = total_qty_ton_pos), 
           stat = "identity", 
           position = "dodge", fill = "blue", alpha = 0.6) +  # Positive quantities
  labs(title = "Quantities by City",
       x = "",
       y = "Total Quantity (tons)") +
  theme_minimal()
```
There seems to be suspicious activities going on at each cities when we look at the negative values in qty_ton.

```{r}
negative_ton_cargo_by_city
```
Next, we will remove the negative quantity and then find the aggregated value by the type of fish, the city, and the date of transaction.

```{r}
fish_by_port_agg <- cargo_list %>%
  distinct() %>%
  filter(qty_tons > 0) %>% 
  group_by(name, city, date) %>%
  summarise(total_qty_ton = sum(qty_tons)) %>%
  ungroup() %>% 
  mutate(month = month(date, 
                       label = TRUE, 
                       abbr = TRUE))
```
Secondly, when we observe the heatmap, we also realised that the data only covers the month from Feb to Nov in year 2035. 

```{r}
# Create an overall Oceanus heat map for all types of fish
fish_agg <- fish_by_port_agg  %>%
  distinct() %>%
  group_by(name,month) %>%
  summarise(total_qty_ton = sum(total_qty_ton)) 

ggplot(fish_agg, aes(x = month, y = name, fill = total_qty_ton)) +
    geom_tile(color = "white") +
    scale_fill_gradient(low = "white", high = "blue") +
    labs(title = paste("Calendar Heatmap for fish in Oceanus"),
         x = "Month of the Year",
         y = "Fish Type",
         fill = "Total Quantity (tons)") +
    theme_minimal()
```


```{r}
# Function to create a calendar heat map
create_heatmap <- function(data, city, f) {
  ggplot(data, aes(x = month, y = name, fill = total_qty_ton)) +
    geom_tile(color = "white") +
    scale_fill_gradient(low = "white", high = "blue") +
    labs(title = paste("Calendar Heatmap for fish in", city),
         x = "Month of the Year",
         y = "Fish Type",
         fill = "Total Quantity (tons)") +
    theme_minimal()
}
```

```{r}
# Create an empty list to store heatmaps
heatmaps <- list()

# Iterate over each city
cities <- unique(cargo_list$city)
for (c in cities) {
  # Filter the data for the current city
  heatmap_data <- fish_by_port_agg %>% 
    filter(city == c)
  
  # Create the heatmap for the current city
  heatmap <- create_heatmap(heatmap_data, c, name)
  
  # Store the heatmap in the list
  heatmaps[[c]] <- heatmap
}

# Print or visualize the heatmaps
for (c in cities) {
  print(heatmaps[[c]])
}
```

## 2.3.1 **Understanding the types of fish that should not be in the market**

```{r}
region_fish_species <- mc2_nodes %>% 
  filter(entity3 == "Region") %>% 
  select(Name, fish_species_present, Activities, kind)
```

```{r}
word_list <- strsplit(region_fish_species$fish_species_present, "\\,")

max_elements <- max(lengths(word_list))

word_list_padded <- lapply(word_list, 
function(x) c(x, rep(NA, max_elements - length(x))))

word_df <- do.call(rbind, word_list_padded)
colnames(word_df) <- paste0("species", 1:max_elements) 

word_df <- as_tibble(word_df) %>% 
  mutate(species1 = str_replace(species1, "/.*", "")) %>% 
  mutate(species2 = str_replace(species2, "/.*", "")) %>% 
  mutate(species3 = str_replace(species3, "/.*", "")) %>% 
  mutate(species4 = str_replace(species4, "/.*", "")) %>% 
  mutate(species5 = str_replace(species5 , "/.*", "")) %>%
  mutate_at(vars(species1:species5), trimws)
class(word_df)

region_fish_species <- region_fish_species %>%
  cbind(word_df) 
  
region_fish_species
```
```{r}
# Convert data to long format
region_fish_species_long <- pivot_longer(region_fish_species, cols = starts_with("species"), names_to = "Species", values_to = "Presence")

# Filter out empty values and trim away leading and trailing whitespace
region_fish_species_long <- region_fish_species_long[region_fish_species_long$Presence != "", ] %>% 
  na.omit() %>%
  mutate_at(vars(Presence), trimws)
```

**Visualising the Species presence in each Region**

```{r}
# Order them based on 3 Preserves and 3 Fishing Ground
desired_order <- c("Ghoti Preserve", "Nemo Reef", "Don Limpet Preserve","Cod Table", "Wrasse Beds","Tuna Shelf")  

region_fish_species_long$Name <- factor(region_fish_species_long$Name, levels = desired_order)

ggplot(region_fish_species_long, aes(x = Name, 
                                     y = Presence,
                                     colour = Presence)) +
  geom_point() +
  labs(title = "Species Presence by Name",
       x = "Name",
       y = "Species") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")
```

From the above visualisation, we can derive that Sockfish, Offidiaa, and Helenaa species can only be found in the preserves but not in the fishing grounds. Therefore, any cargoes that contains these fish species would have fished illegal. Below shows the visualisation of the species and qty_ton that flows through each city by months. 

```{r}
# Create an empty list to store heatmaps
heatmaps <- list()

# Iterate over each city
cities <- unique(cargo_list$city)
for (c in cities) {
  # Filter the data for the current city
  heatmap_data <- fish_by_port_agg %>% 
    filter(city == c) %>% 
    filter(name %in% c("Sockfish", "Offidiaa", "Helenaa"))
  
  # Create the heatmap for the current city
  heatmap <- create_heatmap(heatmap_data, c, name)
  
  # Store the heatmap in the list
  heatmaps[[c]] <- heatmap
}

# Print or visualize the heatmaps
for (c in cities) {
  print(heatmaps[[c]])
}
```

```{r}
# Create an overall Oceanus heat map for all types of fish
fish_agg <- fish_by_port_agg  %>% 
  filter(name %in% c("Sockfish", "Offidiaa", "Helenaa")) %>% 
  distinct() %>%
  group_by(name,month) %>%
  summarise(total_qty_ton = sum(total_qty_ton))

ggplot(fish_agg, aes(x = month, y = name, fill = total_qty_ton)) +
    geom_tile(color = "white") +
    scale_fill_gradient(low = "white", high = "blue") +
    labs(title = paste("Calendar Heatmap for fish in Oceanus"),
         x = "Month of the Year",
         y = "Fish Type",
         fill = "Total Quantity (tons)") +
    theme_minimal()
```

From this heatmap above, we understand that there is an abnormal increase in Sockfish catch from May onwards, and abnormal increase in Offidiaa catch from September onwards , which are species unique to the Don Limpet Preserve and Ghoti Preserve respectively. 

Probable reason for this is that since SouthSeafood Express Corp was caught in mid-May for illegal fishing in Ghoti Preserve, other illegal fishing vessels made a switch to Don Limpet Reserves to fish. 

## 3.0 Task 2

Develop visualizations that illustrate the inappropriate behavior of SouthSeafood Express Corp vessels. How do their movement and catch contents compare to other fishing vessels? When and where did SouthSeafood Express Corp vessels perform their illegal fishing? How many different types of suspicious behaviors are observed? Use visual evidence to justify your conclusions.

## 3.1 Illegal fishing by SouthSeafood Express Corp

SouthSeafood Express Corp operates two fishing vessels by the id of "snappersnatcher7be" and "roachrobberdb6".

```{r}
transponder_ping_edge <- mc2_edges %>% 
  filter(event3 == "TransponderPing")
```

```{r}
transponder_ping_edge_agg <-
  transponder_ping_edge %>%
  distinct() %>%
  group_by(source, target, type) %>%
  summarise(weights = n()) %>%
  filter(source!=target) %>% 
  ungroup
```

```{r}
transponder_ping_edge_agg %>% 
  filter(target %in% c("snappersnatcher7be","roachrobberdb6")) %>%
  group_by(target) %>% 
  ggplot(aes(x=target, y=source,
             size = weights)) +
  geom_point()

```

```{r}
southseafood_edge <- mc2_edges %>% 
  filter(event3 == "TransponderPing") %>% 
  filter(target %in% c("snappersnatcher7be","roachrobberdb6")) %>% 
  arrange(target,time)
```

```{r}
ssf_edges_agg <-
  southseafood_edge %>%
  distinct() %>%
  group_by(source, target, type) %>%
  summarise(weights = n()) %>%
  filter(source!=target) %>% 
  ungroup
```

```{R}
id1 <- ssf_edges_agg %>% 
  select(source) %>% 
  rename(id = source) 

id2 <- ssf_edges_agg %>% 
  select(target) %>% 
  rename(id = target)

mc2_nodes1 <- rbind(id1,id2) %>% 
  distinct() 
```

```{r}
ssf_graph <- tbl_graph(nodes = mc2_nodes1,
                       edges = ssf_edges_agg,
                       directed = TRUE)
```

```{r}
# Add a color column to nodes
ssf_graph <- ssf_graph %>%
  activate(nodes) %>%
  mutate(color = case_when(
    id %in% c("snappersnatcher7be", "roachrobberdb6") ~ "Vessel",
    TRUE ~ "Location"
  ))

# Create the plot
ssf_graph %>% 
  activate(edges) %>%
  arrange(desc(weights)) %>% 
  ggraph(layout = "fr") +
  geom_edge_link(aes(color = "", 
                     linewidth = weights)) +
  geom_node_point(aes(color = color, size = 10)) + 
  theme_graph() +
  theme(
    plot.background = element_rect(fill = "white", color = NA),
    text = element_text(color = "black"))+
  geom_node_text(aes(label = id), 
                 repel = TRUE, 
                 vjust = 1, 
                 hjust = 1,
                 size = 3)
```
### 3.1.1 When and where did SouthSeafood Express Corp vessels perform their illegal fishing?

Since only Snapper Snatcher appears to be operating in Ghoti Preserve, we will examine this fishing vessel more closely. 

```{r}
snapper_activities <- mc2_edges %>% 
  filter(event3 == "TransponderPing") %>% 
  filter(target %in% c("snappersnatcher7be")) %>% 
  filter(source == "Ghoti Preserve") %>% 
  arrange(target,time) %>% 
  mutate(end_time = time + dwell) %>% 
  select(time, dwell, end_time)
snapper_activities
```

There three instances (2,9 and 16 Feb) where Snapper Snatcher stayed at the Ghoti Preserve for over 3 days. These are the instances where SouthSeafood Express Corp's Snapper Snatcher conducted IUU Fishing in Ghoti Preserve. 


## 4.0 Task 4

**The Questions**:

1.  How did fishing activity change after SouthSeafood Express Corp was caught?

2.  What new behaviors in the Oceanus commercial fishing community are most suspicious and why?

In order to understand the change in fishing activities, we first have to determine the date where SouthSeafood Express Corp was caught. We will use this timeline as the

The final activities of SouthSeafood's vessels are on 2035-05-16 (snappersnatcher7be) and 2035-05-16 (roachrobberdb6) according to the transponder pings. Hence, we can conclude that the SouthSeafood is caught for illegal fishing, and had ceased operating its fishing vessels since 2035-05-16.

## 4.1 Changes in Commercial Fishing

Firstly, we take a look at the species caught across the months (Feb to Nov 2035). 

```{r}
# Create an overall Oceanus heat map for all types of fish
fish_agg <- fish_by_port_agg  %>%
  distinct() %>%
  group_by(name,month) %>%
  summarise(total_qty_ton = sum(total_qty_ton)) 

oceanus_heatmap <- ggplot(fish_agg, aes(x = month, y = name, fill = total_qty_ton)) +
    geom_tile(color = "white") +
    scale_fill_gradient(low = "white", high = "blue") +
    labs(title = paste("Calendar Heatmap for fish in Oceanus"),
         x = "Month of the Year",
         y = "Fish Type",
         fill = "Total Quantity (tons)") +
    theme_minimal() +
  geom_vline(xintercept = "May",color = 'red', linetype = 'dashed') +
  annotate("text", x = "May" , y = "Offidiaa", label = "SouthSeafood caught", angle = 90, vjust = -0.5, hjust = 0.5, color = "red")
```

```{r}
# Order them based on 3 Preserves and 3 Fishing Ground
desired_order <- c("Ghoti Preserve", "Nemo Reef", "Don Limpet Preserve","Cod Table", "Wrasse Beds","Tuna Shelf")  

region_fish_species_long$Name <- factor(region_fish_species_long$Name, levels = desired_order)

species_plot <-ggplot(region_fish_species_long, aes(x = Name, 
                                     y = Presence,
                                     colour = Presence)) +
  geom_point() +
  labs(title = "Species Presence by Name",
       x = "Name",
       y = "Species") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")
```

```{r, fig.width=6, fig.height=6}
oceanus_heatmap / species_plot
```
For recapitulation, we know that Sockfish, Offidiaa, and Helenaa are fish species that are unique to the three Preserves. From the two plots above, we can derive initial conclusion that there is an usual increase in Sockfish catch after SouthSeafood was caught in mid-May. We also see a minor increase in Helenaa between Jun to Aug, and later in Oct to Nov. The spike in Offidiaa catch begins in Sep and grows gradually to Nov. 

Combining the information above, we can make the following two hypothesis about the changes in fishing activities in Oceanus after SouthSeafood was caught:

1.  The fishing vessels switched to Don Limpet Preserve for IUU fishing. Tell tale sign is the increase in Sockfish catch, which is species unique to Don Limpet Preserve. This also explains the slight increase in Helena catch from Jun. 

2.  The fishing vessels moved into Ghoti Preserves from Sep onwards for IUU fishing. Tell tale sign is the increase in Offidia catch from Sep, which is species unique to Ghoti Preserve. 

For confirmation, we take a look at the changes to OVLS Transponder Ping, comparing the total pings to various Fishing Grounds and Preserves month by month.

```{r}
transponder_ping_edge_long <- transponder_ping_edge %>% 
  filter(target %in% unlist(fishing_vessel_list)) %>% 
  filter(source %in% c("Ghoti Preserve", 
                       "Nemo Reef", 
                       "Don Limpet Preserve",
                       "Cod Table", 
                       "Wrasse Beds",
                       "Tuna Shelf")) %>% 
  mutate(month = month(time)) %>% 
  select(source, target, month) %>% 
  group_by(source, month) %>% 
  summarize(n = n()) 
```


```{r}
transponder_ping_edge_long %>% 
  mutate(month = as.factor(month)) %>% 
  newggslopegraph(month,n, source,
                Title = "Changes in Visit Frequency",
                SubTitle = "across Feb to Nov 2035",
                Caption = "Prepared by: Liang Xiuhao")
```
In the line graph below, we observe that the overall fishing vessels activities in the fishing ground and preserves dropped. 

```{r}
average <- transponder_ping_edge %>% 
  filter(target %in% unlist(fishing_vessel_list)) %>% 
  filter(source %in% c("Ghoti Preserve", 
                       "Nemo Reef", 
                       "Don Limpet Preserve",
                       "Cod Table", 
                       "Wrasse Beds",
                       "Tuna Shelf")) %>%
  mutate(month = month(time)) %>% 
  summarise(average = (n()/10))

transponder_ping_edge %>% 
  filter(source %in% c("Ghoti Preserve", 
                       "Nemo Reef", 
                       "Don Limpet Preserve",
                       "Cod Table", 
                       "Wrasse Beds",
                       "Tuna Shelf")) %>%
  filter(target %in% unlist(fishing_vessel_list)) %>% 
  mutate(month = month(time)) %>% 
  group_by(month) %>% 
  summarise(n = as.numeric(n())) %>%
  ggplot(aes(x = month, y = n)) + 
  geom_line(color = "blue") +  
  geom_point(size = 4, color = "blue") +
  geom_text(aes(label = n), 
            vjust = -1,
            size = 3) +
  labs(title = "Visit Frequency to All Fishing Grounds and Preserves by Month",
       x = "Month",
       y = "Frequency") +
  geom_hline(average, 
             yintercept = as.numeric(average), 
             color="black",
             linetype = 6) +
  geom_point(x = 5, y = 13366,
             size = 4, color = "red") +
  geom_text(aes(x = 5, y = 13366, label = "SouthSeafood caught"),
            color = "red",
            hjust = -0.2,
            size = 3) +
  geom_text(aes(x = 4.5, y = 12000, label = "Monthly Average = 11854"),
            color = "black",
            size = 3) +
  theme_minimal()
  
```
Derive monthly transponder ping:

```{r}
monthly_transponder_ping <- transponder_ping_edge %>% 
  filter(target %in% unlist(fishing_vessel_list)) %>% 
  filter(source %in% c("Ghoti Preserve", 
                       "Nemo Reef", 
                       "Don Limpet Preserve",
                       "Cod Table", 
                       "Wrasse Beds",
                       "Tuna Shelf")) %>% 
  mutate(month = month(time)) %>% 
  select(source, target, month) %>% 
  group_by(source, month) %>% 
  summarize(n = n()) 
```



```{r, fig.width= 10}
monthly_transponder_ping$month <- factor(monthly_transponder_ping$month)
monthly_transponder_ping$source <- factor(monthly_transponder_ping$source,
                                             levels = c("Ghoti Preserve", 
                                                        "Nemo Reef",
                                                        "Don Limpet Preserve",
                                                        "Cod Table",
                                                        "Wrasse Beds",
                                                        "Tuna Shelf"))

hline.data <- monthly_transponder_ping %>% 
  group_by(source) %>%
  summarise(avgvalue = mean(n))

ggplot(monthly_transponder_ping , aes(x = month, 
                                      y = n, 
                                      group = source, 
                                      color = source)) +
  geom_line(size = 1) +
  geom_point(size = 2) +
  facet_wrap(~ source, scales = "free_y") +  # Facet by 'source'
  theme_minimal() +
  labs(title = "Changes in Visit Frequency by Month by Fishing Vessels",
       x = "Month",
       y = "No. of Visits",
       color = "Source") +
  geom_hline(data = hline.data,
             aes(yintercept = avgvalue),
             linetype = 6,
             color = "black",
             size = 0.5) +
  geom_text(data = hline.data, 
            aes(x = "4", y = avgvalue, label = "Average"), 
            hjust = 1, vjust = 1, 
            color = "black",
            size = 3) +
  geom_vline(aes(xintercept = 4),
             linetype = 6,
             color = "red",
             size = 0.5) +
  geom_text(data = hline.data, 
            aes(x = "4", y = avgvalue, label = "SouthSeafood caught"), 
            hjust = 1.5, vjust = 1.5,
            angle = 90,
            color = "red",
            size = 2)

```
From the plot above, we can see that after SouthSeafood was caught in mid-May, there is a drop in activities for all the fishing grounds and preserves immediately after mid-May, except for the increase in Don Limpet Preserve, from 1 in Mar and Jun to 2 observations in Aug.  

Let's observe for month to month if the dwell time increase for Don Limpet Preserve.

```{r}
don_monthly_transponder_ping <- transponder_ping_edge %>% 
  filter(target %in% unlist(fishing_vessel_list)) %>% 
  select(source, dwell, time) %>% 
  mutate(month = month(time)) %>% 
  filter(source == "Don Limpet Preserve") %>%
  group_by(month) %>% 
  summarise(dwell_total = sum(dwell)) %>%
  ggplot(aes(x = month, y = dwell_total)) + 
  geom_line(color = "blue") +
  labs(title = "Dwell Time in Don Limpet by Month",
       x = "Month",
       y = "Total Count") +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE,
              linetype = 6,
              color = "black") +
  geom_text(data = NULL, aes(label = "Trend Line"), 
            x = 6, y = 7500, 
            angle = 15,
            hjust = -0.3, vjust = -1.5, 
            color = "black", size = 4)
  
```

```{r}
nemo_monthly_transponder_ping <- transponder_ping_edge %>% 
  filter(target %in% unlist(fishing_vessel_list)) %>% 
  select(source, dwell, time) %>% 
  mutate(month = month(time)) %>% 
  filter(source == "Nemo Reef") %>%
  group_by(month) %>% 
  summarise(dwell_total = sum(dwell)) %>%
  ggplot(aes(x = month, y = dwell_total)) + 
  geom_line(color = "blue") +
  labs(title = "Dwell Time in Nemo Reef by Month",
       x = "Month",
       y = "Total Count") +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE,
              linetype = 6,
              color = "black") +
  geom_text(data = NULL, aes(label = "Trend Line"), 
            x = 5, y = 12500000, 
            angle = -15,
            hjust = 0.3, 
            color = "black", size = 4)

```

```{r}
ghoti_monthly_transponder_ping <- transponder_ping_edge %>% 
  filter(target %in% unlist(fishing_vessel_list)) %>% 
  select(source, dwell, time) %>% 
  mutate(month = month(time)) %>% 
  filter(source == "Ghoti Preserve") %>%
  group_by(month) %>% 
  summarise(dwell_total = sum(dwell)) %>%
  ggplot(aes(x = month, y = dwell_total)) + 
  geom_line(color = "blue") +
  labs(title = "Dwell Time in Ghoti by Month",
       x = "Month",
       y = "Total Count") +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE,
              linetype = 6,
              color = "black") +
  geom_text(data = NULL, aes(label = "Trend Line"), 
            x = 8, y = 5000000, 
            angle = -5, 
            color = "black", size = 4)
```

```{r, fig.width=6, fig.height=6}
nemo_monthly_transponder_ping/ghoti_monthly_transponder_ping
```
From the above plots, we observe that for Nemo Reef and Ghoti Preserve, the trend is downards for the amount of time spent by the fishing vessels. 

```{r}
fishing_vessels_in_don <- transponder_ping_edge %>% 
  filter(source == "Don Limpet Preserve") %>% 
  filter(target %in% unlist(fishing_vessel_list)) %>% 
  select(target, dwell, date_added, time) %>% 
  mutate(end_time = dwell + time) %>% 
  arrange(time)
fishing_vessels_in_don
```

There are only 4 records of visits through the OVLS to Don Limpet, once in Mar and Jun, for about 1.5 to 2hrs each, and another 2 in Aug, for about 1.25 to 1.75 hrs each. These record is high inconguent to the growing number of Sockfish that are found in the delivery report from May onwards. 


### 4.2 What new behaviors in the Oceanus commercial fishing community are most suspicious and why?






























