[
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, you will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap.\n\n\n\nBy the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps.\n\n\n\n\nBefore we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\n\n\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\n\n\n\n\n\nNote\n\n\n\nThings to learn from the argument above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\n\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bounding box provides information of the extend of the geospatial data.\n\n\n\n\nTo create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\n\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\n\n\n\n\n\n\n\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")\n\n\n\n\n\n\n\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#overview",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#overview",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "Proportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, you will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#learning-outcome",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#learning-outcome",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "By the end of this hands-on exercise, you will acquire the following skills by using appropriate R packages:\n\nTo import an aspatial data file into R.\nTo convert it into simple point feature data frame and at the same time, to assign an appropriate projection reference to the newly create simple point feature data frame.\nTo plot interactive proportional symbol maps."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#getting-started",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#getting-started",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "Before we get started, we need to ensure that tmap package of R and other related R packages have been installed and loaded into R.\n\npacman::p_load(sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#geospatial-data-wrangling",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#geospatial-data-wrangling",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "The data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\n\n\n\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe code chunk below shows list() is used to do the job.\n\nlist(sgpools) \n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame.\n\n\n\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n\n\n\n\n\n\nNote\n\n\n\nThings to learn from the argument above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\n\n\nFigure below shows the data table of sgpools_sf. Notice that a new column called geometry has been added into the data frame.\n\nYou can display the basic information of the newly created sgpools_sf by using the code chunk below.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bounding box provides information of the extend of the geospatial data."
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#drawing-proportional-symbol-map",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#drawing-proportional-symbol-map",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "To create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\n\n\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n\n\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\n\n\n\n\n\n\n\nAn impressive and little-know feature of tmap’s view mode is that it also works with faceted plots. The argument sync in tm_facets() can be used in this case to produce multiple maps with synchronised zoom and pan settings.\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#reference",
    "href": "Hands-on Exercise/Hands-on_Ex08b/Hands-on_Ex08b.html#reference",
    "title": "Hands On Exercise 8b",
    "section": "",
    "text": "tmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html",
    "href": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html",
    "title": "Hands On Exercise 8c",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap\n\n\n\n\n\n\n\n\npacman::p_load(sf, tmap, tidyverse)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")\n\n\nlist(NGA_wp)\n\n[[1]]\nSimple feature collection with 774 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 26662.71 ymin: 30523.38 xmax: 1344157 ymax: 1096029\nProjected CRS: Minna / Nigeria Mid Belt\nFirst 10 features:\n          ADM2_EN ADM2_PCODE                   ADM1_EN ADM1_PCODE\n1       Aba North   NG001001                      Abia      NG001\n2       Aba South   NG001002                      Abia      NG001\n3          Abadam   NG008001                     Borno      NG008\n4           Abaji   NG015001 Federal Capital Territory      NG015\n5            Abak   NG003001                 Akwa Ibom      NG003\n6       Abakaliki   NG011001                    Ebonyi      NG011\n7  Abeokuta North   NG028001                      Ogun      NG028\n8  Abeokuta South   NG028002                      Ogun      NG028\n9             Abi   NG009001               Cross River      NG009\n10    Aboh-Mbaise   NG017001                       Imo      NG017\n                         geometry total_wp wp_functional wp_nonfunctional\n1  MULTIPOLYGON (((548795.5 11...       17             7                9\n2  MULTIPOLYGON (((547286.1 11...       71            29               35\n3  MULTIPOLYGON (((1248985 104...        0             0                0\n4  MULTIPOLYGON (((510864.9 57...       57            23               34\n5  MULTIPOLYGON (((594269 1209...       48            23               25\n6  MULTIPOLYGON (((660767 2522...      233            82               42\n7  MULTIPOLYGON (((78621.56 37...       34            16               15\n8  MULTIPOLYGON (((106627.7 35...      119            72               33\n9  MULTIPOLYGON (((632244.2 21...      152            79               62\n10 MULTIPOLYGON (((540081.3 15...       66            18               26\n   wp_unknown\n1           1\n2           7\n3           0\n4           0\n5           0\n6         109\n7           3\n8          14\n9          11\n10         22\n\n\nPlot a choropleth map showing the distribution of non-function water point by LGA:\n\ntm_shape(NGA_wp) +\n  tm_fill(\"wp_nonfunctional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Reds\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of non-functional water point by LGA\",\n            legend.outside = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\n\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\n\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geometry field.\n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = \"Percentile Map\", \n            title.position = c(\"right\",\"bottom\")) +\n  tm_facets(by=\"ADM1_EN\", \n            free.coords=TRUE, \n            drop.shapes=FALSE)\n}\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nLet’s test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map.\n\narguments:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR\n\nreturns:\n\na tmap-element (plots a map)\n\n\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#overview",
    "href": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#overview",
    "title": "Hands On Exercise 8c",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#getting-started",
    "href": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#getting-started",
    "title": "Hands On Exercise 8c",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)\n\n\n\n\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")\n\n\nlist(NGA_wp)\n\n[[1]]\nSimple feature collection with 774 features and 8 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 26662.71 ymin: 30523.38 xmax: 1344157 ymax: 1096029\nProjected CRS: Minna / Nigeria Mid Belt\nFirst 10 features:\n          ADM2_EN ADM2_PCODE                   ADM1_EN ADM1_PCODE\n1       Aba North   NG001001                      Abia      NG001\n2       Aba South   NG001002                      Abia      NG001\n3          Abadam   NG008001                     Borno      NG008\n4           Abaji   NG015001 Federal Capital Territory      NG015\n5            Abak   NG003001                 Akwa Ibom      NG003\n6       Abakaliki   NG011001                    Ebonyi      NG011\n7  Abeokuta North   NG028001                      Ogun      NG028\n8  Abeokuta South   NG028002                      Ogun      NG028\n9             Abi   NG009001               Cross River      NG009\n10    Aboh-Mbaise   NG017001                       Imo      NG017\n                         geometry total_wp wp_functional wp_nonfunctional\n1  MULTIPOLYGON (((548795.5 11...       17             7                9\n2  MULTIPOLYGON (((547286.1 11...       71            29               35\n3  MULTIPOLYGON (((1248985 104...        0             0                0\n4  MULTIPOLYGON (((510864.9 57...       57            23               34\n5  MULTIPOLYGON (((594269 1209...       48            23               25\n6  MULTIPOLYGON (((660767 2522...      233            82               42\n7  MULTIPOLYGON (((78621.56 37...       34            16               15\n8  MULTIPOLYGON (((106627.7 35...      119            72               33\n9  MULTIPOLYGON (((632244.2 21...      152            79               62\n10 MULTIPOLYGON (((540081.3 15...       66            18               26\n   wp_unknown\n1           1\n2           7\n3           0\n4           0\n5           0\n6         109\n7           3\n8          14\n9          11\n10         22\n\n\nPlot a choropleth map showing the distribution of non-function water point by LGA:\n\ntm_shape(NGA_wp) +\n  tm_fill(\"wp_nonfunctional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Reds\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of non-functional water point by LGA\",\n            legend.outside = FALSE)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#choropleth-map-for-rates",
    "href": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#choropleth-map-for-rates",
    "title": "Hands On Exercise 8c",
    "section": "",
    "text": "In much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\n\n\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\n\n\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#extreme-value-maps",
    "href": "Hands-on Exercise/Hands-on_Ex08c/Hands-on_Ex08c.html#extreme-value-maps",
    "title": "Hands On Exercise 8c",
    "section": "",
    "text": "Extreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n\nStep 1: Exclude records with NA by using the code chunk below.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\n\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\n\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geometry field.\n\n\n\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = \"Percentile Map\", \n            title.position = c(\"right\",\"bottom\")) +\n  tm_facets(by=\"ADM1_EN\", \n            free.coords=TRUE, \n            drop.shapes=FALSE)\n}\n\n\n\n\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map.\n\n\n\n\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\n\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\n\nLet’s test the newly created function\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n\nThe code chunk below is an R function to create a box map.\n\narguments:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR\n\nreturns:\n\na tmap-element (plots a map)\n\n\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take Home Exercise 3",
    "section": "",
    "text": "Mini-challenge 2 focuses on analyzing ship movements and shipping records to understand illegal fishing practices. FishEye analysts need help creating visualizations to show patterns of ship movements and identify suspicious behaviors. They also want to understand how the commercial fishing community changed after a company was caught fishing illegally.\nThe details of the mini challenge can be found here."
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#mini-challenge-2-creating-signatures-for-geo-temporal-patterns",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#mini-challenge-2-creating-signatures-for-geo-temporal-patterns",
    "title": "Take Home Exercise 3",
    "section": "",
    "text": "Mini-challenge 2 focuses on analyzing ship movements and shipping records to understand illegal fishing practices. FishEye analysts need help creating visualizations to show patterns of ship movements and identify suspicious behaviors. They also want to understand how the commercial fishing community changed after a company was caught fishing illegally.\nThe details of the mini challenge can be found here."
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#tasks-and-questions",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#tasks-and-questions",
    "title": "Take Home Exercise 3",
    "section": "",
    "text": "FishEye analysts need your help to perform geographic and temporal analysis of the CatchNet data so they can prevent illegal fishing from happening again. Your task is to develop new visual analytics tools and workflows that can be used to discover and understand signatures of different types of behavior. Can you use your tool to visualize a signature of SouthSeafood Express Corp’s illegal behavior? FishEye needs your help to develop a workflow to find other instances of illegal behavior.\n\nFishEye analysts have long wanted to better understand the flow of commercially caught fish through Oceanus’s many ports. But as they were loading data into CatchNet, they discovered they had purchased the wrong port records. They wanted to get the ship off-load records, but they instead got the port-exit records (essentially trucks/trains leaving the port area). Port exit records do not include which vessel that delivered the products. Given this limitation, develop a visualization system to associate vessels with their probable cargos. Which vessels deliver which products and when? What are the seasonal trends and anomalies in the port exit records?\nDevelop visualizations that illustrate the inappropriate behavior of SouthSeafood Express Corp vessels. How do their movement and catch contents compare to other fishing vessels? When and where did SouthSeafood Express Corp vessels perform their illegal fishing? How many different types of suspicious behaviors are observed? Use visual evidence to justify your conclusions.\nTo support further Fisheye investigations, develop visual analytics workflows that allow you to discover other vessels engaging in behaviors similar to SouthSeafood Express Corp’s illegal activities? Provide visual evidence of the similarities.\nHow did fishing activity change after SouthSeafood Express Corp was caught? What new behaviors in the Oceanus commercial fishing community are most suspicious and why?"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#loading-r-packages",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#loading-r-packages",
    "title": "Take Home Exercise 3",
    "section": "1.1 Loading R Packages",
    "text": "1.1 Loading R Packages\n\n\nShow the code\npacman::p_load(tidyverse, jsonlite, DT, lubridate,\n               igraph, tidygraph, ggraph, \n               visNetwork, sf,\n               patchwork, CGPfunctions,\n               ggHoriPlot, plotly,ggridges,\n               ggdist)"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#loading-the-data",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#loading-the-data",
    "title": "Take Home Exercise 3",
    "section": "1.2 Loading the Data",
    "text": "1.2 Loading the Data\nLoading the .json data using jsonlite package.\n\n\nShow the code\nmc2_data &lt;- fromJSON(\"data/MC2/mc2.json\")\n\n\nmc2 is a directed multigraph, consists of nodes dataframe and links dataframe.\n\n1.2.1 Loading the Geographical Data\n\n\nShow the code\noceanus_geography = st_read(\"data/MC2/Oceanus Information/Oceanus Geography.geojson\") %&gt;%\n  st_transform(crs = 4326)\n\n\nReading layer `Oceanus Geography' from data source \n  `C:\\rydialiang\\ISSS608\\Take-home Exercise\\Take-home_Ex03\\data\\MC2\\Oceanus Information\\Oceanus Geography.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 29 features and 7 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -167.0654 ymin: 38.07452 xmax: -163.2723 ymax: 40.67775\nGeodetic CRS:  WGS 84\n\n\n\n\nShow the code\nglimpse(oceanus_geography)\n\n\nRows: 29\nColumns: 8\n$ Name                 &lt;chr&gt; \"Suna Island\", \"Thalassa Retreat\", \"Makara Shoal\"…\n$ Description          &lt;chr&gt; \"Large island of Oceanus\", \"Smaller island of Oce…\n$ X.note               &lt;chr&gt; \"Suna is 'sand' or 'gritty' in Japanese\", \"Thalas…\n$ type                 &lt;chr&gt; \"Entity.Location.Region\", \"Entity.Location.Region…\n$ X.Kind               &lt;chr&gt; \"Island\", \"Island\", \"Island\", \"Island\", \"Fishing …\n$ Activities           &lt;list&gt; \"Residential\", \"Residential\", \"Recreation\", &lt;\"To…\n$ fish_species_present &lt;list&gt; &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;\"Cod/Gadus n.specificatae\", \"Bi…\n$ geometry             &lt;GEOMETRY [°]&gt; MULTIPOLYGON (((-166.0111 3..., MULTIPOL…\n\n\n\n\nShow the code\nwrite_rds(oceanus_geography, \n  \"data/rds/oceanus_geography.rds\")\n\n\nImporting Geographical Data in ESRI shapefile format\n\n\nShow the code\noceanus_locations &lt;- st_read(dsn = \"data/MC2/shp\",\n  layer = \"Oceanus Geography\")\n\n\nReading layer `Oceanus Geography' from data source \n  `C:\\rydialiang\\ISSS608\\Take-home Exercise\\Take-home_Ex03\\data\\MC2\\shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 27 features and 7 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -167.0654 ymin: 38.07452 xmax: -163.2723 ymax: 40.67775\nGeodetic CRS:  WGS 84\n\n\n\n\nShow the code\nglimpse(oceanus_locations)\n\n\nRows: 27\nColumns: 8\n$ Name       &lt;chr&gt; \"Haacklee\", \"Port Grove\", \"Lomark\", \"Himark\", \"Paackland\", …\n$ Descriptio &lt;chr&gt; NA, NA, NA, NA, NA, \"Adimistrative seat of Oceanus\", NA, NA…\n$ X.note     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ Activities &lt;chr&gt; \"Tourism,Local shipping\", \"Tourism,Research\", \"Deep sea fis…\n$ type       &lt;chr&gt; \"Entity.Location.City\", \"Entity.Location.City\", \"Entity.Loc…\n$ X.Kind     &lt;chr&gt; \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"city\", \"bu…\n$ fish_speci &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ geometry   &lt;POINT [°]&gt; POINT (-165.6908 39.03215), POINT (-165.8855 39.10005…\n\n\n\n\nShow the code\nggplot(data = oceanus_locations) +\n  geom_sf()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nwrite_rds(oceanus_locations, \n  \"data/rds/oceanus_locations.rds\")\n\n\n\n\n1.2.2 Wrangling of Geographical Data\nIn the code chunk below, st_coordinate() of sf package is used to extract coordinates from oceanus_locations sf data.frame.\n\n\nShow the code\ncoords &lt;- st_coordinates(oceanus_locations)\n\n\nNext, code chunk below is used to drop the geometry column of oceanus_locations of sf data.frame by using st_drop_geometry() of sf package and save the output into a new data.frame called oceanus_locations_df.\n\n\nShow the code\noceanus_locations_df &lt;- oceanus_locations %&gt;%\n  st_drop_geometry()\n\n\nThen, the code chunk below is to append the x- and y-coodinate values from coords list into the XCOORD and YCOORD columns of oceanus_locations_df respectively.\n\n\nShow the code\noceanus_locations_df$XCOORD &lt;- coords[, \"X\"]\noceanus_locations_df$YCOORD &lt;- coords[, \"Y\"]\n\n\nLastly, the code chunk below is used to tidy OceanusLocations_df by selecting the necessary columns only and at the same time, rename X.Kind to Loc_Type.\n\n\nShow the code\noceanus_locations_df &lt;- oceanus_locations_df %&gt;%\n  select(Name, X.Kind, XCOORD, YCOORD) %&gt;%\n  rename(loc_type = X.Kind, loc_short = Name)"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-edges",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-edges",
    "title": "Take Home Exercise 3",
    "section": "1.3 Wrangling and tidying edges",
    "text": "1.3 Wrangling and tidying edges\n\n1.3.1 Extracting edges\nFirst, we extract only distinct edges from the tibble links data.frame of mc2_data and save it as a tibble data.frame called mc2_edges.\n\n\nShow the code\nmc2_edges &lt;- mc2_data$links %&gt;% \n  distinct()\n\n\nNext, glimpse() of dplyr will be used to reveal the structure of mc2_edges tibble data.table.\n\n\nShow the code\nglimpse(mc2_edges)\n\n\nRows: 271,643\nColumns: 17\n$ type                &lt;chr&gt; \"Event.TransportEvent.TransponderPing\", \"Event.Tra…\n$ time                &lt;chr&gt; \"2035-09-16T04:06:48.185987\", \"2035-09-20T05:21:33…\n$ dwell               &lt;dbl&gt; 115074.79, 412706.32, 286092.88, 327623.95, 243225…\n$ `_last_edited_by`   &lt;chr&gt; \"Olokun Daramola\", \"Melinda Manning\", \"Olokun Dara…\n$ `_date_added`       &lt;chr&gt; \"2035-09-16T00:59:46.300100\", \"2035-09-22T02:37:37…\n$ `_last_edited_date` &lt;chr&gt; \"2035-09-16T00:59:46.300100\", \"2035-09-22T02:37:37…\n$ `_raw_source`       &lt;chr&gt; \"Oceanus Vessel Locator System\", \"Oceanus Vessel L…\n$ `_algorithm`        &lt;chr&gt; \"OVLS-Catch&Hook\", \"OVLS-Catch&Hook\", \"OVLS-Catch&…\n$ source              &lt;chr&gt; \"City of Haacklee\", \"City of Haacklee\", \"City of H…\n$ target              &lt;chr&gt; \"perchplundererbc0\", \"perchplundererbc0\", \"perchpl…\n$ key                 &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7,…\n$ date                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ data_author         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ aphorism            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ holiday_greeting    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wisdom              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `saying of the sea` &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\nFrom the table above, we can identify some issues with the data:\n\nThe columns with date data type are all in character format.\nSome columns have names that starts with “_”. These need to be rename to avoid coding issues.\n\n\n\n1.3.2 Correcting the date data type with lubridate()\n\n\nShow the code\nmc2_edges$time &lt;- as_datetime(mc2_edges$time)\nmc2_edges$`_last_edited_date` &lt;- as_datetime(mc2_edges$`_last_edited_date`)\nmc2_edges$`_date_added` &lt;- as_datetime(mc2_edges$`_date_added`)\nmc2_edges$date &lt;- as_datetime(mc2_edges$date)\n\n\nNext, glimpse() will be used to confirm if the process have been performed correctly.\n\n\nShow the code\nglimpse(mc2_edges)\n\n\nRows: 271,643\nColumns: 17\n$ type                &lt;chr&gt; \"Event.TransportEvent.TransponderPing\", \"Event.Tra…\n$ time                &lt;dttm&gt; 2035-09-16 04:06:48, 2035-09-20 05:21:33, 2035-09…\n$ dwell               &lt;dbl&gt; 115074.79, 412706.32, 286092.88, 327623.95, 243225…\n$ `_last_edited_by`   &lt;chr&gt; \"Olokun Daramola\", \"Melinda Manning\", \"Olokun Dara…\n$ `_date_added`       &lt;dttm&gt; 2035-09-16 00:59:46, 2035-09-22 02:37:37, 2035-09…\n$ `_last_edited_date` &lt;dttm&gt; 2035-09-16 00:59:46, 2035-09-22 02:37:37, 2035-10…\n$ `_raw_source`       &lt;chr&gt; \"Oceanus Vessel Locator System\", \"Oceanus Vessel L…\n$ `_algorithm`        &lt;chr&gt; \"OVLS-Catch&Hook\", \"OVLS-Catch&Hook\", \"OVLS-Catch&…\n$ source              &lt;chr&gt; \"City of Haacklee\", \"City of Haacklee\", \"City of H…\n$ target              &lt;chr&gt; \"perchplundererbc0\", \"perchplundererbc0\", \"perchpl…\n$ key                 &lt;int&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7,…\n$ date                &lt;dttm&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ data_author         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ aphorism            &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ holiday_greeting    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wisdom              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `saying of the sea` &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n\n\n\n\n1.3.3 Changing field name\nIn the code chunk below, rename() of dplyr package is used to change the following fields.\n\n\nShow the code\nmc2_edges &lt;- mc2_edges %&gt;%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"date_added\" = \"_date_added\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"raw_source\" = \"_raw_source\",\n         \"algorithm\" = \"_algorithm\") \n\n\n\n\n1.3.4 Splitting words in type column\nThe code chunk below combined the following steps:\n\nSplitting the words by “.” - after observing that the format for type is as such: “Event.TransportEvent.TransponderPing”\nThe max(lengths(word_list)) will be used to find the maximum number of elements in any split.\nApply function(x) to pad shorter splits with NA values to make them all the same length.\nCreate word_df and changing column names to event1 etc.\nConvert word_df from matrix into tibble data.frame, and checks its class.\nAppend word_df to mc2_edges tibble data.frame.\nSaving mc2_edges into R rds format as a physical file, so that there is no need to repeat the following code chunk to access a tidy mc2_edges tibble data frame.\n\n\n\nShow the code\nword_list &lt;- strsplit(mc2_edges$type, \"\\\\.\")\n\nmax_elements &lt;- max(lengths(word_list))\n\nword_list_padded &lt;- lapply(word_list, \nfunction(x) c(x, rep(NA, max_elements - length(x))))\n\nword_df &lt;- do.call(rbind, word_list_padded)\ncolnames(word_df) &lt;- paste0(\"event\", 1:max_elements)\n\nword_df &lt;- as_tibble(word_df) %&gt;%\n  select(event2, event3)\nclass(word_df)\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nShow the code\nmc2_edges &lt;- mc2_edges %&gt;%\n  cbind(word_df)\n\n# prior to running this code, create an rds folder in data folder to ensure files are saved in the correct directory\nwrite_rds(mc2_edges, \"data/rds/mc2_edges.rds\")"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-nodes",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#wrangling-and-tidying-nodes",
    "title": "Take Home Exercise 3",
    "section": "1.4 Wrangling and tidying nodes",
    "text": "1.4 Wrangling and tidying nodes\n\n1.4.1 Extracting nodes\nThe code chunk below will be used to extract the nodes data.frame of mc2_data and parses it as a tibble data.frame called mc2_nodes.\n\n\nShow the code\nmc2_nodes &lt;- as_tibble(mc2_data$nodes) %&gt;%\n  distinct()\n\n\nNext, take a glimpse() to understand the data structure.\n\n\nShow the code\nglimpse(mc2_nodes)\n\n\nRows: 5,637\nColumns: 20\n$ type                 &lt;chr&gt; \"Entity.Commodity.Fish\", \"Entity.Commodity.Fish\",…\n$ `_last_edited_by`    &lt;chr&gt; \"Clepper Jessen\", \"Clepper Jessen\", \"Haenyeo Hyun…\n$ `_date_added`        &lt;chr&gt; \"2033-09-04T00:00:00\", \"2034-01-21T00:00:00\", \"20…\n$ `_last_edited_date`  &lt;chr&gt; \"2035-01-25T00:00:00\", \"2035-01-04T00:00:00\", \"20…\n$ `_raw_source`        &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"Oceanus:…\n$ `_algorithm`         &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ name                 &lt;chr&gt; \"Cod/Gadus n.specificatae\", \"Birdseye/Pisces frig…\n$ id                   &lt;chr&gt; \"gadusnspecificatae4ba\", \"piscesfrigus900\", \"pisc…\n$ Name                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Haacklee…\n$ Description          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Activities           &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, …\n$ kind                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"city\", \"…\n$ qty_tons             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ date                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ flag_country         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ company              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ tonnage              &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ length_overall       &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ style                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ fish_species_present &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, …\n\n\nFrom the table above, beside the date data type, inappropriate field name, and treatment for type column issues we discussed earlier, two additional data issues can be observed. They are:\n\nThe values in Activities and fish_species_present fields are in list data type, which will affect the ability to process and to analyse the data.\nSome values in the Activities field are not ready to be analyse without further tidying (i.e. removing c(““)).\n\nWe will first repeat the steps similar steps to wrangling the mc2_edges, before proceeding to tackle the issues for Activities and fish_species_present field.\n\n\n1.4.2 Correcting the date data type with lubridate()\nCorrect the date data type and take a glimpse() to confirm changes.\n\n\nShow the code\nmc2_nodes$`_last_edited_date` &lt;- as_datetime(mc2_nodes$`_last_edited_date`)\nmc2_nodes$`_date_added` &lt;- as_datetime(mc2_nodes$`_date_added`)\nmc2_nodes$date &lt;- as_datetime(mc2_nodes$date)\nglimpse(mc2_nodes)\n\n\nRows: 5,637\nColumns: 20\n$ type                 &lt;chr&gt; \"Entity.Commodity.Fish\", \"Entity.Commodity.Fish\",…\n$ `_last_edited_by`    &lt;chr&gt; \"Clepper Jessen\", \"Clepper Jessen\", \"Haenyeo Hyun…\n$ `_date_added`        &lt;dttm&gt; 2033-09-04, 2034-01-21, 2033-06-22, 2033-11-24, …\n$ `_last_edited_date`  &lt;dttm&gt; 2035-01-25, 2035-01-04, 2035-01-14, 2035-01-14, …\n$ `_raw_source`        &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"Oceanus:…\n$ `_algorithm`         &lt;chr&gt; \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n$ name                 &lt;chr&gt; \"Cod/Gadus n.specificatae\", \"Birdseye/Pisces frig…\n$ id                   &lt;chr&gt; \"gadusnspecificatae4ba\", \"piscesfrigus900\", \"pisc…\n$ Name                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"Haacklee…\n$ Description          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ Activities           &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, …\n$ kind                 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"city\", \"…\n$ qty_tons             &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ date                 &lt;dttm&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ flag_country         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ company              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ tonnage              &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ length_overall       &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ style                &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ fish_species_present &lt;list&gt; &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, &lt;NULL&gt;, …\n\n\n\n\n1.4.3 Changing field name\nIn the code chunk below, rename() of dplyr package is used to change the following fields.\n\n\nShow the code\nmc2_nodes &lt;- mc2_nodes %&gt;%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"date_added\" = \"_date_added\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"raw_source\" = \"_raw_source\",\n         \"algorithm\" = \"_algorithm\") \n\n\n\n\n1.4.4 Splitting words in type column\nDetails on the code chunk can be found in section 1.3.4. At this point, we will not be saving the mc2_nodes as R rds format yet, as there are more works to be done to clean up the dataframe.\n\n\nShow the code\nword_list &lt;- strsplit(mc2_nodes$type, \"\\\\.\")\n\nmax_elements &lt;- max(lengths(word_list))\n\nword_list_padded &lt;- lapply(word_list, \nfunction(x) c(x, rep(NA, max_elements - length(x))))\n\nword_df &lt;- do.call(rbind, word_list_padded)\ncolnames(word_df) &lt;- paste0(\"entity\", 1:max_elements)\n\nword_df &lt;- as_tibble(word_df) %&gt;%\n  select(entity2, entity3,entity4)\nclass(word_df)\n\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nShow the code\nmc2_nodes &lt;- mc2_nodes %&gt;%\n  cbind(word_df)\n\n\n\n\n1.4.5 Tidying text field\nUsing mutate() of dplyr and gsub() of Base R to tidy up the values in the cell. Essentially, the unwanted characters like c, (, ), and \\ are removed by substituting with empty value \"\" for both Activities and fish_species_present columns. What is left in the columns will be characters separated by ,.\n\n\nShow the code\nmc2_nodes &lt;- mc2_nodes %&gt;%\n  mutate(Activities = gsub(\"c[(]\", \"\", Activities)) %&gt;% \n  mutate(Activities = gsub(\"\\\"\", \"\", Activities)) %&gt;%\n  mutate(Activities = gsub(\"[)]\", \"\", Activities))\n\n\n\n\nShow the code\nmc2_nodes &lt;- mc2_nodes %&gt;%\n  mutate(fish_species_present = gsub(\"c[(]\", \"\", fish_species_present)) %&gt;% \n  mutate(fish_species_present = gsub(\"\\\"\", \"\", fish_species_present)) %&gt;%\n  mutate(fish_species_present = gsub(\"[)]\", \"\", fish_species_present)) \n\nmc2_nodes$entity3[5342] = \"Ferry_Cargo\"\nmc2_nodes$entity3[5461] = \"Ferry_Cargo\"\nmc2_nodes$entity3[5332] = \"Ferry_Passenger\"\nmc2_nodes$entity3[5452] = \"Ferry_Passenger\"\nmc2_nodes$entity3[5484] = \"Ferry_Passenger\"\n\n\nLastly, we will save the tidied mc2_nodes\n\n\nShow the code\n# prior to running this code, create an rds folder in data folder to ensure files are saved in the correct directory\nwrite_rds(mc2_nodes, \"data/rds/mc2_nodes.rds\")"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#extracting-the-required-columns-for-each-graph",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#extracting-the-required-columns-for-each-graph",
    "title": "Take Home Exercise 3",
    "section": "1.5 Extracting the required columns for each graph",
    "text": "1.5 Extracting the required columns for each graph\nIn this section, we will extract the required column for the following graphs:\n\nVessel Movements\nHarbor Reports\nHarbor Import Records\n\n\n1.5.1 Vessel Movements\nVessel Movements: Oceanus is outfitted with a transponder/ping system named the Oceanus Vessel Locator System (OVLS).  Vessels are outfitted with a transponder and periodic ‘pings’ from base-stations results in a report of vessel locations at any time.  The raw ping granularity is at the minute-level but post-processing has converted it into visit/dwell times. OVLS is generally reliable, though vessel records may be missing for a variety of reasons.\nNode/Edge types and properties present\n\nEntity.Vessel: Description of the vessel\nEntity.Location: Description of a geographic location\nEvent.TransponderPing: Links a vessel to a location\n\nFirst, we will extract the relevant nodes, namely the vessels and locations from mc2_nodes.\n\n\nShow the code\nvessel_mvmt_nodes &lt;- mc2_nodes %&gt;% \n  filter(entity2 %in% c(\"Vessel\",\"Location\")) \n\n\nNext, we will extract the vessel movement edges from mc2_edges, by filtering the “TransponderPing” from event3 column.\n\n\nShow the code\nvessel_mvmt_edges &lt;- mc2_edges %&gt;% \n  filter(event3 %in% c(\"TransponderPing\"))\n\n\n\n\nShow the code\nvessel_movement_data &lt;- vessel_mvmt_edges %&gt;% \n  filter(event3 %in% c(\"TransponderPing\")) %&gt;%\n  select(time, dwell, source, target) %&gt;% \n  mutate(source = gsub(\"^City of\", \"\", source)) %&gt;%\n  mutate(source = gsub(\"^\\\\s+\", \"\", source)) %&gt;%\n  left_join(oceanus_locations_df,\n            by = c(\"source\" = \"Name\"))\n\n\n\n\n1.5.2 Harbor Reports\nHarbor Reports: Harbor masters regularly report the vessels found in their purview anytime during the day.  This data is derived from a different system than OVLS (see “Vessel Movements”), though the data overlaps.  Harbor Reports are provided on a different schedule from different harbors. Since no harbor reports every day, this data has lower temporal granularity than vessel movement data. Additionally, the Harbor Master is also responsible for proximate navigational beacon(s), so this data has lower spatial granularity as well.  However, the list of vessels observed is considered canonical.\nNode/edge types present:\n\nEntity.Vessel\nEntity.location\nEvent.HarborReport\n\nSince the node type are the same as the vessel movements, we will make a copy of the node from vessel movement nodes.\n\n\nShow the code\nharbor_report_nodes &lt;- vessel_mvmt_nodes\n\n\nNext, we will extract the harbor report edges from mc2_edges, by filtering the “HarborReport” from event3 column.\n\n\nShow the code\nharbor_report_edges &lt;- mc2_edges %&gt;% \n  filter(event2 %in% c(\"HarborReport\"))\n\n\n\n\n1.5.3 Harbor Import Records\nHarbor Import Records: Vessels deliver cargo to the ports, and that cargo is brought into Oceanus.  These records reflect the goods that *leave* the harbor to go to businesses in Oceanus or to be exported.  It was filtered pre-ingest to focus on the delivery of raw fish.  Because it is raw, fish leave the port quickly (generally one day after delivery).  Due to clerical error, the records purchased by FishEye do not include the vessel that delivered the cargo.\nNode/Edge types present:\n\nEntity.location\nEntity.Commodity.Fish\nEntity.Document.DeliveryReport\nEvent.Transaction\n\nFirst, we will extract the relevant nodes, namely the location, commodity.fish and document.delivery report from mc2_nodes.\n\n\nShow the code\nharbor_import_records_nodes &lt;- mc2_nodes %&gt;% \n  filter(entity2 %in% c(\"Location\",\"Commodity\",\"Document\"))\n\n\nNext, we will extract harbor import records edges, by filtering the event2 with value of “Transaction”.\n\n\nShow the code\nharbor_import_records_edges &lt;- mc2_edges %&gt;% \n  filter(event2 == \"Transaction\")\n\n\nBefore we move on to exploring the data, we will save the 3 sources edges and nodes tibble data frame as R rds format in the data/rds folder:\n\n\nShow the code\nwrite_rds(vessel_mvmt_nodes, \"data/rds/vessel_mvmt_nodes.rds\")\nwrite_rds(vessel_mvmt_edges, \"data/rds/vessel_mvmt_edges.rds\")\nwrite_rds(vessel_movement_data, \"data/rds/vessel_movement_data.rds\")\nwrite_rds(harbor_report_nodes, \"data/rds/harbor_report_nodes.rds\")\nwrite_rds(harbor_report_edges, \"data/rds/harbor_report_edges.rds\")\nwrite_rds(harbor_import_records_nodes, \"data/rds/harbor_import_records_nodes.rds\")\nwrite_rds(harbor_import_records_edges, \"data/rds/harbor_import_records_edges.rds\")\n\n\n\n\nShow the code\nunique(mc2_edges$type)\n\n\n[1] \"Event.TransportEvent.TransponderPing\"\n[2] \"Event.Transaction\"                   \n[3] \"Event.HarborReport\""
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#task-1-flow-of-commercially-caught-fish",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#task-1-flow-of-commercially-caught-fish",
    "title": "Take Home Exercise 3",
    "section": "2.0 Task 1: Flow of Commercially Caught Fish",
    "text": "2.0 Task 1: Flow of Commercially Caught Fish\nIn this section, we focus on a few key areas to understand how the commercially caught fish flows from the vessels through the various ports:\n\nAssociating the vessels with their probable cargoes\nWhich vessels deliver which products and when?\nExamine the seasonal trends and anomalies in the port exit records"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#associating-the-vessels-with-their-probable-cargoes",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#associating-the-vessels-with-their-probable-cargoes",
    "title": "Take Home Exercise 3",
    "section": "2.1 Associating the vessels with their probable cargoes",
    "text": "2.1 Associating the vessels with their probable cargoes\nMatching the vessel with the import_record\nWe will use the vessel_nodes that contains information on the movement of fishing vessels and cargoes, and define the vessels location, start time and end time of the vessels in the particular location using transponder ping.\n\n\nShow the code\nfishing_and_cargo_vessel_list &lt;- vessel_nodes %&gt;% \n  filter(type %in% c(\"FishingVessel\", \"CargoVessel\")) %&gt;% \n  select(vessel)\n\nfishing_and_cargo_vessel_list &lt;- as.list(fishing_and_cargo_vessel_list)\n\nvessel_location &lt;- vessel_movement %&gt;% \n  filter(vessel %in% unlist(fishing_and_cargo_vessel_list)) %&gt;% \n  arrange(vessel,time) %&gt;% \n  mutate(next_time = ifelse(lead(vessel) == vessel, lead(time), NA)) %&gt;% \n  mutate(next_time = as_datetime(next_time))   %&gt;% \n  mutate(end_time = time + dwell)\n\nvessel_location_city &lt;- vessel_location %&gt;% \n  filter(loc_short %in% c(\"Haacklee\",\n                       \"Lomark\",\n                       \"Himark\",\n                       \"Paackland\",\n                       \"South Paackland\",\n                       \"Port Grove\"))\n\n\nVessel Location based on harbor report\nThe next step we do is to extract the date, location and vessel from the harbor report. Since this is describe as canonical, it should be considered for matching first before using the vessel location data from transponder ping. Columns are renamed to match the information in the cargo_list.\n\n\nShow the code\nvessel_mvmt_hr &lt;- harbor_report %&gt;% \n  select(vessel, city, date) %&gt;% \n  rename(vessel_delivery_date = date)\n\n\nMerging import_record and vessel_mvmt_hr\nAdding one column on vessel delivery date, which is 1 day before the date stated in the harbor import record.\n\n\nShow the code\ncargo_list &lt;- import_record %&gt;% \n  mutate(vessel_delivery_date = cargo_delivery_date + days(-1))\n\n\nSaving cargo_list:\n\n\nShow the code\nwrite_rds(cargo_list, \"data/rds/cargo_list.rds\")\n\n\n\n\nShow the code\nvessel_location_match_hr &lt;- cargo_list %&gt;% \n  left_join(vessel_mvmt_hr ) %&gt;%\n  filter(if_all(c(qty_tons,vessel), ~ !is.na(.))) %&gt;% \n  distinct()\n\n\n\n\nShow the code\nwrite_rds(vessel_location_match_hr, \"data/rds/vessel_location_match_hr.rds\")\n\n\n\n\nShow the code\nhr_match &lt;- mc2_nodes %&gt;% \n  select(id,Name,flag_country, company, tonnage,entity3) %&gt;% \n  rename(vessel = id) %&gt;% \n  left_join(vessel_location_match_hr) %&gt;%   \n  filter(if_all(c(qty_tons, tonnage), ~ !is.na(.))) %&gt;% \n  distinct() %&gt;% \n  filter()\n\n\nMerging cargo_list and vessel_location_city\n\n\nShow the code\nvessel_location_city &lt;- vessel_location_city %&gt;% \n  mutate(date = substr(`time`,1,10)) %&gt;% \n  mutate(vessel_delivery_date = ymd(date))  %&gt;% \n  filter(dwell &gt; 0)\n\n\n\n\nShow the code\nvessel_location_match &lt;- vessel_location_city %&gt;% \n  left_join(cargo_list, \n            unmatched = \"drop\") %&gt;%\n  filter(if_all(c(qty_tons), ~ !is.na(.))) %&gt;% \n  distinct()\n\n\nVessel Match Graph\n\n\nShow the code\nid1 &lt;- vessel_location_match_hr  %&gt;% \n  select(vessel) %&gt;% \n  rename(id = vessel) \n\nid2 &lt;- vessel_location_match_hr  %&gt;% \n  select(cargo) %&gt;% \n  rename(id = cargo)\n\ncargo_vessel_nodes &lt;- rbind(id1,id2) %&gt;% \n  distinct() \n\ncargo_vessel_edges &lt;- vessel_location_match_hr %&gt;% \n  select(vessel,cargo, fish, city) %&gt;% \n  distinct() %&gt;%\n  group_by(vessel, cargo) %&gt;%\n  rename(source = vessel, target = cargo)%&gt;%\n  filter(source!=target) %&gt;% \n  ungroup()\n\ncargo_vessel_graph &lt;- tbl_graph(nodes = cargo_vessel_nodes,\n                       edges = cargo_vessel_edges,\n                       directed = FALSE)\n\n\n\n\nShow the code\ncargo_vessel_graph %&gt;%\n  ggraph(layout = 'fr') +\n  geom_edge_link() +\n  geom_node_point() + \n  theme_graph()\n\n\n\n\n\n\n\n\n\nFinding anomalies in vessel movement by comparing end time (calculated by dwell) with next time (the next time the vessel is detected at the next location).\n\n\nShow the code\nab_vessel_mvmt &lt;- vessel_location %&gt;%\n  mutate(time = ymd_hms(time)) %&gt;% \n  mutate(next_time = ymd_hms(next_time)) %&gt;% \n  mutate(end_time = ymd_hms(end_time)) %&gt;% \n  filter(end_time != next_time) \n\nab_vessel_mvmt_agg &lt;- ab_vessel_mvmt %&gt;% \n  distinct() %&gt;% \n  group_by(vessel) %&gt;% \n  summarise(weights = n()) %&gt;%\n  arrange(desc(weights))\nab_vessel_mvmt_agg\n\n\n# A tibble: 277 × 2\n   vessel                 weights\n   &lt;chr&gt;                    &lt;int&gt;\n 1 brooktroutbuccaneerc0b     151\n 2 bluemarlinbandit292        149\n 3 halibuthero9b9             146\n 4 catchcruisera94            145\n 5 bluefishbandit8ec          138\n 6 tenchtaker595              133\n 7 deepseadrifter9f2          132\n 8 whitefishwrangler7df       132\n 9 yellowfintunataker08b      130\n10 rainbowtroutraider4d0      129\n# ℹ 267 more rows"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#examine-the-seasonal-trends-and-anomalies-in-the-port-exit-records",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#examine-the-seasonal-trends-and-anomalies-in-the-port-exit-records",
    "title": "Take Home Exercise 3",
    "section": "2.3 Examine the seasonal trends and anomalies in the port exit records",
    "text": "2.3 Examine the seasonal trends and anomalies in the port exit records\n\n2.3.1 Seasonal trends in port exit records\n\n\nShow the code\nimport_record1 &lt;- import_record %&gt;% \n  mutate(year = year(cargo_delivery_date),\n         month = month(cargo_delivery_date, label = TRUE),\n         day = day(cargo_delivery_date),\n         week = week(cargo_delivery_date),\n         weekday = wday(cargo_delivery_date, label = TRUE, week_start = 1))\n\n# Create an overall Oceanus heat map for all types of fish\nfish_agg &lt;- import_record1  %&gt;%\n  distinct() %&gt;%\n  group_by(fish,month) %&gt;%\n  summarise(total_qty_tons = sum(qty_tons)) %&gt;% \n  ungroup()\n\nggplot(fish_agg, aes(x = month, y = fish, fill = total_qty_tons)) +\n    geom_tile(color = \"white\") +\n    scale_fill_gradient(low = \"white\", high = \"blue\") +\n    labs(title = paste(\"Calendar Heatmap for fish in Oceanus\"),\n         x = \"Month of the Year\",\n         y = \"Fish Type\",\n         fill = \"Total Quantity (tons)\") +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Function to create a calendar heat map\ncreate_heatmap &lt;- function(data, city) {\n  ggplot(data, aes(x = month, \n                   y = fish, \n                   fill = total_qty_tons)) +\n    geom_tile(color = \"white\") +\n    scale_fill_gradient(low = \"white\", high = \"blue\") +\n    labs(title = paste(\"Calendar Heatmap for fish in\", city),\n         x = \"Month of the Year\",\n         y = \"Fish Type\",\n         fill = \"Total Quantity (tons)\") +\n    theme_minimal()\n}\n\n\n\n\nShow the code\nfish_by_port_agg &lt;- import_record1 %&gt;% \n  group_by(city,fish,month) %&gt;% \n  summarise(total_qty_tons = sum(qty_tons))\n\n\n\n\nShow the code\n# Create an empty list to store heatmaps\nheatmaps &lt;- list()\n\n# Iterate over each city\ncities &lt;- unique(cargo_list$city)\nfor (c in cities) {\n  # Filter the data for the current city\n  heatmap_data &lt;- fish_by_port_agg %&gt;% \n    filter(city == c)\n  \n  # Create the heatmap for the current city\n  heatmap &lt;- create_heatmap(heatmap_data, c)\n  \n  # Store the heatmap in the list\n  heatmaps[[c]] &lt;- heatmap\n}\n\n# Print or visualize the heatmaps\nfor (c in cities) {\n  print(heatmaps[[c]])\n}"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#understanding-the-types-of-fish-that-should-not-be-in-the-market",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#understanding-the-types-of-fish-that-should-not-be-in-the-market",
    "title": "Take Home Exercise 3",
    "section": "2.3.1 Understanding the types of fish that should not be in the market",
    "text": "2.3.1 Understanding the types of fish that should not be in the market\n\n\nShow the code\n# Create an empty list to store heatmaps\nheatmaps &lt;- list()\n\n# Iterate over each city\ncities &lt;- unique(cargo_list$city)\nfor (c in cities) {\n  # Filter the data for the current city\n  heatmap_data &lt;- fish_by_port_agg %&gt;% \n    filter(city == c) %&gt;% \n    filter(fish %in% c(\"Sockfish\", \"Offidiaa\", \"Helenaa\"))\n  \n  # Create the heatmap for the current city\n  heatmap &lt;- create_heatmap(heatmap_data, c)\n  \n  # Store the heatmap in the list\n  heatmaps[[c]] &lt;- heatmap\n}\n\n# Print or visualize the heatmaps\nfor (c in cities) {\n  print(heatmaps[[c]])\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from this visualisation\n\n\n\n\nFrom this heatmap above, we understand that there is an abnormal increase in Sockfish catch from May onwards, and abnormal increase in Offidiaa catch from September onwards , which are species unique to the Don Limpet Preserve and Ghoti Preserve respectively.\nProbable reason for this is that since SouthSeafood Express Corp was caught in mid-May for illegal fishing in Ghoti Preserve, other illegal fishing vessels made a switch to Don Limpet Reserves to fish."
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#task-2",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#task-2",
    "title": "Take Home Exercise 3",
    "section": "3.0 Task 2",
    "text": "3.0 Task 2\nDevelop visualizations that illustrate the inappropriate behavior of SouthSeafood Express Corp vessels. How do their movement and catch contents compare to other fishing vessels? When and where did SouthSeafood Express Corp vessels perform their illegal fishing? How many different types of suspicious behaviors are observed? Use visual evidence to justify your conclusions."
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#illegal-fishing-by-southseafood-express-corp",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#illegal-fishing-by-southseafood-express-corp",
    "title": "Take Home Exercise 3",
    "section": "3.1 Illegal fishing by SouthSeafood Express Corp",
    "text": "3.1 Illegal fishing by SouthSeafood Express Corp\nSouthSeafood Express Corp operates two fishing vessels by the id of “snappersnatcher7be” and “roachrobberdb6”.\n\n\nShow the code\nvessel_movement_agg &lt;-\n  vessel_movement %&gt;%\n  distinct() %&gt;%\n  group_by(loc, vessel, type) %&gt;%\n  summarise(weights = n()) %&gt;%\n  ungroup()\n\n\n\n\nShow the code\nvessel_movement_agg %&gt;% \n  filter(vessel %in% c(\"snappersnatcher7be\",\"roachrobberdb6\")) %&gt;%\n  group_by(vessel) %&gt;% \n  ggplot(aes(x=vessel, y=loc,\n             size = weights)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n3.1.1 When and where did SouthSeafood Express Corp vessels perform their illegal fishing?\nSince only Snapper Snatcher appears to be operating in Ghoti Preserve, we will examine this fishing vessel more closely.\n\n\nShow the code\nsnapper_activities &lt;- vessel_movement %&gt;% \n  filter(vessel %in% c(\"snappersnatcher7be\")) %&gt;% \n  filter(loc == \"Ghoti Preserve\") %&gt;% \n  arrange(vessel,time) %&gt;% \n  mutate(end_time = time + dwell) %&gt;% \n  select(time, dwell, end_time)\nsnapper_activities\n\n\n                 time      dwell            end_time\n1 2035-02-02 05:39:59 282000.853 2035-02-05 12:00:00\n2 2035-02-09 05:49:11 281448.765 2035-02-12 12:00:00\n3 2035-02-16 07:02:09 277070.841 2035-02-19 12:00:00\n4 2035-03-15 05:46:02   6410.348 2035-03-15 07:32:52\n\n\nThere three instances (2,9 and 16 Feb) where Snapper Snatcher stayed at the Ghoti Preserve for over 3 days. These are the instances where SouthSeafood Express Corp’s Snapper Snatcher conducted IUU Fishing in Ghoti Preserve.\n\n\n3.1.2 Visualising Vessel Trajectory\nIn the code chunk below, st_as_sf() of sf package is used to convert vessel_movement_data data.frame into sf point data.frame by using values in XCOORD and YCOORD columns. The output is an sf data.frame called vessel_movement_sf.\n\n\nShow the code\nvessel_movement_data &lt;- read_rds(\"data/rds/vessel_movement_data.rds\")\n\nvessel_movement_sf &lt;- vessel_movement_data %&gt;%\n  st_as_sf(coords = c(\"XCOORD\", \"YCOORD\"), \n           crs = 4326)\n\n\nNext arrange() is used to sort the records according to the vessels’ name (i.e. target) and navigation time (i.e. time)\n\n\nShow the code\nvessel_movement_sf &lt;- vessel_movement_sf %&gt;%\n  arrange(target, time)\n\n\nLastly, st_cast() of sf package is used to convert vessel_movement_sf from point features into linestring features called vessel_trajectory.\n\n\nShow the code\nvessel_trajectory &lt;- vessel_movement_sf %&gt;%\n  group_by(target) %&gt;%\n  summarize(do_union = FALSE) %&gt;%\n  st_cast(\"LINESTRING\")\n\n\nSelecting SouthSeafood Express vessels\n\n\nShow the code\nvessel_trajectory_selected &lt;- vessel_trajectory %&gt;%\n  filter(target %in% c(\"snappersnatcher7be\", \"roachrobberdb6\"))\n\n\nNext, appropriate functions of ggplot2 is used to plot the selected vessel trajectories by using the code chunk below.\n\n\nShow the code\nggplot() +\n  geom_sf(data = oceanus_geography) +\n  geom_sf(data = vessel_trajectory_selected, \n          aes(color = factor(target)), \n          size = 1) +\n  theme_minimal() +\n  labs(title = \"Trajectories of SouthSeafood Express Vessels\", \n  x = \"Longitude\", y = \"Latitude\", color = \"ID\")"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#task-4",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#task-4",
    "title": "Take Home Exercise 3",
    "section": "4.0 Task 4",
    "text": "4.0 Task 4\nThe Questions:\n\nHow did fishing activity change after SouthSeafood Express Corp was caught?\nWhat new behaviors in the Oceanus commercial fishing community are most suspicious and why?\n\nIn order to understand the change in fishing activities, we first have to determine the date where SouthSeafood Express Corp was caught. We will use this timeline as the\nThe final activities of SouthSeafood’s vessels are on 2035-05-16 (snappersnatcher7be) and 2035-05-16 (roachrobberdb6) according to the transponder pings. Hence, we can conclude that the SouthSeafood is caught for illegal fishing, and had ceased operating its fishing vessels since 2035-05-16."
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#changes-in-commercial-fishing",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#changes-in-commercial-fishing",
    "title": "Take Home Exercise 3",
    "section": "4.1 Changes in Commercial Fishing",
    "text": "4.1 Changes in Commercial Fishing\nFirstly, we take a look at the species caught across the months (Feb to Nov 2035).\n\n\nShow the code\n# Create an overall Oceanus heat map for all types of fish\nfish_agg &lt;- fish_by_port_agg  %&gt;%\n  distinct() %&gt;%\n  group_by(fish,month) %&gt;%\n  summarise(total_qty_tons = sum(total_qty_tons)) \n\noceanus_heatmap &lt;- ggplot(fish_agg, aes(x = month, y = fish, fill = total_qty_tons)) +\n    geom_tile(color = \"white\") +\n    scale_fill_gradient(low = \"white\", high = \"blue\") +\n    labs(title = paste(\"Calendar Heatmap for fish in Oceanus\"),\n         x = \"Month of the Year\",\n         y = \"Fish Type\",\n         fill = \"Total Quantity (tons)\") +\n    theme_minimal() +\n  geom_vline(xintercept = \"May\",color = 'red', linetype = 'dashed') +\n  annotate(\"text\", x = \"May\" , y = \"Offidiaa\", label = \"SouthSeafood caught\", angle = 90, vjust = -0.5, hjust = 0.5, color = \"red\")\n\n\n\n\nShow the code\n# Order them based on 3 Preserves and 3 Fishing Ground\ndesired_order &lt;- c(\"Ghoti Preserve\", \"Nemo Reef\", \"Don Limpet Preserve\",\"Cod Table\", \"Wrasse Beds\",\"Tuna Shelf\")  \n\nregion_fish_species_long$Name &lt;- factor(region_fish_species_long$Name, levels = desired_order)\n\nspecies_plot &lt;-ggplot(region_fish_species_long, aes(x = Name, \n                                     y = Presence,\n                                     colour = Presence)) +\n  geom_point() +\n  labs(title = \"Species Presence by Name\",\n       x = \"Name\",\n       y = \"Species\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\")\n\n\n\n\nShow the code\noceanus_heatmap / species_plot\n\n\n\n\n\n\n\n\n\nFor recapitulation, we know that Sockfish, Offidiaa, and Helenaa are fish species that are unique to the three Preserves. From the two plots above, we can derive initial conclusion that there is an usual increase in Sockfish catch after SouthSeafood was caught in mid-May. We also see a minor increase in Helenaa between Jun to Aug, and later in Oct to Nov. The spike in Offidiaa catch begins in Sep and grows gradually to Nov.\nCombining the information above, we can make the following two hypothesis about the changes in fishing activities in Oceanus after SouthSeafood was caught:\n\nThe fishing vessels switched to Don Limpet Preserve for IUU fishing. Tell tale sign is the increase in Sockfish catch, which is species unique to Don Limpet Preserve. This also explains the slight increase in Helena catch from Jun.\nThe fishing vessels moved into Ghoti Preserves from Sep onwards for IUU fishing. Tell tale sign is the increase in Offidia catch from Sep, which is species unique to Ghoti Preserve.\n\nFor confirmation, we take a look at the changes to OVLS Transponder Ping, comparing the total pings to various Fishing Grounds and Preserves month by month.\n\n\nShow the code\nvessel_movement_long &lt;- vessel_movement %&gt;% \n  filter(type == \"FishingVessel\") %&gt;%\n  filter(loc %in% c(\"Ghoti Preserve\", \n                       \"Nemo Reef\", \n                       \"Don Limpet Preserve\",\n                       \"Cod Table\", \n                       \"Wrasse Beds\",\n                       \"Tuna Shelf\")) %&gt;% \n  mutate(month = month(time)) %&gt;% \n  select(loc, vessel, month) %&gt;% \n  group_by(loc, month) %&gt;% \n  summarize(n = n()) \n\n\n\n\nShow the code\nvessel_movement_long %&gt;% \n  mutate(month = as.factor(month)) %&gt;% \n  newggslopegraph(month,n, loc,\n                Title = \"Changes in Visit Frequency\",\n                SubTitle = \"across Feb to Nov 2035\",\n                Caption = \"Prepared by: Liang Xiuhao\")\n\n\n\n\n\n\n\n\n\nIn the line graph below, we observe that the overall fishing vessels activities in the fishing ground and preserves dropped.\n\n\nShow the code\naverage &lt;- vessel_movement %&gt;% \n  filter(type == \"FishingVessel\") %&gt;%\n  filter(loc %in% c(\"Ghoti Preserve\", \n                       \"Nemo Reef\", \n                       \"Don Limpet Preserve\",\n                       \"Cod Table\", \n                       \"Wrasse Beds\",\n                       \"Tuna Shelf\")) %&gt;%\n  mutate(month = month(time)) %&gt;% \n  summarise(average = (n()/10))\n\nvessel_movement %&gt;% \n  filter(loc %in% c(\"Ghoti Preserve\", \n                       \"Nemo Reef\", \n                       \"Don Limpet Preserve\",\n                       \"Cod Table\", \n                       \"Wrasse Beds\",\n                       \"Tuna Shelf\")) %&gt;%\n  filter(type == \"FishingVessel\") %&gt;% \n  mutate(month = month(time)) %&gt;% \n  group_by(month) %&gt;% \n  summarise(n = as.numeric(n())) %&gt;%\n  ggplot(aes(x = month, y = n)) + \n  geom_line(color = \"blue\") +  \n  geom_point(size = 4, color = \"blue\") +\n  geom_text(aes(label = n), \n            vjust = -1,\n            size = 3) +\n  labs(title = \"Visit Frequency to All Fishing Grounds and Preserves by Month\",\n       x = \"Month\",\n       y = \"Frequency\") +\n  geom_hline(average, \n             yintercept = as.numeric(average), \n             color=\"black\",\n             linetype = 6) +\n  geom_point(x = 5, y = 13366,\n             size = 4, color = \"red\") +\n  geom_text(aes(x = 5, y = 13366, label = \"SouthSeafood caught\"),\n            color = \"red\",\n            hjust = -0.2,\n            size = 3) +\n  geom_text(aes(x = 4.5, y = 12000, label = \"Monthly Average = 11854\"),\n            color = \"black\",\n            size = 3) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nDerive monthly transponder ping:\n\n\nShow the code\nmonthly_vessel_movement &lt;- vessel_movement %&gt;% \n  filter(type == \"FishingVessel\") %&gt;%\n  filter(loc %in% c(\"Ghoti Preserve\", \n                       \"Nemo Reef\", \n                       \"Don Limpet Preserve\",\n                       \"Cod Table\", \n                       \"Wrasse Beds\",\n                       \"Tuna Shelf\")) %&gt;% \n  mutate(month = month(time)) %&gt;% \n  select(loc, vessel, month) %&gt;% \n  group_by(loc, month) %&gt;% \n  summarize(n = n()) \n\n\n\n\nShow the code\nmonthly_vessel_movement$month &lt;- factor(monthly_vessel_movement$month)\nmonthly_vessel_movement$loc &lt;- factor(monthly_vessel_movement$loc,\n                                             levels = c(\"Ghoti Preserve\", \n                                                        \"Nemo Reef\",\n                                                        \"Don Limpet Preserve\",\n                                                        \"Cod Table\",\n                                                        \"Wrasse Beds\",\n                                                        \"Tuna Shelf\"))\n\nhline.data &lt;- monthly_vessel_movement %&gt;% \n  group_by(loc) %&gt;%\n  summarise(avgvalue = mean(n))\n\nggplot(monthly_vessel_movement, \n       aes(x = month, \n           y = n, \n           group = loc, \n           color = loc)) +\n  geom_line(size = 1) +\n  geom_point(size = 2) +\n  facet_wrap(~ loc, scales = \"free_y\") +  \n  theme_minimal() +\n  labs(title = \"Changes in Visit Frequency by Month by Fishing Vessels\",\n       x = \"Month\",\n       y = \"No. of Visits\",\n       color = \"Source\") +\n  geom_hline(data = hline.data,\n             aes(yintercept = avgvalue),\n             linetype = 6,\n             color = \"black\",\n             size = 0.5) +\n  geom_text(data = hline.data, \n            aes(x = \"4\", y = avgvalue, label = \"Average\"), \n            hjust = 1, vjust = 1, \n            color = \"black\",\n            size = 3) +\n  geom_vline(aes(xintercept = 4),\n             linetype = 6,\n             color = \"red\",\n             size = 0.5) +\n  geom_text(data = hline.data, \n            aes(x = \"4\", y = avgvalue, label = \"SouthSeafood caught\"), \n            hjust = 1.5, vjust = 1.5,\n            angle = 90,\n            color = \"red\",\n            size = 2)\n\n\n\n\n\n\n\n\n\nFrom the plot above, we can see that after SouthSeafood was caught in mid-May, there is a drop in activities for all the fishing grounds and preserves immediately after mid-May, except for the increase in Don Limpet Preserve, from 1 in Mar and Jun to 2 observations in Aug.\n\n4.2 What new behaviors in the Oceanus commercial fishing community are most suspicious and why?"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#wrangling-of-geographical-data",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#wrangling-of-geographical-data",
    "title": "Take Home Exercise 3",
    "section": "1.2.2 Wrangling of Geographical Data",
    "text": "1.2.2 Wrangling of Geographical Data\nIn the code chunk below, st_coordinate() of sf package is used to extract coordinates from oceanus_locations sf data.frame.\n\n\nShow the code\ncoords &lt;- st_coordinates(oceanus_locations)\n\n\nNext, code chunk below is used to drop the geometry column of oceanus_locations of sf data.frame by using st_drop_geometry() of sf package and save the output into a new data.frame called oceanus_locations_df.\n\n\nShow the code\noceanus_locations_df &lt;- oceanus_locations %&gt;%\n  st_drop_geometry()\n\n\nThen, the code chunk below is to append the x- and y-coodinate values from coords list into the XCOORD and YCOORD columns of oceanus_locations_df respectively.\n\n\nShow the code\noceanus_locations_df$XCOORD &lt;- coords[, \"X\"]\noceanus_locations_df$YCOORD &lt;- coords[, \"Y\"]\n\n\nLastly, the code chunk below is used to tidy OceanusLocations_df by selecting the necessary columns only and at the same time, rename X.Kind to Loc_Type.\n\n\nShow the code\noceanus_locations_df &lt;- oceanus_locations_df %&gt;%\n  select(Name, X.Kind, XCOORD, YCOORD) %&gt;%\n  rename(Loc_Type = X.Kind)"
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#exploratory-data-analysis",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#exploratory-data-analysis",
    "title": "Take Home Exercise 3",
    "section": "1.6 Exploratory Data Analysis",
    "text": "1.6 Exploratory Data Analysis\n\n1.6.1 Understanding the Fish Species in each Region\nBefore we can detect anomalies in the for fishing activities, we first need to understand where are the fish species found in each Region.\n\n\nShow the code\nregion_fish_species &lt;- mc2_nodes %&gt;% \n  filter(entity3 == \"Region\") %&gt;% \n  select(Name, fish_species_present, Activities, kind) \n\n\n\n\nShow the code\nword_list &lt;- strsplit(region_fish_species$fish_species_present, \"\\\\,\")\n\nmax_elements &lt;- max(lengths(word_list))\n\nword_list_padded &lt;- lapply(word_list, \nfunction(x) c(x, rep(NA, max_elements - length(x))))\n\nword_df &lt;- do.call(rbind, word_list_padded)\ncolnames(word_df) &lt;- paste0(\"species\", 1:max_elements) \n\nword_df &lt;- as_tibble(word_df) %&gt;% \n  mutate(species1 = str_replace(species1, \"/.*\", \"\")) %&gt;% \n  mutate(species2 = str_replace(species2, \"/.*\", \"\")) %&gt;% \n  mutate(species3 = str_replace(species3, \"/.*\", \"\")) %&gt;% \n  mutate(species4 = str_replace(species4, \"/.*\", \"\")) %&gt;% \n  mutate(species5 = str_replace(species5 , \"/.*\", \"\")) %&gt;%\n  mutate_at(vars(species1:species5), trimws)\n\nregion_fish_species &lt;- region_fish_species %&gt;%\n  cbind(word_df)\n\n# Convert data to long format\nregion_fish_species_long &lt;- pivot_longer(region_fish_species, cols = starts_with(\"species\"), names_to = \"Species\", values_to = \"Presence\")\n\n# Filter out empty values and trim away leading and trailing whitespace\nregion_fish_species_long &lt;- region_fish_species_long[region_fish_species_long$Presence != \"\", ] %&gt;% \n  na.omit() %&gt;%\n  mutate_at(vars(Presence), trimws)\n\n\n\n\nShow the code\n# Order them based on 3 Preserves and 3 Fishing Ground\ndesired_order &lt;- c(\"Ghoti Preserve\", \"Nemo Reef\", \"Don Limpet Preserve\",\"Cod Table\", \"Wrasse Beds\",\"Tuna Shelf\")  \n\nregion_fish_species_long$Name &lt;- factor(region_fish_species_long$Name, levels = desired_order)\n\nggplot(region_fish_species_long, aes(x = Name, \n                                     y = Presence,\n                                     colour = Presence)) +\n  geom_point() +\n  labs(title = \"Species Presence in each Region\",\n       x = \"Region\",\n       y = \"Species\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from this visualisation\n\n\n\nEcological Preserves\nWe can derive that Sockfish, Offidiaa, and Helenaa species can only be found in the preserves but not in the fishing grounds. Therefore, any cargoes that contains these fish species (Sockfish, Offidiaa, and Helenaa) would have fished illegally. Below shows the visualisation of the species and qty_ton that flows through each city by months.\n\nSockfish: Only found in Don Limpet Preserve\nOffidiaa: Only found in Ghoti Preserve\nHelenaa: Only found in Ecological Preserves (all three)\n\nFishing Grounds\n\nCod: Only found in Cod Table\nHarland: Only found in Tuna Shelf\n\nOther notable point\n\nSalmon: Not found in any of the 6 locations mentioned above. This might be imports from other countries or from international shipping.\n\n\n\n\n\n1.6.2 Understanding the qty_tons of each Fish Species by City\nAfter identifying the three fish species (Sockfish, Offidiaa, and Helenaa) that are only found in the Ecological Preserves, we will have an overview of how each of the fish species are spread across the city.\n\n\nShow the code\n# Aggregate the qty_tons by fish and city\nqty_tons_agg &lt;- import_record %&gt;%\n  group_by(fish, city) %&gt;%\n  summarize(total_qty_tons = sum(qty_tons, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# Add distinct colors to flag out Sockfish, Offidiaa, and Helenaa\ncolor &lt;- c(\"Wrasse\" = \"#000099\",\n           \"Tuna\" = \"#0000CC\",\n           \"Harland\" = \"#0000FF\",\n           \"Cod\" = \"#3333FF\",\n           \"Birdseye\" = \"#6666FF\",\n           \"Beauvoir\" = \"#9999FF\",\n           \"Salmon\" = \"#CCCCFF\",\n           \"Helenaa\" = \"#FF99FF\",\n           \"Offidiaa\" = \"#FF00FF\",\n           \"Sockfish\" = \"#990099\")\n\n# Reorder to match the above \nqty_tons_agg$fish &lt;- factor(qty_tons_agg$fish,\n                            levels = c(\"Wrasse\",\"Tuna\",\n                                       \"Harland\",\"Cod\",\n                                       \"Birdseye\", \"Beauvoir\",\n                                       \"Salmon\",\"Helenaa\",\n                                       \"Offidiaa\",\"Sockfish\"))\n\n# Reorder city in descending order based on total_qty_tons\nqty_tons_agg$city &lt;- factor(qty_tons_agg$city,\n                            levels = c(\"City of Paackland\",\n                                       \"City of Himark\",\n                                       \"City of Lomark\",\n                                       \"City of South Paackland\",\n                                       \"City of Haacklee\"))\n\n# Bar plot\nggplot(qty_tons_agg, aes(x = city, \n                         y = total_qty_tons, \n                         fill = fish)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = color) +\n  labs(title = \"Quantity Tons of Fish by City and Fish Species\",\n       x = \"City\",\n       y = \"Total Quantity (tons)\",\n       fill = \"Fish Species\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n1.6.3 Understanding the number of cargoes of each Fish Species by City\n\n\nShow the code\n# Aggregate the qty_tons by fish and city\ncargo_n_agg &lt;- import_record %&gt;%\n  group_by(fish, city) %&gt;%\n  summarize(total_cargo = n()) %&gt;%\n  ungroup()\n\n# Add distinct colors to flag out Sockfish, Offidiaa, and Helenaa\ncolor &lt;- c(\"Wrasse\" = \"#000099\",\n           \"Tuna\" = \"#0000CC\",\n           \"Harland\" = \"#0000FF\",\n           \"Cod\" = \"#3333FF\",\n           \"Birdseye\" = \"#6666FF\",\n           \"Beauvoir\" = \"#9999FF\",\n           \"Salmon\" = \"#CCCCFF\",\n           \"Helenaa\" = \"#FF99FF\",\n           \"Offidiaa\" = \"#FF00FF\",\n           \"Sockfish\" = \"#990099\")\n\n# Reorder to match the above \ncargo_n_agg$fish &lt;- factor(cargo_n_agg$fish,\n                            levels = c(\"Wrasse\",\"Tuna\",\n                                       \"Harland\",\"Cod\",\n                                       \"Birdseye\", \"Beauvoir\",\n                                       \"Salmon\",\"Helenaa\",\n                                       \"Offidiaa\",\"Sockfish\"))\n\n# Reorder city in descending order based on total_qty_tons\ncargo_n_agg$city &lt;- factor(cargo_n_agg$city,\n                            levels = c(\"City of Paackland\",\n                                       \"City of Himark\",\n                                       \"City of Lomark\",\n                                       \"City of South Paackland\",\n                                       \"City of Haacklee\"))\n\n# Bar plot\nggplot(cargo_n_agg, aes(x = city, \n                         y = total_cargo, \n                         fill = fish)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = color) +\n  labs(title = \"Number of Cargoes by City and Fish Species\",\n       x = \"City\",\n       y = \"No. of Cargoes\",\n       fill = \"Fish Species\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from this visualisation\n\n\n\n\nBoth qty_tons and number of cargoes bar plots shows similar distribution of fish species within each city.\nThe City of Paackland processed the highest qty_tons and number of cargoes, follow by City of Himark, City of Lomark, City of South Paackalnd, and City of Hacklee.\n\n\n\n\n\n1.6.4 Understanding the Activities by Locations\nUnderstanding the activities in each of the locations.\n\n\nShow the code\nword_list &lt;- strsplit(location_nodes$Activities, \"\\\\,\")\n\nmax_elements &lt;- max(lengths(word_list))\n\nword_list_padded &lt;- lapply(word_list, \nfunction(x) c(x, rep(NA, max_elements - length(x))))\n\nword_df &lt;- do.call(rbind, word_list_padded)\ncolnames(word_df) &lt;- paste0(\"activity\", 1:max_elements) \n\nword_df &lt;- as_tibble(word_df) \n\nlocation_nodes1 &lt;- location_nodes %&gt;%\n  cbind(word_df)\n\n# Convert data to long format\nlocation_nodes_long &lt;- pivot_longer(location_nodes1, cols = starts_with(\"activity\"), names_to = \"activity\", values_to = \"Presence\")\n\n# Filter out empty values and trim away leading and trailing whitespace\nlocation_nodes_long &lt;- location_nodes_long[location_nodes_long$Presence != \"\", ] %&gt;% \n  mutate_at(vars(Presence), trimws) %&gt;% \n  filter(if_all(c(loc), ~ !is.na(.)))\n\nlocation_nodes_long$Presence[8] = \"Tourism\"\n\n\n\n\nShow the code\n# Order the locations\ndesired_order &lt;- c(\"City of Himark\",\n                   \"City of Lomark\",\n                   \"City of Haacklee\",\n                   \"City of Paackland\",\n                   \"City of South Paackland\",\n                   \"City of Port Grove\",\n                   \"Ghoti Preserve\", \n                   \"Nemo Reef\", \n                   \"Don Limpet Preserve\",\n                   \"Cod Table\", \n                   \"Wrasse Beds\",\n                   \"Tuna Shelf\",\n                   \"Exit North\",\n                   \"Exit South\",\n                   \"Exit East\",\n                   \"Exit West\",\n                   \"Nav 1\",\"Nav 2\", \"Nav 3\", \n                   \"Nav A\", \"Nav B\", \"Nav C\", \"Nav D\", \"Nav E\")  \n\nlocation_nodes_long$loc &lt;- factor(location_nodes_long$loc, levels = desired_order)\n\nggplot(location_nodes_long, aes(x = loc, \n                                y = Presence,\n                                colour = Presence)) +\n  geom_point() +\n  labs(title = \"Activities in each Location\",\n       x = \"Location\",\n       y = \"Activity\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Aggregate the transponder ping by location\nlocation_ping_agg &lt;- vessel_movement %&gt;%\n  group_by(loc, type) %&gt;%\n  summarize(total_ping = n()) %&gt;%\n  ungroup()\n\n\n# Reorder to match the above \nlocation_ping_agg$loc &lt;- factor(location_ping_agg$loc,\n                           levels = c(\"City of Himark\",\n                                      \"City of Lomark\",\n                                      \"City of Haacklee\",\n                                      \"City of Paackland\",\n                                      \"City of South Paackland\",\n                                      \"City of Port Grove\",\n                                      \"Ghoti Preserve\", \n                                      \"Nemo Reef\", \n                                      \"Don Limpet Preserve\",\n                                      \"Cod Table\", \n                                      \"Wrasse Beds\",\n                                      \"Tuna Shelf\",\n                                      \"Exit North\",\n                                      \"Exit South\",\n                                      \"Exit East\",\n                                      \"Exit West\",\n                                      \"Nav 1\",\"Nav 2\", \"Nav 3\", \n                                      \"Nav A\", \"Nav B\", \"Nav C\", \"Nav D\", \"Nav E\"))  \n\n# Bar plot\nggplot(location_ping_agg, aes(x = loc, \n                              y = total_ping, \n                              fill = type)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Number of Transponder Ping by Locations\",\n       x = \"Locations\",\n       y = \"No. of Transponder Ping\",\n       fill = \"Locations\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from this visualisation\n\n\n\n\nThere is abnormally high number of pings for fishing vessels at Nemo Reef. Since Nemo Reef is a Ecological Preserve, the correct safe navigation around it is through Nav D.\nGiven that the fish species (Wrasse, Tuna, Birdseye, Beauvoir) in Nemo Reef, can also be found in other fishing grounds, there is likelihood of IUU here. The presence of Helenaa is the only tell-tale sign if a fishing vessel indeed fish in Nemo Reef.\n\n\n\n\n\n1.6.5 Understanding the Harbor Report by Locations\n\n\nShow the code\n# Aggregate the harbor report by location\nharbor_report_agg &lt;- harbor_report %&gt;%\n  group_by(city, type) %&gt;%\n  summarize(total_report = n()) %&gt;%\n  ungroup()\n\n\n# Reorder to match the above \nharbor_report_agg$city&lt;- factor(harbor_report_agg$city,\n                           levels = c(\"City of Himark\",\n                                      \"City of Lomark\",\n                                      \"City of Haacklee\",\n                                      \"City of Paackland\",\n                                      \"City of South Paackland\",\n                                      \"City of Port Grove\"))\n                                        \n\n# Bar plot\nggplot(harbor_report_agg, aes(x = city, \n                              y = total_report, \n                              fill = type)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Number of Report by City\",\n       x = \"City\",\n       y = \"No. of Reports\",\n       fill = \"City\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from this visualisation\n\n\n\n\nThere is only Research and Tour vessels visiting City of Port Grove.\nThe other five cities have mostly fishing or cargo vessels visits.\n\n\n\n\n\n1.6.6 Understanding the Cargoes\nCargoes by Quantity in Ton\n\n\nShow the code\n# Calculate Vlines\nmean_qty_tons &lt;- mean(cargo_nodes$qty_tons, na.rm = TRUE)\nmedian_qty_tons &lt;- median(cargo_nodes$qty_tons, na.rm = TRUE)\n\n# Create a new column to indicate if the value is negative\ncargo_nodes &lt;- cargo_nodes %&gt;%\n  mutate(is_negative = ifelse(qty_tons &gt; 0, \"Positive\", \"Negative\"))\n\n# Plot Histogram\np1 &lt;- ggplot(cargo_nodes, aes(x = qty_tons, fill = is_negative)) +\n  geom_histogram(binwidth = 5, color = \"black\", alpha = 0.7) +\n  geom_vline(aes(xintercept = mean_qty_tons), \n             color = \"darkgreen\", \n             linetype = \"dashed\", \n             size = 1) +\n  geom_vline(aes(xintercept = median_qty_tons), \n             color = \"blue\", \n             linetype = \"dashed\", size = 1) +\n  scale_fill_manual(values = c(\"Negative\" = \"red\", \n                               \"Positive\" = \"skyblue\"), \n                    name = \"Value Type\") +\n  labs(title = \"Cargo Quantity in Tons with Mean and Median\",\n       x = \"Quantity of Tons\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  annotate(\"text\", \n           x = mean_qty_tons, \n           y = Inf, \n           label = paste(\"Mean =\", round(mean_qty_tons, 2)), \n           vjust = 1, hjust = -0.2, \n           color = \"darkgreen\") +\n  annotate(\"text\", \n           x = median_qty_tons, \n           y = Inf, \n           label = paste(\"Median =\", round(median_qty_tons, 2)), \n           vjust = 1, hjust = 1.3, color = \"blue\")\n\np2 &lt;- boxplot &lt;- ggplot(cargo_nodes, aes(y = qty_tons)) +\n  geom_boxplot(fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  coord_flip() +  # Flip coordinates to make it horizontal\n  labs(title = \"Boxplot of Quantity of Tons\",\n       x = \"\",\n       y = \"Quantity of Tons\") +\n  theme_minimal()\n\np1/p2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from this visualisation\n\n\n\n\nThere are cargoes which has negative. This is abnormal as all cargoes qty_tons values should be at least zero .\nThere are a number of outliers cargoes with qty_tons above ~70 tons.\n\n\n\nCargoes Quantity Ton by Date and City\n\n\nShow the code\n# Aggregate import record data\nimport_record_agg &lt;- import_record %&gt;%\n  mutate(year = year(cargo_delivery_date),\n         month = factor(month(cargo_delivery_date, label = TRUE), levels = month.abb), # Ensure month is a factor\n         day = day(cargo_delivery_date),\n         week = week(cargo_delivery_date),\n         weekday = wday(cargo_delivery_date, label = TRUE, week_start = 1)) %&gt;% \n  group_by(city, year, month) %&gt;%  # Group by city, year, and month\n  summarize(total_qty_tons = sum(qty_tons, na.rm = TRUE)) %&gt;% \n  arrange(city, year, month)\n\n# Create heatmap\nggplot(import_record_agg, \n       aes(x = month, \n           y = city, \n           fill = total_qty_tons)) + \n  geom_tile(color = \"white\", \n            size = 0.1) +  \n  coord_equal() +\n  scale_fill_gradient(name = \"Cargo Quantity Ton by Month\",\n                      low = \"sky blue\", \n                      high = \"dark blue\") +\n  labs(x = NULL, \n       y = NULL, \n       title = \"Cargo Quantity Ton by Month\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from this visualisation\n\n\n\n\nHigher qty_tons of cargoes enters the various cities from Aug to Nov period.\nQty_tons peak in Oct and Nov period, expecially for City of Paackland.\n\n\n\n\n\n1.6.7 Understanding the Vessels\nTypes of vessels\n\n\nShow the code\n# Vessel count and reorder bar plot\nvessel_count &lt;- vessel_nodes %&gt;%\n  group_by(type) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(type = reorder(type, -n))\n\n# Bar plot\nggplot(vessel_count,\n       aes(x = type,\n           y = n)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = n), vjust = -0.5, size = 3)\n\n\n\n\n\n\n\n\n\nLength by Tonnage\n\n\nShow the code\nDT::datatable(vessel_nodes, class= \"compact\")\n\n\n\n\n\n\nShow the code\nd &lt;- highlight_key(vessel_nodes)\n\n# Scatter plot\np &lt;- ggplot(d) +\n  geom_point(aes(x = length_overall,\n                 y = tonnage,\n                 color = type))\n\ngg &lt;- highlight(ggplotly(p),\n                \"plotly_selected\")\n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from this visualisation\n\n\n\n\nCargo vessels have wide range of length and tonnage. Only a few data points ( &lt;20), falls within similar range of the fishing vessels.\nThe fishing vessels tonnage mostly are &lt;12,000 ton and length_overall of &lt;150m. Only three fishing vessels are above these range.\n\n\n\nTonnage Distribution\n\n\nShow the code\n# Raincloud Plot for Tonnage Distribution of Fishing and Cargo Vessels\np1 &lt;- vessel_nodes %&gt;% \n  filter(type %in% c(\"FishingVessel\")) %&gt;%\n  ggplot(aes(x = tonnage, \n             y = type)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = 100,\n            dotsize = 1) +\n  ggtitle(\"Tonnage Distribution by of Fishing Vessels\") +\n  theme(plot.title = element_text(size=12)) +\n  theme_minimal()\n\np2 &lt;- vessel_nodes %&gt;% \n  filter(type %in% c(\"CargoVessel\")) %&gt;%\n  ggplot(aes(x = tonnage, \n             y = type)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = 500,\n            dotsize = 0.1) +\n  ggtitle(\"Tonnage Distribution by of Cargo Vessels\") +\n  theme(plot.title = element_text(size=12)) +\n  theme_minimal()\n\np1/p2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from this visualisation\n\n\n\n\nFishing vessels tonnage distribution is right skewed. There is high concentration of fishing vessels of &lt; 1,000 ton.\nCargo vessels tonnage falls largely into two distinct groups: (1) ~2000 ton, and (2) ~75,000 ton.\n\n\n\nVessel Type and Flag Country\n\n\nShow the code\n# Bar plot\nggplot(vessel_nodes) +\n  geom_bar(aes(x = flag_country,\n               fill = type)) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\nVessels from Oceanus We now take a more detailed look at Oceanus vessel.\n\n\nShow the code\n# Oceanus vessel count and reorder bar plot\nvessel_count &lt;- vessel_nodes %&gt;%\n  filter(flag_country == \"Oceanus\") %&gt;% \n  group_by(type) %&gt;%\n  summarize(n = n()) %&gt;% \n  mutate(type = reorder(type, -n))\n\n# Bar plot\nggplot(vessel_count,\n       aes(x = type,\n           y = n,\n           fill = type)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = n), vjust = -0.5, size = 3)\n\n\n\n\n\n\n\n\n\nVessels from other flag_country\n\n\nShow the code\n# Bar plot for flag countries other than Oceanus\nvessel_nodes %&gt;% \n  filter(flag_country != \"Oceanus\") %&gt;% \n  ggplot() +\n  geom_bar(aes(x = flag_country,\n               fill = type)) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) \n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Bar plot for flag countries other than Oceanus\nvessel_nodes %&gt;% \n  filter(flag_country != \"Oceanus\") %&gt;% \n  ggplot() +\n  geom_bar(aes(x = flag_country,\n               fill = type)) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  facet_grid(~type)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from these vessels visualisation\n\n\n\n\nMost fishing vessels (158 of 178) are registered under flag country of Oceanus.\nOther countries vessels are only cargo vessels (99) and fishing vessels (20).\nOther countries own between 0 to 5 cargo vessels and 0 to 2 fishing vessels.\n\n\n\nVessels by Company\nUpon inspecting the vessel_nodes data, we observe that non-Oceanus fishing vessels has registered company information, while non-Oceanus cargo vessels do not have registered company information. To confirm this is true, we remove those company that are “NA” in the bar plot.\n\n\n\nShow the code\n# Checking the hypothesis that non-Oceanus cargo vessels are not registered as company in the data\nvessel_nodes %&gt;% \n  na.omit(company) %&gt;% \n  filter(flag_country != \"Oceanus\") %&gt;% \n  ggplot(aes(x = company, fill = type)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  facet_grid(~type)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights from this visualisation\n\n\n\n\nOnly one cargo vessel is registered with company. This belongs to the “Saltwater Sisters Company Marine”. Using the data table created above, we found out that this cargo vessel is registered under the flag_country of Oceantterra. This company also owns a fishing vessel (bassbaiterb9f) with flag_country as Oceanus.\nAll 20 non-Oceanus fishing vessels are all registered with company in the data."
  },
  {
    "objectID": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#processing-nodes-and-edges-data",
    "href": "Take-home Exercise/Take-home_Ex03/Take-home_Ex03.html#processing-nodes-and-edges-data",
    "title": "Take Home Exercise 3",
    "section": "1.5 Processing nodes and edges data",
    "text": "1.5 Processing nodes and edges data\n\n1.5.1 Understanding the nodes and edges data\nIn this section, we will gain more insights from the existing data. The table below summarises the type of data we can glean from the nodes and edges:\n\n\n\n\n\n\n\n\n\nmc2_nodes Type\nEntity\nDetails\nRelevant Fields\n\n\n\n\nCommodity\nFish\n10 x Fish Species\n\n\nname (fish species common name/scientific name\nid (species)\n\n\n\nLocation\n\nCity\nPoint\nRegion\n\n24 x Locations:\n6 x City\n\n12 x Point\n\n6 x Region\n\n3 x Ecological Preserves\n3 x Fishing Ground\n\n\n\nid ( City Name)\nName (City short name)\ndescription\nactivities\nkind\nentity3 (type of location)\n\n\n\nDocument\nDelivery Report\n5,307 x Cargoes\n\nid\nqty_tons\ndate\n\n\n\nVessels\n\nFishing Vessels\nCargo Vessels\nFerry Cargo\nFerry Passenger\nResearch\nTour\nOthers\n\n296 x Vessels\n\n178 x Fishing Vessels\n100 x Cargo Vessels\n2 x Cargo Ferry\n3 x Passenger Ferry\n2 x Research Vessels\n6 x Tour Vessels\n5 x Other Vessels\n\n\nid\nName\nflag_country\ncompany\ntonnage\nlength_overall\nentity3 (type of vessels)\n\n\n\n\n\n\n\n\n\n\n\n\nmc2_edges type\nCount (n)\nRelevant Fields\n\n\n\n\nTransponder Ping\n258,542 x Pings\n\ntime\ndwell\nsource (locations)\ntarget (vessels)\n\n\n\nHarbor Report\n 2,487 x Sightings\n\nsource (vessels)\ntarget (city)\ndate\n\n\n\nImport Record\n10,614 x Records (matching 5,307 unique cargoes to fish species and city)\n\nsource (cargo)\ntarget (fish species & city)\ndate\n\n\n\n\n\n\n1.5.2 Extracting Relevant Information for each nodes data\nIn this section, we will extract the relevant columns with intuitive names. From the analysis above, we will have 4 nodes data and 3 edges data as below:\n\n\n\n\n\n\nNodes and Edges Data\n\n\n\nNodes:\n\nfish_nodes: all types of fish species in the data set\nlocation_nodes: all locations in the data set\ncargo_nodes: all cargoes in the data set\nvessel_nodes: all vessels in the data set\n\nEdges:\n\nvessel_movement: vessel movement, location, time and dwell\nharbor_report: date and vessel that dock in the harbor (city)\nimport_record: date and location of transaction of cargoes\n\n\n\nfish_nodes\n\n\nShow the code\nfish_nodes &lt;- mc2_nodes %&gt;% \n  filter(entity2 == \"Commodity\") %&gt;% \n  select(name, id) %&gt;% \n  mutate(name = str_replace(name, \"/.*\", \"\")) %&gt;% \n  rename(fish = name, species = id)\n\n\nlocation_nodes\n\n\nShow the code\nlocation_nodes &lt;- mc2_nodes %&gt;% \n  filter(entity2 == \"Location\" ) %&gt;% \n  select(id, Name, Description, Activities, kind, entity3) %&gt;% \n  rename(loc = id, loc_short = Name, type = entity3)\n\n\ncargo_nodes\n\n\nShow the code\ncargo_nodes &lt;- mc2_nodes %&gt;% \n  filter(entity3 == \"DeliveryReport\") %&gt;% \n  select(id,qty_tons,date) %&gt;% \n  rename(cargo = id, cargo_delivery_date = date)\n\n\nvessel_nodes\n\n\nShow the code\nvessel_nodes &lt;- mc2_nodes %&gt;% \n  filter(entity2 == \"Vessel\") %&gt;% \n  select(id, Name, flag_country, \n         company, tonnage, \n         length_overall, entity3) %&gt;% \n  rename(vessel = id, vessel_name = Name, type = entity3)\n\n\n\n\n1.5.3 Consolidating relevant information in the edges data\nvessel_movement\nWe will add in oceanus_location and vessel_nodes data together with the Transponder Ping data, by using left_join .\n\n\nShow the code\nvessel_movement &lt;- mc2_edges %&gt;% \n  filter(event3 == \"TransponderPing\") %&gt;% \n  select(time, dwell, source, target) %&gt;% \n  rename(loc= source, vessel = target ) %&gt;% \n  mutate(loc_short = gsub(\"^City of\", \"\", loc)) %&gt;%\n  mutate(loc_short = gsub(\"^\\\\s+\", \"\", loc)) %&gt;%\n  left_join(oceanus_locations_df) %&gt;% \n  left_join(vessel_nodes)\n\n\nharbor_report\nSimilarly, we will add in vessel_nodes data into the harbor_report using left_join.\n\n\nShow the code\nharbor_report &lt;- mc2_edges %&gt;% \n  filter(event2 ==\"HarborReport\") %&gt;% \n  select(source, target, date) %&gt;% \n  rename(vessel = source, city = target)\n\nharbor_report &lt;- harbor_report %&gt;% \n  left_join(vessel_nodes, by = \"vessel\")\n\n\nimport_record\nCombining fish_nodes and cargo_nodes data into import_record using left_join.\n\n\nShow the code\nimport_record &lt;- mc2_edges %&gt;% \n  filter(event2 == \"Transaction\") %&gt;% \n  select(source, target, date)\n\n\nimport_city &lt;- import_record %&gt;% \n  select(source,target) %&gt;% \n  filter(target %in% c(\"City of Haacklee\",\n                       \"City of Lomark\",\n                       \"City of Himark\",\n                       \"City of Paackland\",\n                       \"City of South Paackland\",\n                       \"City of Port Grove\")) %&gt;% \n  rename(city = target)\n\nimport_cargo &lt;- import_record %&gt;% \n  select(source,target) %&gt;% \n  filter(!target %in% c(\"City of Haacklee\",\n                       \"City of Lomark\",\n                       \"City of Himark\",\n                       \"City of Paackland\",\n                       \"City of South Paackland\",\n                       \"City of Port Grove\")) %&gt;% \n  rename(species = target)\n\nimport_record &lt;- import_city %&gt;% \n  left_join(import_cargo) %&gt;% \n  rename(cargo = source) %&gt;% \n  left_join(fish_nodes) %&gt;% \n  left_join(cargo_nodes) %&gt;% \n  select(fish, species, city, cargo, qty_tons, cargo_delivery_date)\n\n\nBefore we move on to exploring the data, we will save the 4 nodes and 3 edges as R rds format in the data/rds folder:\n\n\nShow the code\nwrite_rds(fish_nodes, \"data/rds/fish_nodes.rds\")\nwrite_rds(location_nodes, \"data/rds/location_nodes.rds\")\nwrite_rds(cargo_nodes, \"data/rds/cargo_nodes.rds\")\nwrite_rds(vessel_nodes, \"data/rds/vessel_nodes.rds\")\nwrite_rds(vessel_movement, \"data/rds/vessel_movement.rds\")\nwrite_rds(harbor_report, \"data/rds/harbor_report.rds\")\nwrite_rds(import_record, \"data/rds/import_record.rds\")"
  }
]