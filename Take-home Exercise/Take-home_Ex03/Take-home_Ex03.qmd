---
title: "Take Home Exercise 3"
author: "Rydia"
date: "May 13, 2024"
date-modified: "last-modified"
execute:
  eval: true
  echo: true
  warning: false
  freeze: true
---

# VAST 2024 Mini Challenge 2

## Mini-Challenge 2: Creating Signatures for Geo-Temporal Patterns

Mini-challenge 2 focuses on analyzing ship movements and shipping records to understand illegal fishing practices. FishEye analysts need help creating visualizations to show patterns of ship movements and identify suspicious behaviors. They also want to understand how the commercial fishing community changed after a company was caught fishing illegally.

The details of the mini challenge can be found [here](https://vast-challenge.github.io/2024/MC2.html).

## Tasks and Questions

FishEye analysts need your help to perform geographic and temporal analysis of the CatchNet data so they can prevent illegal fishing from happening again. Your task is to develop new visual analytics tools and workflows that can be used to discover and understand signatures of different types of behavior. Can you use your tool to visualize a signature of SouthSeafood Express Corp’s illegal behavior? FishEye needs your help to develop a workflow to find other instances of illegal behavior.

1.  FishEye analysts have long wanted to better understand the flow of commercially caught fish through Oceanus’s many ports. But as they were loading data into CatchNet, they discovered they had purchased the wrong port records. They wanted to get the ship off-load records, but they instead got the port-exit records (essentially trucks/trains leaving the port area). Port exit records do not include which vessel that delivered the products. Given this limitation, develop a visualization system to associate vessels with their probable cargos. Which vessels deliver which products and when? What are the seasonal trends and anomalies in the port exit records?

2.  Develop visualizations that illustrate the inappropriate behavior of SouthSeafood Express Corp vessels. How do their movement and catch contents compare to other fishing vessels? When and where did SouthSeafood Express Corp vessels perform their illegal fishing? How many different types of suspicious behaviors are observed? Use visual evidence to justify your conclusions.

3.  To support further Fisheye investigations, develop visual analytics workflows that allow you to discover other vessels engaging in behaviors similar to SouthSeafood Express Corp’s illegal activities? Provide visual evidence of the similarities.

4.  How did fishing activity change after SouthSeafood Express Corp was caught? What new behaviors in the Oceanus commercial fishing community are most suspicious and why?

## 1.0 Data Preparation

## 1.1 Loading R Packages

```{r}
pacman::p_load(tidyverse, jsonlite, DT, lubridate,
               igraph, tidygraph, ggraph, 
               visNetwork, sf)
```

## 1.2 Loading the Data

Loading the .json data using `jsonlite` package.

```{r}
mc2_data <- fromJSON("data/MC2/mc2.json")
```

mc2 is a directed multigraph, consists of nodes dataframe and links dataframe.

```{r}
oceanus_map <- read_sf("data/MC2/Oceanus Information/Oceanus Geography.geojson")
```

Loading the oceanus map:

```{r}
ggplot(oceanus_map) +
  geom_sf(color = "black",
          ) +
  theme_void() +
  geom_sf_text(aes(label = Name), size = 2,
               vjust = 1.5)
```

## 1.3 **Wrangling and tidying edges**

### 1.3.1 Extracting edges

First, we extract only distinct edges from the tibble *links* data.frame of *mc2_data* and save it as a tibble data.frame called *mc2_edges*.

```{r}
mc2_edges <- mc2_data$links %>% 
  distinct()
```

Next, `glimpse()` of dplyr will be used to reveal the structure of *mc2_edges* tibble data.table.

```{r}
glimpse(mc2_edges)
```

From the table above, we can identify some issues with the data:

1.  The columns with date data type are all in character format.

2.  Some columns have names that starts with "\_". These need to be rename to avoid coding issues.

### 1.3.2 Correcting the date data type with `lubridate()`

```{r}
mc2_edges$time <- as_datetime(mc2_edges$time)
mc2_edges$`_last_edited_date` <- as_datetime(mc2_edges$`_last_edited_date`)
mc2_edges$`_date_added` <- as_datetime(mc2_edges$`_date_added`)
mc2_edges$date <- as_datetime(mc2_edges$date)
```

Next, glimpse() will be used to confirm if the process have been performed correctly.

```{r}
glimpse(mc2_edges)
```

### 1.3.3 Changing field name

In the code chunk below, rename() of dplyr package is used to change the following fields.

```{r}
mc2_edges <- mc2_edges %>%
  rename("last_edited_by" = "_last_edited_by",
         "date_added" = "_date_added",
         "last_edited_date" = "_last_edited_date",
         "raw_source" = "_raw_source",
         "algorithm" = "_algorithm") 
```

### 1.3.4 Splitting words in `type` column

The code chunk below combined the following steps:

1.  Splitting the words by "." - after observing that the format for type is as such: "Event.TransportEvent.TransponderPing"

2.  The `max(lengths(word_list))` will be used to find the maximum number of elements in any split.

3.  Apply function(x) to pad shorter splits with NA values to make them all the same length.

4.  Create word_df and changing column names to event1 etc.

5.  Convert word_df from matrix into tibble data.frame, and checks its class.

6.  Append word_df to mc2_edges tibble data.frame.

7.  Saving mc2_edges into R **rds** format as a physical file, so that there is no need to repeat the following code chunk to access a tidy mc2_edges tibble data frame.

```{r}
word_list <- strsplit(mc2_edges$type, "\\.")

max_elements <- max(lengths(word_list))

word_list_padded <- lapply(word_list, 
function(x) c(x, rep(NA, max_elements - length(x))))

word_df <- do.call(rbind, word_list_padded)
colnames(word_df) <- paste0("event", 1:max_elements)

word_df <- as_tibble(word_df) %>%
  select(event2, event3)
class(word_df)

mc2_edges <- mc2_edges %>%
  cbind(word_df)

# prior to running this code, create an rds folder in data folder to ensure files are saved in the correct directory
write_rds(mc2_edges, "data/rds/mc2_edges.rds")

```

## 1.4 **Wrangling and tidying nodes**

### 1.4.1 Extracting nodes

The code chunk below will be used to extract the nodes data.frame of mc2_data and parses it as a tibble data.frame called mc2_nodes.

```{r}
mc2_nodes <- as_tibble(mc2_data$nodes) %>%
  distinct()
```

Next, take a `glimpse()` to understand the data structure.

```{r}
glimpse(mc2_nodes)
```

From the table above, beside the date data type, inappropriate field name, and treatment for `type` column issues we discussed earlier, two additional data issues can be observed. They are:

-   The values in Activities and fish_species_present fields are in **list** data type, which will affect the ability to process and to analyse the data.

-   Some values in the Activities field are not ready to be analyse without further tidying (i.e. removing c(““)).

We will first repeat the steps similar steps to wrangling the mc2_edges, before proceeding to tackle the issues for Activities and fish_species_present field. 

### 1.4.2 Correcting the date data type with `lubridate()`

Correct the date data type and take a `glimpse()` to confirm changes.
```{r}
mc2_nodes$`_last_edited_date` <- as_datetime(mc2_nodes$`_last_edited_date`)
mc2_nodes$`_date_added` <- as_datetime(mc2_nodes$`_date_added`)
mc2_nodes$date <- as_datetime(mc2_nodes$date)
glimpse(mc2_nodes)
```

### 1.4.3 Changing field name

In the code chunk below, rename() of dplyr package is used to change the following fields.

```{r}
mc2_nodes <- mc2_nodes %>%
  rename("last_edited_by" = "_last_edited_by",
         "date_added" = "_date_added",
         "last_edited_date" = "_last_edited_date",
         "raw_source" = "_raw_source",
         "algorithm" = "_algorithm") 
```

### 1.4.4 Splitting words in `type` column

Details on the code chunk can be found in section 1.3.4. At this point, we will not be saving the mc2_nodes as R **rds** format yet, as there are more works to be done to clean up the dataframe.

```{r}
word_list <- strsplit(mc2_nodes$type, "\\.")

max_elements <- max(lengths(word_list))

word_list_padded <- lapply(word_list, 
function(x) c(x, rep(NA, max_elements - length(x))))

word_df <- do.call(rbind, word_list_padded)
colnames(word_df) <- paste0("entity", 1:max_elements)

word_df <- as_tibble(word_df) %>%
  select(entity2, entity3)
class(word_df)

mc2_nodes <- mc2_nodes %>%
  cbind(word_df)
```

### 1.4.5 Tidying text field

Using `mutate()` of dplyr and `gsub()` of Base R to tidy up the values in the cell. Essentially, the unwanted characters like `c`, `(`, `)`, and `\` are removed by substituting with empty value `""` for both Activities and fish_species_present columns. What is left in the columns will be characters separated by `,`. 

```{r}
mc2_nodes <- mc2_nodes %>%
  mutate(Activities = gsub("c[(]", "", Activities)) %>% 
  mutate(Activities = gsub("\"", "", Activities)) %>%
  mutate(Activities = gsub("[)]", "", Activities)) 
```

```{r}
mc2_nodes <- mc2_nodes %>%
  mutate(fish_species_present = gsub("c[(]", "", fish_species_present)) %>% 
  mutate(fish_species_present = gsub("\"", "", fish_species_present)) %>%
  mutate(fish_species_present = gsub("[)]", "", fish_species_present)) 
```

Lastly, we will save the tidied mc2_nodes

```{r}
# prior to running this code, create an rds folder in data folder to ensure files are saved in the correct directory
write_rds(mc2_nodes, "data/rds/mc2_nodes.rds")
```





























