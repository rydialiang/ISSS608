---
title: "In-class Ex 06""
author: "Liang Xiuhao Rydia"
date: "May 18, 2024"
date-modified: "last-modified"
execute:
  eval: true
  echo: true
  warning: false
  freeze: true
---

Example from [corporaexplorer](https://kgjerde.github.io/corporaexplorer/articles/bible.html)

```{r}
pacman::p_load(tidyverse, stringi,
               rvest, corporaexplorer,
               readtext,
               quanteda, tidytext)
```

```{r}
bible <- readr::read_lines("http://www.gutenberg.org/cache/epub/10/pg10.txt")
```

To tidy the text, we need to know where does it start and end. 

```{r}
# collapse all into one string
bible <- paste(bible, collapse = "\n")
```

```{r}
# Identifying the beginning and end of the Bible / stripping PJ metadata
 # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).
start_v <- stri_locate_first_fixed(bible, "The First Book of Moses: Called Genesis")[1]
end_v <- stri_locate_last_fixed(bible, "Amen.")[2]
bible <- stri_sub(bible, start_v, end_v)
```


```{r}
# In the file, every book in the bible is preceded by five newlines,
  # which we use to split our string into a vector where each element is a book.
books <- stri_split_regex(bible, "\n{5}") %>%
    unlist %>%
    .[-40]  # Removing the heading "The New Testament of the King James Bible",
              # which also was preceded by five newlines.

```



```{r}
# Because of the structure of the text in the file:
  # Replacing double or more newlines with two newlines, and a single newline with space.
books <- str_replace_all(books, "\n{2,}", "NEW_PARAGRAPH") %>%
    str_replace_all("\n", " ") %>%
    str_replace_all("NEW_PARAGRAPH", "\n\n")
books <- books[3:68]  # The two first elements are not books
```


```{r}
# Identifying new chapters within each book and split the text into chapters.
# (The first characters in chapter 2 will e.g. be 2:1)
chapters <- str_replace_all(books, "(\\d+:1 )", "NEW_CHAPTER\\1") %>%
    stri_split_regex("NEW_CHAPTER")
```

```{r}
# Removing the chapter headings from the text (we want them as metadata).
chapters <- lapply(chapters, function(x) x[-1])
```

```{r}
# We are not quite happy with the long book titles in the King James Bible,
  # so we retrieve shorter versions from esv.org which will take up less
  # space in the corpus map plot.
book_titles <- read_html("https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations") %>%
  html_nodes("td:nth-child(1)") %>%
  html_text() %>%
  .[13:78]  # Removing irrelevant elements after manual inspection.
```

```{r}
# We add a column indicating whether a book belongs to the Old or New Testament,
#   knowing that they contain respectively 39 and 27 books.
testament <- c(rep("Old", 39), rep("New", 27))
```

```{r}
# Data frame with one book as one row.
bible_df <- tibble::tibble(Text = chapters,
                           Book = book_titles,
                           Testament = testament)
```

```{r}
# We want each chapter to be one row, but keep the metadata (book and which testament).
bible_df <- tidyr::unnest(bible_df, Text)
```

```{r}
KJB <- prepare_data(dataset = bible_df,
                    date_based_corpus = FALSE,
                    grouping_variable = "Book",
                    columns_doc_info = c("Testament", "Book"))
```

- text field = text we want to analyse

Make sure you check the class of the object. The below should show "corporaexplorerobject".

```{r}
class(KJB)
```
```{r}
explore(KJB)
```

```{r}
pacman::p_load(jsonlite, tidygraph,ggraph,
               visNetwork, graphlayouts,
               ggforce, skimr, tidytext,
               tidyverse)
```

```{r}
mc3_data <- fromJSON("data/MC3.json")
```

This data is a list, not a dataframe.
```{r}
class(mc3_data)
```

Use distinct to remove duplicate
```{r}
mc3_edges <-
  as_tibble(mc3_data$links) %>%
  distinct() %>%
  mutate(source = as.character(source),
         target = as.character(target),
         type = as.character(type)) %>%
  group_by(source, target, type) %>%
  summarise(weights = n()) %>%
  filter(source!=target) %>%
  ungroup
```
### clean edge file
```{r}
mc3_nodes <- as_tibble(mc3_data$nodes) %>% 
  mutate(country = as.character(country),
         id = as.character(id),
         product_services = as.numeric(as.character(revenue_omu)),
         type = as.character(type)) %>% 
  select(id, country, type, revenue_omu,
         product_services)
```

```{r}
skim(mc3_edges)
```

### Add the columns back in after cleaning
```{r}
id1 <- mc3_edges %>% 
  select(source) %>% 
  rename(id = source)

id2 <- mc3_edges %>% 
  select(target) %>% 
  rename(id = target)

mc3_nodes1 <- rbind(id1,id2) %>% 
  distinct() %>% 
  left_join(mc3_nodes,
            unmatched = "drop")
```

```{r}
mc3_graph <- tbl_graph(nodes = mc3_nodes1,
                       edges = mc3_edges,
                       directed = FALSE) %>% 
  mutate(betweenness_centrality = centrality_betweenness(),
                                                         closeness_centrality = centrality_closeness())
```



```{r}
mc3_graph %>% 
  filter(betweenness_centrality >= 300000) %>% 
ggraph(layout = "fr") +
  geom_edge_link(aes(alpha=0.5)) +
  geom_node_point(aes(
    size = betweenness_centrality,
    colors = "lightblue",
    alpha = 0.5)) +
  scale_size_continuous(range=c(1,10)) +
  theme_graph()
  ))
```


